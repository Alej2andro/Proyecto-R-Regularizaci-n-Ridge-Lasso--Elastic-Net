---
title: "Predicci√≥n de Radiaci√≥n Solar en Sector la Puntilla, Pichilemu"
subtitle: "An√°lisis predictivo con M√©todos de Aprendizaje Supervisado y Regularizaci√≥n (Ridge, Lasso y Elastic Net)"
author: "Alejandro Figueroa Rojas"
date: "2025-10-11"
output:
  html_document:
    theme: yeti
    highlight: tango
    df_print: paged
    toc: true
    toc_float:
      collapsed: TRUE
      smooth_scroll: true
    toc_depth: 3
    self_contained: true      # ‚Üê AGREGADO: Incluye dependencias leaflet
    lib_dir: libs             # ‚Üê AGREGADO: Directorio para bibliotecas JS
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(
  comment = "", 
  message = FALSE, 
  warning = FALSE,
  fig.align = "center",
  cache = FALSE
)

```

```{r ,verificaci√≥n biliotecas,include= FALSE}

required_packages <- c("leaflet", "sf", "tidyverse", "glmnet", "caret", 
                       "ggcorrplot", "lmtest", "Metrics", "kableExtra")

for (pkg in required_packages) {
  if (!require(pkg, quietly = TRUE, character.only = TRUE)) {
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

```

# üó∫ Mapa Interactivo: Sector la Puntilla, Pichilemu.
```{r mapa_pichilemu sector la puntilla, echo=FALSE, fig.width=10, fig.height=6, out.width="100%"}

library(leaflet)
library(leaflet.extras)
library(tidyverse)
library(htmlwidgets)
library(glue)
library(htmltools)
library(sf)

# CONFIGURACI√ìN
zoom_levels <- list(
  global   = list(lat = -34.38, lon = -72.01, zoom = 0),
  objetivo = list(lat = -34.37, lon = -72.02, zoom = 18)
)

puntilla_coords <- tibble(
  lon = -72.01,
  lat = -34.38,
  nombre = "Puntilla Principal",
  descripcion = "Zona de an√°lisis estrat√©gica"
)

focus_coords <- list(
  lat = -34.385,
  lon = -72.015,
  zoom = 15
)

# BUFFER PRECISO 300m
punto_sf <- st_sf(
  nombre = puntilla_coords$nombre,
  geometry = st_sfc(st_point(c(puntilla_coords$lon, puntilla_coords$lat))),
  crs = 4326
)

buffer_wgs84 <- punto_sf %>%
  st_transform(32719) %>%
  st_buffer(dist = 300) %>%
  st_transform(4326)

# ICONOS Y POPUPS
iconos <- list(
  objetivo = awesomeIcons(
    icon = "crosshairs",
    markerColor = "blue",
    library = "fa",
    iconColor = "white"
  )
)

popup_principal <- glue(
  "<div style='font-family: Arial, sans-serif;'>
     <b>{puntilla_coords$nombre}</b><br>
     {puntilla_coords$descripcion}<br>
     Lat: {round(puntilla_coords$lat, 5)}¬∞ | Lon: {round(puntilla_coords$lon, 5)}¬∞<br>
     Radio: 300 m
   </div>"
)

# MAPA OPTIMIZADO
mapa_hibrido <- leaflet(options = leafletOptions(minZoom = 1.5, maxZoom = 28)) %>%
#mapa_hibrido <- leaflet(options = leafletOptions(minZoom = 2, maxZoom = 28,continuousWorld=FALSE,worldCopyJump = FALSE
#)) %>%

  # Capas base
  addProviderTiles(providers$Esri.WorldImagery, group = "üõ∞Ô∏è Sat√©lite") %>%
  addTiles(group = "üó∫Ô∏è Est√°ndar") %>%
  addProviderTiles(providers$CartoDB.DarkMatter, group = "üåô Nocturno") %>%
  addProviderTiles(providers$Esri.WorldTopoMap, group = "‚õ∞Ô∏è Topogr√°fico") %>%

  setView(lng = zoom_levels$global$lon, lat = zoom_levels$global$lat, zoom = zoom_levels$global$zoom) %>%

  # Marcador principal
  addAwesomeMarkers(
    lng = puntilla_coords$lon,
    lat = puntilla_coords$lat,
    popup = popup_principal,
    icon = iconos$objetivo,
    label = puntilla_coords$nombre,
    group = "üéØ Objetivo Principal"
  ) %>%

  # C√≠rculo simple
  addCircles(
    lng = puntilla_coords$lon,
    lat = puntilla_coords$lat,
    radius = 300,
    color = "#5AA2A2",
    weight = 2,
    fillColor = "#6BAF92",
    fillOpacity = 0.08,
    opacity = 0.5,
    label = "üîµ Zona de an√°lisis principal (300m)",
    group = "üéØ √Årea de Estudio (C√≠rculo)"
  ) %>%

  # Buffer preciso con sf
  addPolygons(
    data = buffer_wgs84,
    color = "#5AA2A2",
    weight = 2,
    fillColor = "#6BAF92",
    fillOpacity = 0.15,
    label = "üîµ √Årea precisa SF (300m)",
    popup = "√Årea de estudio precisa (buffer 300m)",
    group = "üéØ √Årea de Estudio (SF)"
  ) %>%

  # MiniMap y pantalla completa
  addMiniMap(tiles = providers$Esri.WorldStreetMap, toggleDisplay = TRUE, minimized = TRUE) %>%
  addFullscreenControl() %>%

  # Botones EasyButton (incluyendo medici√≥n personalizada)
  addEasyButton(
    easyButton(icon="fa-crosshairs", title="üéØ Ir al objetivo",
               onClick=JS(sprintf(
                 "function(btn,map){ map.flyTo([%f,%f], %d, {animate:true, duration:3}); }",
                 zoom_levels$objetivo$lat, zoom_levels$objetivo$lon, zoom_levels$objetivo$zoom)))
  ) %>%
  addEasyButton(
    easyButton(icon="fa-dot-circle-o", title="üîµ Ir al centro del √°rea",
               onClick=JS(sprintf(
                 "function(btn,map){ map.flyTo([%f,%f], %d, {animate:true, duration:3}); }",
                 focus_coords$lat, focus_coords$lon, focus_coords$zoom)))
  ) %>%
  addEasyButton(
    easyButton(icon="fa-ruler", title="üìè Medir",
               onClick=JS("function(btn, map) {
                 L.measureControl._enabled = !L.measureControl._enabled;
                 if (L.measureControl._enabled) {
                   btn.button.style.backgroundColor = '#5AA2A2';
                   btn.button.style.color = '#ffffff';
                 } else {
                   btn.button.style.backgroundColor = '';
                   btn.button.style.color = '';
                 }
                 L.measureControl.toggle();
               }"))
  ) %>%

  # Control de capas
  addLayersControl(
    baseGroups = c("üõ∞Ô∏è Sat√©lite", "üó∫Ô∏è Est√°ndar", "üåô Nocturno", "‚õ∞Ô∏è Topogr√°fico"),
    overlayGroups = c("üéØ Objetivo Principal", "üéØ √Årea de Estudio (C√≠rculo)", "üéØ √Årea de Estudio (SF)"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%

  # Animaci√≥n inicial
  htmlwidgets::onRender(sprintf("
    function(el, x){
      var map = this;
      const measureControls = el.querySelectorAll('.leaflet-control-measure');
      measureControls.forEach(control => control.remove());
      setTimeout(function(){
        map.flyTo([%f,%f], %d, {animate:true, duration:4});
      }, 1000);
    }
", focus_coords$lat, focus_coords$lon, focus_coords$zoom))


mapa_hibrido


```

<br>

# Proyecto de Machine Learning: Predicci√≥n de Radiaci√≥n Solar Descendente en superficie en Sector la Puntilla

¬øDe qu√© trata esto?

Predecir radiaci√≥n solar en la costa de Pichilemu usando 17 variables meteorol√≥gicas. Un caso completo de machine learning: limpieza ‚Üí exploraci√≥n ‚Üí modelado ‚Üí validaci√≥n.

**El desaf√≠o**

¬øPodemos estimar cu√°nta energ√≠a solar llegar√° ma√±ana sin medirla directamente? √ötil para paneles fotovoltaicos, riego agr√≠cola y gesti√≥n h√≠drica.

**Qu√© aprender√°s**

**Tres m√©todos de regularizaci√≥n:**

- ***Ridge:*** Estabiliza coeficientes ante multicolinealidad sin eliminar variables
- ***Lasso:*** Selecciona variables autom√°ticamente  
- ***Elastic Net:*** Combina ambos (el ganador: R¬≤=0.96)


**Los datos: NASA POWER**

***Ventaja:*** 20+ a√±os de datos satelitales gratuitos  
***Limitaci√≥n:*** Resoluci√≥n ~50km (promedios regionales, no puntuales)


¬øPara qui√©n est√° dirigido este proyecto?

- Personas que est√°n aprendiendo R o machine learning con datos reales.

- Quienes buscan construir o ampliar su portafolio de ciencia de datos.

- Interesados en la aplicaci√≥n de anal√≠tica a temas de energ√≠a renovable o meteorolog√≠a.


**Resultados**

- Modelo con 96% de varianza explicada y alta precisi√≥n (RMSE=0.19)
- Variables clave identificadas con sentido f√≠sico real
- C√≥digo reproducible y adaptable a otros problemas

---

**Esp√≠ritu:** Ganas de aprender y mejora continua.


# Resumen Ejecutivo

Predecir radiaci√≥n solar en la costa de Pichilemu en el sector la puntilla usando **17 variables meteorol√≥gicas** de NASA POWER (2001-2025). Un proyecto completo de machine learning: datos satelitales ‚Üí exploraci√≥n ‚Üí regularizaci√≥n ‚Üí validaci√≥n.

**Metodolog√≠a**

- ***Preprocesamiento***: 63 outliers detectados y conservados como eventos extremos
- ***Modelos***: Ridge, Lasso y Elastic Net optimizado con validaci√≥n cruzada 10-fold
- ***Divisi√≥n***: 80% entrenamiento / 20% prueba

<br>

**Resultados clave:**

<br>

| **M√©trica**               | **Valor**                | **Interpretaci√≥n**                                        |
|----------------------------|---------------------------|------------------------------------------------------------|
| **R¬≤**                     | 0.96                      | Explica el 96 % de la varianza en la radiaci√≥n solar       |
| **RMSE**                   | 0.19                      | Error promedio en escala estandarizada                     |
| **Mejora vs baseline**     | +95.8 pp                  | Reducci√≥n del 79.4 % en el error predictivo                |
| **Hiperpar√°metros √≥ptimos**| Œ± = 0.10 , Œª = 0.000886   | Equilibrio entre selecci√≥n de variables y estabilidad       |


<br>


***Hallazgo principal:*** El modelo captura mecanismos f√≠sicos reales (correlaci√≥n radiaci√≥n-temperatura r=0.84), validando la coherencia meteorol√≥gica de las predicciones.

***Limitaci√≥n cr√≠tica:*** ‚ö†Ô∏è Datos satelitales requieren calibraci√≥n local** con piran√≥metros antes de uso operacional. Este an√°lisis es exploratorio y pedag√≥gico.


***Aplicabilidad:*** V√°lido para an√°lisis de tendencias, planificaci√≥n energ√©tica preliminar y contextos educativos. NO reemplaza mediciones directas.

<br>

## Objetivo

**Objetivo principal:** Desarrollar un modelo predictivo robusto para radiaci√≥n solar descendente en superfcie en sector la puntilla , que sirva como caso de estudio did√°ctico sobre m√©todos de regularizaci√≥n en machine learning.

**Objetivos espec√≠ficos:**

1. **Metodol√≥gicos:**

  - Aplicar Ridge, Lasso y Elastic Net para comprender sus fundamentos matem√°ticos y diferencias pr√°cticas
  - Demostrar el flujo completo de ciencia de datos: limpieza ‚Üítransformaci√≥n ‚Üí exploraci√≥n ‚Üí modelado ‚Üí validaci√≥n
   - Ilustrar la importancia del preprocesamiento (detecci√≥n de outliers, estandarizaci√≥n)

2. **T√©cnicos:**

  - Optimizar hiperpar√°metros (Œ±, Œª) mediante validaci√≥n cruzada
  - Comparar rendimiento de modelos regularizados vs validaci√≥n de supuestos y baseline
  - Interpretar resultados m√©tricos , gr√°ficos y selecci√≥n autom√°tica de variables

3. **Pedag√≥gicos:**

  - Crear un recurso reproducible para personas aprendiendo R y machine learning
  - Conectar teor√≠a matem√°tica (penalizaciones L1/L2) con implementaci√≥n pr√°ctica
  - Mostrar diagn√≥stico exhaustivo de supuestos (normalidad, homocedasticidad, autocorrelaci√≥n)

4. **Aplicados:**

  - Evaluar viabilidad de datos satelitales MERRA-2 para predicci√≥n de radiaci√≥n solar
  - Identificar variables meteorol√≥gicas clave con significado f√≠sico
  - Establecer limitaciones y requisitos para uso operacional

**P√∫blico objetivo:** Estudiantes/profesionales de ciencia de datos, meteorolog√≠a aplicada y energ√≠as renovables que buscan comprender machine learning supervisado con datos reales.

üó∫ Localizaci√≥n del √Årea de Estudio
```{r mapa_pichilemu localizacion, echo=FALSE, fig.height=6}

# Coordenadas Puntilla de Pichilemu
coords <- list(lat = -34.38, lon = -72.01)

# Buffer 300m para visualizaci√≥n
punto_sf <- st_sf(
  geometry = st_sfc(st_point(c(coords$lon, coords$lat))),
  crs = 4326
) %>%
  st_transform(32719) %>% 
  st_buffer(dist = 300) %>% 
  st_transform(4326)

```

**Ubicaci√≥n**: Puntilla de Pichilemu (34.38¬∞S, 72.01¬∞W), sector costero representativo del clima mediterr√°neo costero de Chile central.

<br>

# An√°lisis Clim√°tico 
```{r ,include = FALSE }

#check in directorio de trabajo 
getwd()

```

## Preprocesamiento de datos 
### Dataset
```{r show dataset}

df <- read.csv("Meteorologia_sector_la_puntilla_pichilemu.csv",
               header = TRUE, sep = ";", fileEncoding ="UTF-8")
head(df)

```

### Data cleaning

Cambio de nombres de las variables de ingles a espa√±ol 
```{r cambio nombres variables}

library(dplyr)

df <- df %>% rename(
  `A√±o` = YEAR,
  `D√≠a del a√±o` = DOY,
  `Radiaci√≥n solar descendente superficie (W/m¬≤)` = ALLSKY_SFC_SW_DWN,
  `Radiaci√≥n solar superior atmosfera (W/m¬≤)` = TOA_SW_DWN,
  `Radiaci√≥n solar directa normal en superficie (W/m¬≤)` = ALLSKY_SFC_SW_DNI,
  `Radiaci√≥n onda larga superficie (W/m¬≤)` = ALLSKY_SFC_LW_DWN,
  `Temperatura 2 mts altura (¬∞c)` = T2M,
  `Temperatura h√∫meda 2 mts altura (¬∞c)` = T2MWET,
  `Temperatura m√°x 2 mts altura (¬∞c)` = T2M_MAX,
  `Temperatura m√≠n 2 mts altura (¬∞c)` = T2M_MIN,
  `Temperatura m√°x superficie (¬∞c)` = TS_MAX,
  `Temperatura m√≠n superficie (¬∞c)` = TS_MIN,
  `Contenido vapor agua 2 mts altura (g/m¬≥)` = QV2M,
  `Humedad relativa 2 mts altura (%)` = RH2M,
  `Precipitaci√≥n total corregida (mm)` = PRECTOTCORR,
  `Presi√≥n superficial (Pa)` = PS,
  `Velocidad m√°x viento 2 mts altura (m/s)` = WS2M_MAX,
  `Velocidad m√≠n viento 2 mts altura  (m/s)` = WS2M_MIN,
  `Velocidad m√°x viento 10 mts altura (m/s)` = WS10M_MAX,
  `Velocidad m√≠n viento 10 mts altura (m/s)` = WS10M_MIN,
  `Humedad perfil suelo(%)` = GWETPROF,
  `Temperatura superficie (¬∞c)` = TS
)

names(df)

```
<br>

### Variables meteorol√≥gicas

**Variables Meteorol√≥gicas y Clim√°ticas con Unidades de medida :**

-   Radiaci√≥n solar descendente superficie - W/m¬≤ (vatios por metro cuadrado)
-   Radiaci√≥n solar superior atm√≥sfera - W/m¬≤ (vatios por metro cuadrado)
-   Radiaci√≥n solar directa normal en superficie - W/m¬≤ (vatios por metro cuadrado)
-   Temperatura a 2 metros de altura - ¬∞C (grados Celsius)
-   Temperatura h√∫meda a 2 metros de altura - ¬∞C (grados Celsius)
-   Temperatura m√°xima a 2 metros de altura - ¬∞C (grados Celsius)
-   Temperatura m√≠nima a 2 metros de altura - ¬∞C (grados Celsius)
-   Temperatura m√°xima de superficie - ¬∞C (grados Celsius)
-   Temperatura m√≠nima de superficie - ¬∞C (grados Celsius)
-   Contenido de vapor de agua a 2 metros de altura - kg/kg o g/m¬≥
-   H√∫medad relativa a 2 metros de altura - % (porcentaje)
-   Precipitaci√≥n total corregida - mm (mil√≠metros)
-   Presi√≥n superficial - Pa (pascales) o hPa (hectopascales)
-   Velocidad m√°xima del viento a 2 metros de altura - m/s (metros por segundo)
-   Velocidad m√≠nima del viento a 2 metros de altura - m/s (metros por segundo)
-   Velocidad m√°xima del viento a 10 metros de altura - m/s (metros por segundo)
-   Velocidad m√≠nima del viento a 10 metros de altura - m/s (metros por segundo)
-   Humedad del perfil del suelo - m¬≥/m¬≥ o % (porcentaje volum√©trico)
-   Radiaci√≥n de onda larga de superficie - W/m¬≤ (vatios por metro cuadrado)
-   Temperatura de superficie - ¬∞C (grados Celsius)

<br>

## Inspecci√≥n Preliminar de Datos
```{r}

summary(df)

```

De acuerdo a lo observado en el resumen .Los valores -999, al ser c√≥digos especiales para datos faltantes o inv√°lidos, se convirtieran a NA para evitar sesgos en el an√°lisis, garantizando un manejo adecuado en analsis estad√≠stico y asegurar la consistencia de los modelos de machine learning, que requieren datos limpios y coherentes para un rendimiento √≥ptimo.

<br>

Se Reemplazara los valores -999 por NA , esto facilitara el manejo correcto de dichos valores en an√°lisis y funciones estad√≠sticas.
```{r}
df[df == -999] <- NA
```
<br>

Verificaci√≥n de valores faltantes
```{r,echo = FALSE}

cat(paste0("El Data Frame Contiene filas NA :", anyNA(df)))

```
Dado respuesta, esta condici√≥n se trata m√°s adelante .

<br>

Detecci√≥n de Filas duplicadas
```{r,echo = FALSE}

cat(paste0("El Data Frame contiene filas duplicadas: ", any(duplicated(df))))

```
<br>

Resumen de datos iniciales
```{r resumen_datos,echo=FALSE}

cat(sprintf("üìà Dataset cargado: %d observaciones, %d variables\nüîç Valores NA detectados: %d (%.1f%%)\nüß© Registros duplicados: %s\n\n",
            nrow(df), ncol(df),
            sum(is.na(df)), sum(is.na(df)) / (nrow(df) * ncol(df)) * 100,
            ifelse(any(duplicated(df)), "S√≠", "No")))

```
<br>

Verificaci√≥n de valores m√≠nimos
```{r,echo=FALSE}

cat("‚úÖ Valores m√≠nimos despu√©s de la correcci√≥n:\n",
    "  ‚Ä¢ Radiaci√≥n solar descendente superficie:", min(df$`Radiaci√≥n solar descendente superficie (W/m¬≤)`, na.rm = TRUE), "W/m¬≤\n",
    "  ‚Ä¢ Humedad relativa 2 mts altura:", min(df$`Humedad relativa 2 mts altura (%)`, na.rm = TRUE), "%\n")
```


<br>

Estructura de los datos
```{r}

str(df)

```
<br>

## Analisis exploratorio 
### Preprocesamiento para visualizaci√≥n clim√°tica
```{r trabajo previo gr√°ficos dispersi√≥n- var climaticas claves}

library(ggplot2)
library(gridExtra)
library(scales)

# An√°lisis de variables claves

variables_clave <- c(
  "Radiaci√≥n solar descendente superficie (W/m¬≤)",
  "Temperatura m√°x 2 mts altura (¬∞c)", 
  "Humedad relativa 2 mts altura (%)",
  "Velocidad m√°x viento 2 mts altura (m/s)",
  "Precipitaci√≥n total corregida (mm)",
  "Presi√≥n superficial (Pa)"
)

# Preparaci√≥n de datos 

# Filtrar datos v√°lidos (sin valores NA en las variables principales)
df_clean <- df %>%
  filter(
    !is.na(`Radiaci√≥n solar descendente superficie (W/m¬≤)`) &
    !is.na(`Temperatura m√°x 2 mts altura (¬∞c)`) &
    !is.na(`Humedad relativa 2 mts altura (%)`) &
    !is.na(`Velocidad m√°x viento 2 mts altura (m/s)`)
  )

cat("üìä Datos procesados:\n",
    "Registros originales:", nrow(df), "\n",
    "Registros v√°lidos:", nrow(df_clean), "\n",
    "Porcentaje utilizable:", round(nrow(df_clean) / nrow(df) * 100, 1), "%\n\n")

```
<br>

### Personalizaci√≥n para gr√°ficos 
```{r Personalizaci√≥n para graficos}

#Personalizaci√≥n para gr√°ficos
tema_climatico <- theme_minimal() +
  theme(
    plot.title = element_text(size = 9, face = "bold", hjust = 0.5, 
                              color = "#2c3e50", margin = margin(b = 15)),
    plot.subtitle = element_text(size = 7, hjust = 0.5, color = "#7f8c8d", 
                                 margin = margin(b = 20)),
    axis.title = element_text(size = 11, face = "bold", color = "#34495e"),
    axis.text = element_text(size = 10, color = "#5d6d7e"),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_line(color = "#ecf0f1", size = 0.5),
    plot.background = element_rect(fill = "white", color = NA),
    panel.background = element_rect(fill = "#fafbfc", color = NA),
    legend.position = "bottom",
    legend.title = element_text(size = 10, face = "bold"),
    plot.margin = margin(20, 20, 20, 20)
  )

```

<br>

### Gr√°fico 1: radiaci√≥n solar vs temperatura M√°xima
```{r graficos1}

# Dise√±o gr√°fico de radiaci√≥n vs temperatura
p1 <- ggplot(df_clean, aes(x = `Radiaci√≥n solar descendente superficie (W/m¬≤)`, 
                           y = `Temperatura m√°x 2 mts altura (¬∞c)`)) +
  
  # Puntos con transparencia y color
  geom_point(alpha = 0.7, size = 2.5, color = "#FDB813") +
  
  # L√≠nea de tendencia con intervalo de confianza
  geom_smooth(method = "lm", se = TRUE, 
              color = "#E74C3C", fill = "#fadbd8", size = 1.2) +
  
  # Etiquetas y t√≠tulo
  labs(
    title = "Relaci√≥n: Radiaci√≥n Solar vs Temperatura M√°xima",
    x = "Radiaci√≥n Solar Descendente (W/m¬≤)",
    y = "Temperatura M√°xima a 2 mts (¬∞c)"
  ) +

  tema_climatico +
  
  # Formatear escalas
  scale_x_continuous(labels = scales::comma_format()) +
  scale_y_continuous(labels = scales::number_format(suffix = "¬∞C"))

```

<br>

### Correlaci√≥n: radiaci√≥n solar vs temperatura m√°xima
```{r estadistica corr grafico 1}

cor_rad_temp <- cor(df_clean$`Radiaci√≥n solar descendente superficie (W/m¬≤)`, 
                    df_clean$`Temperatura m√°x 2 mts altura (¬∞c)`, 
                    use = "complete.obs",method = "pearson")

cat("üî• RADIACI√ìN SOLAR vs TEMPERATURA M√ÅXIMA\n   ‚Ä¢ Correlaci√≥n:", round(cor_rad_temp, 3), "\n   ‚Ä¢ Interpretaci√≥n:", if(abs(cor_rad_temp) > 0.7) "Correlaci√≥n fuerte" else if(abs(cor_rad_temp) > 0.5) "Correlaci√≥n moderada" else "Correlaci√≥n d√©bil", "\n\n")

```
<br>

### Gr√°fico 2: humedad relativa vs velocidad del viento
```{r graficos 2}
# Dise√±o  gr√°fico de humedad vs viento
p2 <- ggplot(df_clean, aes(x = `Humedad relativa 2 mts altura (%)`, 
                           y = `Velocidad m√°x viento 2 mts altura (m/s)`)) +
  
  geom_point(alpha = 0.7, size = 2.5, color = "#3498db") +
  
  geom_smooth(method = "lm", se = TRUE, 
              color = "#2980b9", fill = "#d6eaf8", size = 1.2) +
  
  # Etiquetas y t√≠tulo
  labs(
    title = "Relaci√≥n: Humedad Relativa vs Velocidad Viento",
    x = "Humedad Relativa a 2 mts (%)",
    y = "Velocidad M√°xima del Viento a 2 mts (m/s)"
  ) +
  
  tema_climatico +
  
  # Formatear escalas
  scale_x_continuous(labels = scales::number_format(suffix = "%")) +
  scale_y_continuous(labels = scales::number_format(suffix = " m/s"))

```

<br>

### Correlaci√≥n: humedad relativa vs velocidad del viento
```{r estadistica corr gragico 2}

cor_hum_viento <- cor(df_clean$`Humedad relativa 2 mts altura (%)`, 
                      df_clean$`Velocidad m√°x viento 2 mts altura (m/s)`, 
                      use = "complete.obs", method = "pearson")


cat("üí® HUMEDAD RELATIVA vs VELOCIDAD DEL VIENTO\n", "   ‚Ä¢ Correlaci√≥n:", round(cor_hum_viento, 3), "\n", "   ‚Ä¢ Interpretaci√≥n:", if(abs(cor_hum_viento) > 0.7) "Correlaci√≥n fuerte" else if(abs(cor_hum_viento) > 0.5) "Correlaci√≥n moderada" else "Correlaci√≥n d√©bil", "\n\n")

```
<br>

### Gr√°ficos de dispersi√≥n: variables clim√°ticas clave
```{r panel_climatico, fig.width=11, fig.height=5.5}

# Crear panel con ambos gr√°ficos
panel_climatico <- grid.arrange(p1, p2, ncol = 2, 
                                top = grid::textGrob(
                                "AN√ÅLISIS DE CORRELACIONES CLIM√ÅTICAS - LA PUNTILLA, PICHILEMU", gp = grid::gpar(fontsize = 15, fontface = "bold", 
                                                  col = "#2c3e50")))

```

<br>

El coeficiente de Pearson se define como:

\[
r = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}
         {\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2} \;
          \sqrt{\sum_{i=1}^{n} (y_i - \bar{y})^2}}
\]

donde: 

- \(0 < r \leq 1 \Rightarrow\)  correlaci√≥n positiva  
- \(-1 \leq r < 0 \Rightarrow\) correlaci√≥n negativa  


El coeficiente de determinaci√≥n se define como:


\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]


la relacion entre \[
R^{2} = r^{2}
\]

<br>
En este caso: 

* $r=0.84 \Rightarrow R^{2}=0.7056 \approx 71\%$ \Rightarrow \text{Radiaci√≥n solar vs temperatura m√°xima}$

* $r=-0.396 \Rightarrow R^{2}=0.1568 \approx 15.7\%$ \Rightarrow \text{Humedad Relativa vs Velocidad del Viento}$

<br>

**Interpretaci√≥n: Radiaci√≥n Solar vs Temperatura M√°xima**

El an√°lisis revela una correlaci√≥n fuerte y positiva de r=0.84 entre la radiaci√≥n solar descendente y la temperatura m√°xima, lo cual confirma el comportamiento f√≠sico esperado entre estas variables meteorol√≥gicas.

Como se observa a mayor radiaci√≥n solar, mayor temperatura. La radiaci√≥n solar constituye la principal fuente de energ√≠a t√©rmica que calienta la superficie terrestre y, por consiguiente, el aire circundante.

Patrones identificados

Patr√≥n diario: Ambas variables presentan un comportamiento conjunto a lo largo del d√≠a, alcanzando sus valores m√°ximos alrededor del mediod√≠a cuando el sol se encuentra en su punto m√°s alto y la radiaci√≥n solar es m√°s intensa.

Patr√≥n estacional: Se observa una variaci√≥n estacional coherente donde ambas variables aumentan durante el verano (mayor incidencia solar) y disminuyen en invierno (menor incidencia solar y d√≠as m√°s cortos).

Conclusi√≥n La correlaci√≥n de r= 0.84 indica que aproximadamente el 71% de la variabilidad en la temperatura m√°xima puede explicarse por la radiaci√≥n solar, confirmando la estrecha relaci√≥n f√≠sico-clim√°tica entre estas variables y validando la calidad de los datos meteorol√≥gicos analizados , por otro lado 29.44% restante se debe a las otras variables no explicadas en el analisis.



**Interpretaci√≥n: Humedad Relativa vs Velocidad del Viento**

El an√°lisis revela una correlaci√≥n d√©bil r=-0.396 entre humedad relativa y velocidad del viento , lo cual confirma el comportamiento f√≠sico esperado entre estas variables meteorol√≥gicas. En la medida que aumenta la humedad relativa ,tienda a disminuir la velocidad del viento ,esta relaci√≥n puede estar modulada por diversos factores atmosf√©ricos que interact√∫an de forma compleja.

Factores f√≠scos relevantes

Estabilidad atmosf√©rica: alta humedad a menudo se asocia con masas de aire m√°s estables , el aire h√∫medo tiende a ser menos turbulento . Menor turbulencia = menores velocidades de viento

Condiciones anticicl√≥nicas:

Los sistemas de alta presi√≥n suelen generar mayor humedad relativa (aire descendente se comprime) Vientos m√°s d√©biles (gradientes de presi√≥n menores)

Conclusi√≥n Aunque existe una tendencia de que los d√≠as m√°s h√∫medos tengan vientos m√°s d√©biles, esta relaci√≥n es inconsistente y est√° influenciada por m√∫ltiples factores meteorol√≥gicos que pueden enmascarar esta tendencia general.

```{r guardado directorio trabajo,fig.width=10, fig.height=5.5,include=FALSE}

library(grid) 

png('panel_climatico.png', 
    width = 10,     # Ancho en pulgadas (coincide con fig.width=10)
    height = 5.5,   # Alto en pulgadas (coincide con fig.height=5.5)
    units = "in",   # ESENCIAL: Establece la unidad a pulgadas
    res = 300)      # Alta resoluci√≥n para calidad

#DIBUJA FORZADAMENTE el panel
grid::grid.draw(panel_climatico) 

#Cierra el dispositivo de guardado
dev.off()

```

```{r include= FALSE}
#Restablecer el layout a gr√°fico por defecto

par(mfrow = c(1, 1))
```

<br>

## Estad√≠sticas descriptivas
```{r estadsitica descripyiva }

variables_analizar <- c("Radiaci√≥n solar descendente superficie (W/m¬≤)",
                       "Temperatura m√°x 2 mts altura (¬∞c)",
                       "Humedad relativa 2 mts altura (%)",
                       "Velocidad m√°x viento 2 mts altura (m/s)")

for(var in variables_analizar) {
  if(var %in% names(df_clean)) {
    valores <- df_clean[[var]]
    cat("\n", toupper(var), ":\n")
    cat("   ‚Ä¢ M√≠nimo    :", round(min(valores, na.rm = TRUE), 2), "\n")
    cat("   ‚Ä¢ M√°ximo    :", round(max(valores, na.rm = TRUE), 2), "\n")
    cat("   ‚Ä¢ Media     :", round(mean(valores, na.rm = TRUE), 2), "\n")
    cat("   ‚Ä¢ Mediana   :", round(median(valores, na.rm = TRUE), 2), "\n")
    cat("   ‚Ä¢ Desv. Est.:", round(sd(valores, na.rm = TRUE), 2), "\n")
  }
}
```
<br>

### C√°lculo correlacci√≥n de Pearson
```{r}

# Seleccionar variables num√©ricas principales
vars_numericas <- df_clean[, variables_analizar]
matriz_cor <- cor(vars_numericas, use = "complete.obs",method = "pearson")

```

<br>

### Construcci√≥n de Dataframe correlaciones significativas
```{r ,escribr en apuntes correcion }
library(knitr)
library(kableExtra)

correlaciones_significativas <- data.frame()

for(i in 1:(ncol(matriz_cor)-1)) {
  for(j in (i+1):ncol(matriz_cor)) {
    cor_val <- matriz_cor[i,j]
    if(abs(cor_val) > 0.3) {

      
correlaciones_significativas <- rbind(correlaciones_significativas, 
                                           data.frame(
                                             Variable1=colnames(matriz_cor)[i],
                                             Variable2=colnames(matriz_cor)[j],
                                             Correlacion = cor_val,
                                             Par = paste(colnames(matriz_cor)[i], "vs", colnames(matriz_cor)[j])
                                           ))
    }
  }
}

```

<br>

### Tabla con correlaciones significativas (|r| > 0.3)
```{r escribir apuntes correcion}

# tabla con marco
correlaciones_significativas %>%
  knitr::kable(
    digits = 2,  # Redondear correlaciones a 2 decimales
    caption = "Correlaciones significativas (|r| > 0.3)"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "bordered"),  # Filas alternadas y marco
    full_width = FALSE,  # Tabla compacta
    position = "center"  # Centrar la tabla
  ) %>%
  column_spec(
    column = 1:ncol(correlaciones_significativas),
    extra_css = "padding-right: 5pt;"  # Padding de 5pt a la derecha
  )

```

<br>

### Matriz de correlaciones significativas
```{r matriz_correlacion_visual ,fig.width=12, fig.height=8 }

# Gr√°fico Comparaci√≥n de magnitudes
correlaciones_significativas$Magnitud <- abs(correlaciones_significativas$Correlacion)
correlaciones_significativas$Tipo <- ifelse(correlaciones_significativas$Correlacion > 0, "Positiva", "Negativa")

g_comparaci√≥n_magnitudes<-ggplot(correlaciones_significativas, aes(x = reorder(Par, Magnitud), 
                                         y = Magnitud)) +
  geom_col(aes(fill = Tipo), width = 0.7, alpha = 0.8) +
  geom_text(aes(label = sprintf("%.3f", Correlacion)), 
            hjust = -0.2, size = 3.6, fontface = "bold") +  # Reducir tama√±o del texto
  scale_fill_manual(values = c("Positiva" = "#2E86AB", "Negativa" = "#A23B72")) +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  coord_flip() +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 13),
    legend.position = "bottom",
    axis.text.y = element_text(size = 11, margin = margin(r = 10)),
    axis.text.x = element_text(size = 11),
    plot.margin = margin(20, 40, 20, 20)
  ) +
  labs(title = "Magnitud de Correlaciones Significativas",
       subtitle = "Ordenado por fuerza de la correlaci√≥n",
       x = "Pares de Variables",
       y = "Magnitud de Correlaci√≥n (Valor Absoluto)")


g_comparaci√≥n_magnitudes

```
<br>

El coeficiente de correlaci√≥n de Pearson se define como:

\[
r = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}
         {\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2} \;
          \sqrt{\sum_{i=1}^{n} (y_i - \bar{y})^2}}
\]


donde:  

- \( 0 < r \leq 1 \;\Rightarrow\; \exists\) correlaci√≥n positiva  
- \(-1 \leq r < 0 \;\Rightarrow\; \exists\) correlaci√≥n negativa

<br>

El coeficiente de determinaci√≥n se define como:


\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]


la relacion entre \[
R^{2} = r^{2}
\]

**Interpetaci√≥n de Correlaciones Clim√°ticas**


El an√°lisis se centr√≥ en dos correlaciones que ilustran patrones atmosf√©ricos fundamentales en los datos satelitales:

***Radiaci√≥n Solar vs Temperatura M√°xima (r = 0.84)***

Esta correlaci√≥n fuerte y positiva es consistente con la relaci√≥n f√≠sica esperada: mayor radiaci√≥n solar genera mayor calentamiento superficial. El valor observado en datos de NASA POWER (MERRA-2) sugiere que los algoritmos de rean√°lisis capturan adecuadamente este acoplamiento termodin√°mico, validando la coherencia interna del dataset.

***Humedad Relativa vs Velocidad del Viento (r = -0.396)***

Se identific√≥ una correlaci√≥n d√©bil y negativa. Este patr√≥n sugiere que condiciones de mayor humedad tienden a asociarse con vientos m√°s d√©biles, posiblemente debido a mayor estabilidad atmosf√©rica o condiciones anticicl√≥nicas en los datos del modelo.

Correlaciones Adicionales Identificadas

***Correlaci√≥n: Radiaci√≥n Solar Descendente vs Humedad Relativa***

\[
r = -0.842 \;\;\Rightarrow\;\; R^{2} = 0.7090 \approx 70.9\%
\]

El an√°lisis revela una correlaci√≥n fuerte y negativa de r = -0.842 entre la radiaci√≥n solar y la humedad relativa, consistente con el comportamiento termodin√°mico esperado.

Patr√≥n observado: A medida que la radiaci√≥n solar aumenta y la superficie se calienta, la temperatura del aire asciende. El c√°lculo de Humedad Relativa sobre aire m√°s c√°lido resulta en valores menores, aunque el contenido absoluto de vapor de agua permanezca constante.

Interpretaci√≥n: Aproximadamente el 71% de la variabilidad en Humedad Relativa se asocia con la radiaci√≥n solar en estos datos. Este patr√≥n indica que el ciclo de calentamiento diurno es un factor dominante en la modulaci√≥n de la humedad relativa capturada por el rean√°lisis satelital.

***Correlaci√≥n: Temperatura M√°xima vs Humedad Relativa***

\[
r = -0.817 \;\;\Rightarrow\;\; R^{2} = 0.6675 \approx 66.8\%
\]

Se observa una correlaci√≥n fuerte y negativa de r = -0.817, confirmando la relaci√≥n inversa esperada.

Patr√≥n observado: Incrementos en Temperatura M√°xima reducen el porcentaje de saturaci√≥n del aire, provocando descensos en la Humedad Relativa. Los d√≠as con temperaturas m√°ximas elevadas corresponden sistem√°ticamente a baja humedad relativa en el dataset.

Nota metodol√≥gica: El R¬≤ ligeramente menor respecto a la radiaci√≥n (66.8% vs 70.9%) puede reflejar efectos de inercia t√©rmica de la masa de aire o desfases temporales en la respuesta de la humedad a cambios de temperatura.

***Correlaci√≥n: Temperatura M√°xima vs Velocidad M√°xima del Viento (2 mts)***

\[
r = 0.418 \;\;\Rightarrow\;\; R^{2} = 0.1747 \approx 17.5\%
\]

El an√°lisis indica una correlaci√≥n baja a moderada y positiva (r = 0.418). Se observa tendencia a que mayores temperaturas coincidan con vientos m√°s intensos.

Interpretaci√≥n f√≠sica posible: En zonas costeras como Pichilemu, el calentamiento solar genera gradientes t√©rmicos tierra-mar que intensifican la brisa marina, resultando en mayores velocidades de viento durante horas c√°lidas. Sin embargo, el bajo R¬≤ (‚âà17.5%) indica que la temperatura local es un factor secundario; el viento est√° principalmente controlado por sistemas sin√≥pticos de presi√≥n a gran escala.

***Correlaci√≥n: Radiaci√≥n Solar Descendente vs Velocidad M√°xima del Viento (2 mts)***

\[
r = 0.403 \;\;\Rightarrow\;\; R^{2} = 0.1624 \approx 16.2\%
\]

Se presenta una correlaci√≥n baja a moderada y positiva (r = 0.403), similar a la relaci√≥n Temperatura-Viento.

Patr√≥n observado: La radiaci√≥n solar proporciona energ√≠a para calentar la superficie y generar diferencias de presi√≥n que impulsan vientos locales (circulaciones t√©rmicas costeras).

Diferencia con temperatura: La correlaci√≥n con Temperatura M√°xima es marginalmente mayor que con radiaci√≥n (r = 0.418 vs r = 0.403). Esto sugiere que la acumulaci√≥n de calor tiene impacto ligeramente m√°s fuerte en velocidad del viento que la radiaci√≥n instant√°nea, indicando un efecto mediado por el calentamiento superficial.

Limitaci√≥n: Estos patrones reflejan asociaciones estad√≠sticas en datos de rean√°lisis satelital. La validaci√≥n de estas relaciones en condiciones reales requerir√≠a comparaci√≥n con mediciones instrumentales in situ.


```{r include= FALSE}

# Restablecer el layout a 1 gr√°fico por defecto
#s una buena pr√°ctica restablecer la configuraci√≥n de los par√°metros gr√°ficos al final. Si no lo haces, cualquier gr√°fico posterior podr√≠a intentar dibujarse en el mismo dise√±o de 1x2, lo cual podr√≠a no ser deseado.
 
par(mfrow = c(1, 1))
```

<br>

## An√°lisis de outliers

Filtrar registros con NA en las variables principales
```{r}

df_analisis <- df %>%
  filter(
    !is.na(`A√±o`) &
    !is.na(`D√≠a del a√±o`) &
    !is.na(`Radiaci√≥n solar descendente superficie (W/m¬≤)`) &
    !is.na(`Radiaci√≥n solar superior atmosfera (W/m¬≤)`) &
    !is.na(`Radiaci√≥n solar directa normal en superficie (W/m¬≤)`) &
    !is.na(`Temperatura 2 mts altura (¬∞c)`) &
    !is.na(`Temperatura h√∫meda 2 mts altura (¬∞c)`) &
    !is.na(`Temperatura m√°x 2 mts altura (¬∞c)`) &
    !is.na(`Temperatura m√≠n 2 mts altura (¬∞c)`) &
    !is.na(`Temperatura m√°x superficie (¬∞c)`) &
    !is.na(`Temperatura m√≠n superficie (¬∞c)`) &
    !is.na(`Contenido vapor agua 2 mts altura (g/m¬≥)`) &
    !is.na(`Humedad relativa 2 mts altura (%)`) &
    !is.na(`Precipitaci√≥n total corregida (mm)`) &
    !is.na(`Presi√≥n superficial (Pa)`) &
    !is.na(`Velocidad m√°x viento 2 mts altura (m/s)`) &
    !is.na(`Velocidad m√≠n viento 2 mts altura  (m/s)`) &
    !is.na(`Velocidad m√°x viento 10 mts altura (m/s)`) &
    !is.na(`Velocidad m√≠n viento 10 mts altura (m/s)`) &
    !is.na(`Humedad perfil suelo(%)`) &
    !is.na(`Radiaci√≥n onda larga superficie (W/m¬≤)`) &
    !is.na(`Temperatura superficie (¬∞c)`)
  )

```

<br>

Verificaci√≥n de NA 
```{r , echo = FALSE}
cat("¬øExisten valores NA despu√©s del filtrado? ", anyNA(df_analisis))

```

De acuerdo a verifcaci√≥n de NA ,significa que no existen valores faltantes (NA) en el conjunto de datos. Esto es clave para garantizar que los procesos de estandarizaci√≥n y modelado (ridge, lasso, elastic net) se ejecuten correctamente sin interrupciones ni sesgos por datos incompletos.

<br>

Eliminar variables para fines pr√°ctico del an√°lisis
```{r delete 4 variables}
df_analisis <- df_analisis %>%
  select(-`A√±o`,
         -`D√≠a del a√±o`,
         -`Radiaci√≥n solar superior atmosfera (W/m¬≤)`,
         -`Temperatura superficie (¬∞c)`)

names(df_analisis)
```
<br>

### Detecci√≥n outliers 

√ötil cuando se quiere evitar que los valores at√≠picos distorsionen el an√°lisis
```{r detecci√≥n de outliers}

detectar_outliers_iqr <- function(df_analisis) {
  outliers <- list()
  
  for (col in names(df_analisis)) {
    if (is.numeric(df_analisis[[col]])) {
      q1 <- quantile(df_analisis[[col]], 0.25, na.rm = TRUE)
      q3 <- quantile(df_analisis[[col]], 0.75, na.rm = TRUE)
      iqr <- q3 - q1
      
      lim_inf <- q1 - 1.5 * iqr
      lim_sup <- q3 + 1.5 * iqr
      
      outlier_indices <- which(df_analisis[[col]] < lim_inf | df_analisis[[col]] > lim_sup)
      
      if (length(outlier_indices) > 0) {
        outliers[[col]] <- outlier_indices
      }
    }
  }
  
  return(outliers)
}

outliers_detectados <- detectar_outliers_iqr(df_analisis)

```

<br>

### Variables con outliers
```{r columnas que tienen outliers,echo=FALSE}

cat(paste0("‚Ä¢ ", names(outliers_detectados), collapse = "\n"), "\n")

```
<br>

### Valores outliers detectados
```{r  OUTLIERS show escribir vrsion cuaderno, echo=FALSE}

for (col in names(outliers_detectados)) {
  # Cantidad de outliers para esa columna
  n_out <- length(outliers_detectados[[col]])
  
  # Encabezado con el nombre y la cantidad entre par√©ntesis
  cat(paste0("‚û°Ô∏è ", col, " (", n_out, "): "), "\n")
  
  # Lista de valores outlier separados por coma
  cat(paste(df_analisis[[col]][outliers_detectados[[col]]], collapse = ", "), "\n\n")
}

```

<br>

### **Decisi√≥n metodol√≥gica** 

Se decidi√≥ mantener los valores at√≠picos identificados, asumiendo que corresponden a eventos meteorol√≥gicos reales capturados por los sensores satelitales de NASA POWER. Sin embargo, al trabajar con datos de rean√°lisis sin validaci√≥n in situ, no es posible verificar con certeza si representan:

- Eventos extremos reales (tormentas, olas de fr√≠o, r√°fagas de viento)
- Artefactos de interpolaci√≥n espacial del modelo MERRA-2
- Variaciones locales no capturadas adecuadamente por la resoluci√≥n espacial (~50km)

Esta decisi√≥n se fundamenta en que los modelos de regularizaci√≥n (Ridge/Lasso/Elastic Net) son robustos ante valores extremos en las variables predictoras. No obstante, se reconoce que outliers en la variable objetivo pueden afectar las estimaciones de los coeficientes.

En este caso valores extremos identificados:

- Precipitaci√≥n: 29 outliers (posibles eventos de lluvia intensa)
- Humedad del suelo: 21 outliers (saturaci√≥n o sequ√≠a extrema)
- Velocidad del viento: 7 outliers (r√°fagas intensas)
- Temperatura m√≠nima: 2 outliers (condiciones de fr√≠o inusual)

```{r ,verificaci√≥n de biliotecas,include= FALSE}

paquetes <- c("dplyr", "tidyr", "ggplot2", "scales")

for (p in paquetes) {
  if (!require(p, quietly = TRUE, character.only = TRUE)) {
    cat("‚ùå No instalado:", p, "\n")
  } else {
    cat("‚úÖ Instalado:", p, "\n")
  }
}

```

<br>

### Resumen estad√≠stico summarise outliers
```{r resumen de summarize personnalizado outliers, escribir cuaderno}

library(dplyr)
library(tidyr)


# üìù Mapeo de nombres largos a nombres cortos
nombres_cortos <- c(
  "Temperatura m√≠n 2 mts altura (¬∞c)" = "Temp M√≠n 2m h (¬∞c)",
  "Precipitaci√≥n total corregida (mm)" = "Precipitaci√≥n total (mm)",
  "Presi√≥n superficial (Pa)" = "Presi√≥n (Pa)",
  "Humedad perfil suelo(%)" = "Humedad Suelo (%)",
  "Velocidad m√°x viento 2 mts altura (m/s)" = "Vel Viento 2m h (m/s) ",
  "Velocidad m√°x viento 10 mts altura (m/s)" = "Vel Viento 10m h (m/s)"
)

# Crear resumen general con comentarios m√°s descriptivos
resumen_outliers <- tibble(
  Variable = unname(nombres_cortos),   # nombre corto de la variable
  Mediana = sapply(names(nombres_cortos), function(col) {
    median(df_analisis[[col]], na.rm = TRUE)
  }),
  Outliers = sapply(names(nombres_cortos), function(col) {
    length(outliers_detectados[[col]])
  }),
  Comentario = sapply(names(nombres_cortos), function(col) {
    n_out <- length(outliers_detectados[[col]])
    mediana_val <- round(median(df_analisis[[col]], na.rm = TRUE), 2)
    
    if (n_out == 0) {
      paste0("La mediana robusta (", mediana_val, 
             ") indica un centro estable, sin valores at√≠picos detectados.")
    } else if (n_out == 1) {
      paste0("La mediana robusta (", mediana_val, 
             ") refleja estabilidad. Se detect√≥ 1 outlier que requiere revisi√≥n.")
    } else if (n_out < 5) {
      paste0("La mediana robusta (", mediana_val, 
             ") es confiable. Se detectaron ", n_out, 
             " outliers que deben manejarse antes de la estandarizaci√≥n.")
    } else {
      paste0("La mediana robusta (", mediana_val, 
             ") sugiere un centro estable, pero se detectaron ", n_out, 
             " valores extremos que pueden distorsionar el an√°lisis.")
    }
  })
)

resumen_outliers %>%
  kable(digits = 2, 
        caption = "Resumen general de variables: Mediana, Outliers y Comentarios",
        format = "markdown") %>%  # Agregar formato HTML para estilos
  kable_styling(
    bootstrap_options = c("striped", "bordered"),  # Agregar bordered para el marco
    full_width = FALSE,
    position = "center"  # Centrar la tabla
  ) %>%
  column_spec(
    column = 1:ncol(resumen_outliers), 
    extra_css = "padding-right: 5pt;"
  )


```
<br>

**Componentes del Boxplot y su Interpretaci√≥n**

Caja Central (Q25 a Q75): Los cuartiles ( Q25 y Q75 ) definen la amplitud de la caja, que contiene el 50% central de los datos.

L√≠nea Mediana (Median): Este valor ( Q2 ) se representa con la l√≠nea divisoria dentro de la caja, indicando la tendencia central robusta de la distribuci√≥n.

Bigotes (Min y Max ajustados): Los valores m√≠nimos y m√°ximos te√≥ricos delimitan los bigotes. Es crucial notar que estos bigotes se ajustan autom√°ticamente a 1.5 veces el Rango Intercuart√≠lico (IQR=Q75‚àíQ25).

√ânfasis en Outliers

La presencia de valores at√≠picos (outliers), visualizados como puntos individuales fuera de los bigotes, ser√° m√°s evidente en los boxplots de aquellas variables que, seg√∫n la detecci√≥n previa, muestran una mayor separaci√≥n entre Min o Max y los extremos de los bigotes calculados. 

Este an√°lisis es fundamental para decidir si es necesario aplicar t√©cnicas de winsorizaci√≥n o transformaci√≥n antes de la estandarizaci√≥n para los modelos Ridge, Lasso, y Elastic Net.

<br>

### Boxplots de variables meteorol√≥gicas por grupos
```{r boxplots_grupos,results='asis',fig.width=12, fig.height=8}


# üìù PASO 1: Nombres m√°s cortos 
nombres_cortos <- c(
  "Radiaci√≥n solar descendente superficie (W/m¬≤)" = "Radiaci√≥n Solar desc (W/m¬≤)",
  "Radiaci√≥n solar directa normal en superficie (W/m¬≤)" = "Rad. Directa (W/m¬≤)",
  "Radiaci√≥n onda larga superficie (W/m¬≤)" = "Rad. Onda Larga (W/m¬≤)",
  "Temperatura 2 mts altura (¬∞c)" = "Temp 2m h (¬∞c)",
  "Temperatura h√∫meda 2 mts altura (¬∞c)" = "Temp H√∫meda (¬∞c)",
  "Temperatura m√°x 2 mts altura (¬∞c)" = "Temp M√°x 2m h (¬∞c)",
  "Temperatura m√≠n 2 mts altura (¬∞c)" = "Temp M√≠n 2m h (¬∞c)",
  "Temperatura m√°x superficie (¬∞c)" = "Temp M√°x Sup (¬∞c)",
  "Temperatura m√≠n superficie (¬∞c)" = "Temp M√≠n Sup (¬∞c)",
  "Contenido vapor agua 2 mts altura (g/m¬≥)" = "Vapor Agua 2m h (g/m¬≥)",
  "Humedad relativa 2 mts altura (%)" = "Humedad Rel 2m h (%)",
  "Precipitaci√≥n total corregida (mm)" = "Precipitaci√≥n total (mm)",
  "Presi√≥n superficial (Pa)" = "Presi√≥n (Pa)",
  "Velocidad m√°x viento 2 mts altura (m/s)" = "Vel Viento 2m h (m/s)",
  "Velocidad m√≠n viento 2 mts altura  (m/s)" = "Vel M√≠n 2m h (m/s)",
  "Velocidad m√°x viento 10 mts altura (m/s)" = "Vel Viento 10m h (m/s)",
  "Velocidad m√≠n viento 10 mts altura (m/s)" = "Vel M√≠n 10m h (m/s)",
  "Humedad perfil suelo(%)" = "Humedad Suelo (%)"
)


# üéØ PASO 2: Definir GRUPOS TEM√ÅTICOS
grupos <- list(
  # GRUPO 1: Variables de TEMPERATURA Y RADIACI√ìN (6 variables)
  temperatura_radiacion = c(
    "Radiaci√≥n Solar desc (W/m¬≤)", "Rad. Directa (W/m¬≤)", "Rad. Onda Larga (W/m¬≤)",
    "Temp 2m h (¬∞c)", "Temp M√°x 2m h (¬∞c)", "Temp M√≠n 2m h (¬∞c)"
  ),
  
  # GRUPO 2: Variables de HUMEDAD Y PRECIPITACI√ìN (6 variables)  
  humedad_precipitacion = c(
    "Temp H√∫meda (¬∞c)", "Vapor Agua 2m h (g/m¬≥)", "Humedad Rel 2m h (%)", 
    "Precipitaci√≥n total (mm)", "Humedad Suelo (%)", "Presi√≥n (Pa)"
  ),
  
  # GRUPO 3: Variables de VIENTO Y TEMPERATURA SUPERFICIAL (6 variables)
  viento_superficie = c(
    "Vel Viento 2m h (m/s)", "Vel M√≠n 2m h (m/s)", "Vel Viento 10m h (m/s)", 
    "Vel M√≠n 10m h (m/s)", "Temp M√°x Sup (¬∞c)", "Temp M√≠n Sup (¬∞c)"
  )
)

# üìä PASO 3: Preparar datos
df_long <- df_analisis %>%
  pivot_longer(everything(), names_to = "variable", values_to = "valor") %>%
  mutate(variables= recode(variable, !!!nombres_cortos))

# üé® FUNCI√ìN para crear boxplots por grupo
crear_boxplot_grupo <- function(datos, variables_grupo, titulo_grupo, color_fill = "lightblue") {
  
  datos_filtrados <- datos %>% 
    filter(variables %in% variables_grupo)
  
  ggplot(datos_filtrados, aes(x = variables, y = valor)) +
    geom_boxplot(
      fill = color_fill,
      color = "black",
      outlier.color = "red",
      outlier.size = 2) +
    facet_wrap(~variables, scales = "free", ncol = 3) +
    theme_bw() +
    theme(axis.text.x = element_blank(),axis.ticks.x = element_blank(),
      strip.text = element_text(size = 11, face = "bold"),
      plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
      plot.subtitle = element_text(size = 10, hjust = 0.5),
      axis.title = element_text(size = 11)) +
    labs(
      title = titulo_grupo,
      subtitle = "Mediana (l√≠nea), Q1-Q3 (caja), rango (bigotes), outliers (puntos rojos)",
      x = "",
      y = "Valores"
    )
}

```

<br>

### Resumen de boxplots
```{r analisis y resumen explicativo boxplot, echo=FALSE}

cat("üìä An√°lisis de distribuci√≥n de variables clim√°ticas\n",
    "Divisi√≥n en 3 grupos tem√°ticos para mejor interpretaci√≥n\n")

# L√≠nea de separaci√≥n
cat("\n") 

cat("üìã Componentes del boxplot:\n","‚Ä¢ L√≠nea negra = Mediana (Q2)\n",
    "‚Ä¢ Caja = Rango intercuart√≠lico (Q1-Q3)\n",
    "‚Ä¢ Bigotes = Rango de datos normales\n",
    "‚Ä¢ Puntos azules = Outliers (valores at√≠picos)\n",
    "‚Ä¢ Eje X = Variables analizadas\n",
    "‚Ä¢ Eje Y = Valores de la variable\n")
```

<br>

## Visualizaci√≥n de distribuciones mediante boxplots
### Boxplots grupo 1: temperatura y radiaci√≥n
```{r ,echo = FALSE, fig.width=12, fig.height=8}

cat("üå°Grupo 1 : Temperatura y Radiaci√≥n\n",
    "Variables que miden calor y energ√≠a solar\n",
    "Incluye: Radiaci√≥n solar, temperaturas ambientales\n")

var_int <- "Temperatura m√≠n 2 mts altura (¬∞c)"
var_corta <- recode(var_int, !!!nombres_cortos)

# Boxplot Grupo 1
df_plot <- df_long %>% filter(variables %in% grupos$temperatura_radiacion)

# Outliers solo de la variable espec√≠fica (mant√©n l√≥gica original)
outliers_df <- data.frame(
  variables = var_corta,
  valor = df_analisis[[var_int]][outliers_detectados[[var_int]]],
  label = length(outliers_detectados[[var_int]]),
  stringsAsFactors = FALSE
)

texto_outliers <- data.frame(
  variables = var_corta,
  valor = df_analisis[[var_int]][outliers_detectados[[var_int]]][1], # Usar posici√≥n del primer outlier
  label = paste0(length(outliers_detectados[[var_int]]), " Outliers"),
  stringsAsFactors = FALSE
)

# Gr√°fico con texto de outliers agregado
boxplot1 <-ggplot(df_plot, aes(x = variables, y = valor)) +
  geom_boxplot(outlier.shape = NA, fill = "lightcoral", color = "black") +
  facet_wrap(~variables, scales = "free", ncol = 3) +
  theme_bw() +
  theme(axis.text.x = element_blank(),
        axis.ticks.x = element_blank(),
        strip.text = element_text(size = 11, face = "bold"),
        plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
        axis.title = element_text(size = 11)) +
  labs(title = "GRUPO 1: Variables de Temperatura y Radiaci√≥n",
       subtitle = "Bigotes: rango, Caja: Q1-Q3, Mediana: l√≠nea central",
       x = "", y = "Valores") +
  geom_point(data = outliers_df, aes(x = variables, y = valor),
             color = "blue", size = 3) +
  # TEXTO CON CANTIDAD DE OUTLIERS EN LA MISMA POSICI√ìN QUE LOS PUNTOS
  geom_text(data = texto_outliers, aes(x = variables, y = valor, label = label),
            hjust = -0.2, color = "blue", fontface = "bold", size = 3.5)
print(boxplot1)

```

**üìä An√°lisis de Tendencia Central, Dispersi√≥n, Sesgo y Outliers**

El an√°lisis se centra en la tendencia central (Q2), la dispersi√≥n (IQR), y la detecci√≥n de asimetr√≠a (sesgo) y valores at√≠picos (outliers), elementos cr√≠ticos para la fase previa a la estandarizaci√≥n y selecci√≥n de variables en modelos de regularizaci√≥n como Ridge, Lasso y Elastic Net.

üå°Ô∏è Tendencia Central, Dispersi√≥n y Sesgo

- Temp Min 2m h (Temperatura m√≠nima a 2 mts de altura):
Presenta una mediana de 10.66‚ÄØ¬∞C, lo que indica un valor central robusto y estable. Sin embargo, se identifican dos outliers por debajo del rango inferior, lo que sugiere mediciones aisladas en condiciones extremas. Dada su estabilidad general y relevancia f√≠sica, esta variable es una fuerte candidata como feature predictiva en modelos de machine learning.

- Rad. Directa, Rad. Onda Larga, Radiaci√≥n Solar Descendente, Temp 2m h, Temp M√°x 2m h
Todas estas variables muestran una dispersi√≥n controlada, sin presencia de outliers.

- Temp M√°x 2m h presenta un ligero sesgo, con la mediana desplazada hacia el borde inferior del IQR, lo que indica una leve asimetr√≠a.

- Las variables de radiaci√≥n exhiben mayor variabilidad (cajas m√°s anchas), lo que refleja fluctuaciones naturales en la intensidad de radiaci√≥n solar y atmosf√©rica.
Este an√°lisis confirma la diversidad de escalas y distribuciones dentro del conjunto, lo que refuerza la necesidad de un tratamiento uniforme previo a la modelizaci√≥n.

‚ö†Ô∏è Impacto de los Valores At√≠picos (Outliers) en la Modelizaci√≥n
Se identificaron dos outliers, ambos en la variable Temp Min 2m h. Las dem√°s variables no presentan valores at√≠picos visibles en la gr√°fica.
La presencia de estos outliers, junto con las diferencias de escala entre las variables de temperatura y radiaci√≥n, hace obligatorio el paso de estandarizaci√≥n. Este proceso es esencial para que las penalizaciones L1 (Lasso) y L2 (Ridge) operen correctamente sobre un espacio de features uniforme, asegurando una selecci√≥n y ajuste de coeficientes robusto en los modelos de regularizaci√≥n.

```{r include= FALSE}

par(mfrow = c(1, 1))

```

<br>

### Boxplots grupo 2: humedad y precipitaci√≥n
```{r,echo = FALSE, fig.width=12, fig.height=8}

cat("üíß Grupo 2: Humedad y Precipitaci√≥n \n",
    "Variables que miden agua en la atm√≥sfera\n", 
    "Incluye: Humedad, precipitaci√≥n, presi√≥n atmosf√©rica\n")

variables_outliers <- c("Humedad Suelo (%)", "Precipitaci√≥n total (mm)", "Presi√≥n (Pa)")

boxplot_grupo_outliers <- function(df_long, variables_grupo, titulo, color_fill = "lightcoral") {
  df_plot <- df_long %>% filter(variables %in% variables_grupo)
  
  p <- ggplot(df_plot, aes(x = variables, y = valor)) +
    geom_boxplot(outlier.shape = NA, fill = color_fill, color = "black") +
    facet_wrap(~variables, scales = "free", ncol = 3) +
    theme_bw() +
    theme(axis.text.x = element_blank(), axis.ticks.x = element_blank(),
          strip.text = element_text(size = 11, face = "bold"),
          plot.title = element_text(size = 14, face = "bold", hjust = 0.5)) +
  labs(title = "GRUPO 2: Variables de Humedad y Precipitaci√≥n total",
       subtitle = "Bigotes: rango, Caja: Q1-Q3, Mediana: l√≠nea central",
       x = "", y = "Valores")
  
  for(var in variables_outliers[variables_outliers %in% variables_grupo]) {
    valores <- df_plot %>% filter(variables == var) %>% pull(valor)
    Q1 <- quantile(valores, 0.25, na.rm = TRUE)
    Q3 <- quantile(valores, 0.75, na.rm = TRUE)
    outliers_vals <- valores[valores < Q1 - 1.5*(Q3-Q1) | valores > Q3 + 1.5*(Q3-Q1)]
    
    if(length(outliers_vals) > 0) {
      p <- p + geom_point(data = data.frame(variables = var, valor = outliers_vals), 
                         aes(x = variables, y = valor), color = "blue", size = 2) +
              geom_text(data = data.frame(variables = var, valor = max(valores), 
                       label = paste0("Outliers: ", length(outliers_vals))),
                       aes(x = variables, y = valor, label = label), 
                       vjust = 1.5, color = "blue", fontface = "bold", size = 3.5)
    }
  }
  return(p)
}

boxplot_hum_prec <-boxplot_grupo_outliers(df_long, grupos$humedad_precipitacion, 
  "GRUPO 2: Variables de Humedad y Precipitaci√≥n total", color_fill = "#B0C4DE")

print(boxplot_hum_prec)

```

**üíß An√°lisis de Tendencia Central, Dispersi√≥n, Sesgo y Outliers**

El an√°lisis se centra en la tendencia central (Q2), la dispersi√≥n (IQR), y la detecci√≥n de asimetr√≠a (sesgo) y valores at√≠picos (outliers), elementos cr√≠ticos para la fase previa a la estandarizaci√≥n y selecci√≥n de variables en modelos de regularizaci√≥n como Ridge, Lasso y Elastic Net.

üå°Ô∏è Tendencia Central, Dispersi√≥n y Sesgo

- Precipitaci√≥n Total
Presenta una mediana de 0.02 mm, lo que indica que la mayor√≠a de los registros corresponden a d√≠as sin lluvia. Se identifican 29 outliers hacia el extremo superior, reflejando eventos de precipitaci√≥n intensa. Este sesgo extremo hacia la derecha sugiere una distribuci√≥n altamente asim√©trica, t√≠pica en variables pluviom√©tricas. Su tratamiento previo es indispensable para evitar distorsiones en la modelizaci√≥n.

- Humedad del Suelo
Con una mediana de 0.52 m¬≥/m¬≥, esta variable muestra una distribuci√≥n relativamente estable, aunque se detectan 21 outliers que podr√≠an representar condiciones de saturaci√≥n o sequ√≠a inusuales. El IQR es estrecho, lo que indica baja dispersi√≥n en condiciones normales. Su comportamiento f√≠sico la convierte en una variable relevante para modelos predictivos.

- Presi√≥n Superficial
La mediana se sit√∫a en 99.90 kPa, con una distribuci√≥n bastante sim√©trica y baja dispersi√≥n. No obstante, se identifican 4 outliers, posiblemente asociados a eventos meteorol√≥gicos extremos como sistemas de baja o alta presi√≥n. Aunque su escala es distinta al resto, su estabilidad la hace √∫til tras estandarizaci√≥n.

estas 3 variable son fuertes candidata como feature predictiva en modelos de machine learning.

- Humedad Relativa 2m h, Temp H√∫meda y Vapor Agua 2m h
Estas tres variables no presentan outliers visibles en la gr√°fica.

- Humedad Relativa muestra una distribuci√≥n compacta, con valores altos y estables.

- Temperatura H√∫meda y Vapor de Agua presentan distribuciones sim√©tricas y controladas, con medianas coherentes con condiciones atmosf√©ricas normales.

Estas variables, por su estabilidad y ausencia de valores extremos, son buenas candidatas para modelizaci√≥n directa tras estandarizaci√≥n.
Este an√°lisis confirma la diversidad de escalas, simetr√≠as y dispersi√≥n entre las variables del grupo, lo que refuerza la necesidad de un tratamiento uniforme previo a la modelizaci√≥n.

‚ö†Ô∏è Impacto de los Valores At√≠picos (Outliers) en la Modelizaci√≥n
Se identificaron 54 outliers en total, distribuidos en:
- Precipitaci√≥n Total (29)
- Humedad del Suelo (21)
- Presi√≥n (4)

La presencia de estos valores extremos, junto con las diferencias de escala entre las variables de humedad, presi√≥n y precipitaci√≥n, hace obligatorio el paso de estandarizaci√≥n. Este proceso es esencial para que las penalizaciones L1 (Lasso) y L2 (Ridge) operen correctamente sobre un espacio de features uniforme, asegurando una selecci√≥n y ajuste de coeficientes robusto en los modelos de regularizaci√≥n.

```{r include= FALSE}

par(mfrow = c(1, 1))

```

<br>

### Boxplots grupo 3: viento y temperatura superficial 
```{r,echo = FALSE, fig.width=12, fig.height=8}

cat("üå¨Ô∏è GRUPO 3: Viento y  Temperatura Superficial\n",
    "Variables que miden movimiento del aire y temperatura del suelo\n",
    "Incluye: Velocidades de viento, temperaturas superficiales\n")

boxplot_viento_sup <- crear_boxplot_grupo(
  df_long, 
  grupos$viento_superficie, 
  "GRUPO 3: Variables de Viento y Temperatura Superficial",
  color_fill = "lightgreen"
)

# Variables que quieres mostrar outliers (solo las 2 que tienen outliers)
variables_con_outliers <- c("Vel Viento 10m h (m/s)", "Vel Viento 2m h (m/s)")

# Agregar outliers al gr√°fico existente
df_plot <- df_long %>% filter(variables %in% grupos$viento_superficie)

for(var in variables_con_outliers) {
  valores <- df_plot %>% filter(variables == var) %>% pull(valor)
  Q1 <- quantile(valores, 0.25, na.rm = TRUE)
  Q3 <- quantile(valores, 0.75, na.rm = TRUE)
  IQR <- Q3 - Q1
  outliers_vals <- valores[valores < Q1 - 1.5*IQR | valores > Q3 + 1.5*IQR]
  
  if(length(outliers_vals) > 0) {
    outliers_data <- data.frame(variables = var, valor = outliers_vals)
    boxplot_viento_sup <- boxplot_viento_sup + 
      geom_point(data = outliers_data, aes(x = variables, y = valor), 
                 color = "blue", size = 3)
    
    text_data <- data.frame(variables = var, valor = outliers_vals[1], 
                           label = paste0(length(outliers_vals), " Outliers"))
    boxplot_viento_sup <- boxplot_viento_sup + 
      geom_text(data = text_data, aes(x = variables, y = valor, label = label),
                hjust = -0.2, color = "blue", fontface = "bold", size = 3)
  }
}

boxplot_viento_sup <- boxplot_viento_sup +
  labs(title = "GRUPO 3: Variables de viento y Temperatura superficial",
       subtitle = "Bigotes: rango, Caja: Q1-Q3, Mediana: l√≠nea central",
       x = "", y = "Valores") +
  theme(plot.subtitle = element_text(hjust = 0)) 

print(boxplot_viento_sup)

```
<br>

**üí® An√°lisis de Tendencia Central, Dispersi√≥n, Sesgo y Outliers**

El an√°lisis se centra en la tendencia central (Q2), la dispersi√≥n (IQR), y la detecci√≥n de asimetr√≠a (sesgo) y valores at√≠picos (outliers), elementos cr√≠ticos para la fase previa a la estandarizaci√≥n y selecci√≥n de variables en modelos de regularizaci√≥n como Ridge, Lasso y Elastic Net.

üå°Ô∏è Tendencia Central, Dispersi√≥n y Sesgo

- Vel Viento 10m h
Presenta una distribuci√≥n moderadamente dispersa, con una mediana coherente con velocidades t√≠picas a esa altura. Se identifican 3 outliers hacia el extremo superior, lo que sugiere la presencia de r√°fagas intensas o eventos meteorol√≥gicos puntuales. El sesgo es leve, pero su tratamiento es necesario para evitar distorsiones en la modelizaci√≥n.

- Vel Viento 2m h
Exhibe una mediana estable, aunque se detectan 4 outliers que podr√≠an corresponder a condiciones de viento an√≥malas a baja altura. La dispersi√≥n es moderada y el sesgo es leve. Estos valores extremos deben ser gestionados antes de aplicar modelos de regularizaci√≥n.

- Temp M√°x Sup, Temp M√≠n Sup, Vel M√≠n 10m h, Vel M√≠n 2m h
Estas cuatro variables no presentan outliers visibles en la gr√°fica.

- Las temperaturas superficiales muestran distribuciones sim√©tricas y estables, con medianas representativas del comportamiento t√©rmico t√≠pico.

- Las velocidades m√≠nimas del viento, tanto a 10‚ÄØm como a 2‚ÄØm, presentan IQRs estrechos, lo que indica baja variabilidad y condiciones de calma frecuentes.
Estas variables, por su estabilidad y ausencia de valores extremos, son buenas candidatas para modelizaci√≥n directa tras estandarizaci√≥n.
Este an√°lisis confirma la diversidad de escalas, simetr√≠as y dispersi√≥n entre las variables del grupo, lo que refuerza la necesidad de un tratamiento uniforme previo a la modelizaci√≥n.

‚ö†Ô∏è Impacto de los Valores At√≠picos (Outliers) en la Modelizaci√≥n
Se identificaron 7 outliers en total, distribuidos en:

- Vel Viento 10m h (3)
- Vel Viento 2m h (4)

La presencia de estos valores extremos, junto con las diferencias de escala entre las variables de viento y temperatura, hace obligatorio el paso de estandarizaci√≥n. Este proceso es esencial para que las penalizaciones L1 (Lasso) y L2 (Ridge) operen correctamente sobre un espacio de features uniforme, asegurando una selecci√≥n y ajuste de coeficientes robusto en los modelos de regularizaci√≥n.

```{r include= FALSE}

par(mfrow = c(1, 1))

```

<br>

### Visualizaci√≥n de la matriz de correlaci√≥n
```{r matriz_completa, fig.width=12, fig.height=10}

library(ggcorrplot)

# Calcular matriz de correlaci√≥n
cor_matrix <- cor(df_analisis, use = "complete.obs")


matrix_correlaccion<-ggcorrplot(cor_matrix, 
           hc.order = TRUE, 
           type = "lower",
           lab = TRUE, 
           lab_size = 3.5,#Aumenta el tama√±o de la etiqueta para leer mejor
           tl.srt = 45, #Gira las etiquetas de las filas 45 grados
           title = "Correlaciones entre Variables Clim√°ticas")

matrix_correlaccion
```

**üß† Analisis de Matriz de Correlaci√≥n y Justificaci√≥n de Modelos de Regularizaci√≥n**

A partir del an√°lisis de la matriz de correlaci√≥n entre variables clim√°ticas, se confirma la existencia de redundancia significativa y multicolinealidad dentro de varios grupos de predictores. La presencia de correlaciones muy fuertes (positivas y negativas, cercanas a ¬±1) podr√≠a comprometer la estabilidad y la precisi√≥n de modelos predictivos tradicionales como la Regresi√≥n por M√≠nimos Cuadrados Ordinarios (OLS).

***Relaciones fuertemente positivas (correlaci√≥n cercana a +1)*** 

- Las variables de temperatura m√°xima, m√≠nima y promedio a 2 metros presentan una correlaci√≥n muy alta entre s√≠, lo que indica que comparten gran parte de la informaci√≥n. Esto sugiere que puede seleccionarse una sola como representativa del grupo. - La radiaci√≥n solar descendente en superficie muestra una correlaci√≥n elevada con la temperatura m√°xima y la temperatura superficial, lo cual es coherente con el efecto directo de la radiaci√≥n sobre el calentamiento del suelo y del aire. - La temperatura de bulbo h√∫medo y la humedad relativa tambi√©n est√°n estrechamente relacionadas, ya que ambas dependen del contenido de vapor de agua en el aire.

**Relaciones negativas (correlaci√≥n cercana a -1)**

- La humedad relativa tiende a correlacionarse negativamente con la temperatura m√°xima, reflejando que en condiciones m√°s c√°lidas el aire suele estar m√°s seco. - La presi√≥n superficial muestra correlaciones negativas con variables como la precipitaci√≥n y la velocidad del viento, lo que es caracter√≠stico de sistemas de baja presi√≥n asociados a borrascas y fen√≥menos inestables.

**Variables con baja correlaci√≥n (cercanas a 0)** 

- Algunas variables como la precipitaci√≥n presentan correlaciones d√©biles con la temperatura, lo que indica que su comportamiento est√° m√°s influenciado por la din√°mica atmosf√©rica que por el calentamiento directo.

<br>

```{r include= FALSE}
 
par(mfrow = c(1, 1))

```
### Conclusi√≥n del preprocesamiento de datos 

El an√°lisis exploratorio revel√≥ patrones clim√°ticos coherentes con la f√≠sica atmosf√©rica costera. La correlaci√≥n fuerte entre radiaci√≥n solar y temperatura m√°xima (r = 0.84, R¬≤ ‚âà 71%) confirma el acoplamiento termodin√°mico en los datos MERRA-2, mientras que correlaciones adicionales identificaron redundancia significativa entre grupos de variables (temperaturas, radiaciones, humedades), justificando plenamente el uso de m√©todos de regularizaci√≥n. Las visualizaciones mediante boxplots tem√°ticos facilitaron la interpretaci√≥n de distribuciones y asimetr√≠as, confirmando que variables como precipitaci√≥n y humedad del suelo exhiben sesgo extremo caracter√≠stico del clima mediterr√°neo costero.

La detecci√≥n sistem√°tica identific√≥ 63 outliers distribuidos en seis variables meteorol√≥gicas, representando posibles eventos extremos reales capturados por el rean√°lisis satelital. Se decidi√≥ conservarlos, dado que los modelos de regularizaci√≥n son generalmente robustos frente a valores at√≠picos en los predictores y pueden incorporar su influencia sin distorsionar significativamente las estimaciones de los coeficientes.

El an√°lisis exploratorio tambi√©n evidenci√≥ amplias diferencias de escala entre variables (por ejemplo, ¬∞C frente a Pascales), lo que anticipa la necesidad de aplicar una estandarizaci√≥n z-score. Esta transformaci√≥n ‚Äîesencial en la mayor√≠a de los m√©todos de aprendizaje autom√°tico‚Äî garantiza que las penalizaciones L1 y L2 act√∫en sobre un espacio num√©ricamente homog√©neo, evitando la dominancia artificial de variables con magnitudes mayores.

<br>

# Modelado predictivo de machine learning

**Fundamentos Te√≥ricos**

Definici√≥n: hiperpar√°metro es un par√°metro de control de alto nivel definido antes del entrenamiento que define la estructura y complejidad del modelo, sin derivarse de los datos.

Ejemplos en este proyecto:

- $\lambda$ (lambda): Intensidad de penalizaci√≥n ($0 \leq \lambda < \infty$)

- $\alpha$ (alpha): Mezcla L1/L2 en Elastic Net ($0 \leq \alpha \leq 1$)

- $k$: N√∫mero de pliegues en validaci√≥n cruzada

***Diferencia con par√°metros***: Los coeficientes $\beta_0, \beta_1, \ldots, \beta_p$ se estiman durante el entrenamiento; los hiperpar√°metros se fijan previamente mediante t√©cnicas como validaci√≥n cruzada.

***Funci√≥n Objetivo General***

Los m√©todos de regularizaci√≥n minimizan:

$$
\min_{\beta} \left[ \underbrace{\frac{1}{2n} \sum_{i=1}^{n} \left( y_i - \beta_0 - \sum_{j=1}^{p} \beta_j x_{ij} \right)^2}_{\text{P√©rdida (MSE)}} + \underbrace{\lambda \mathcal{R}(\beta)}_{\text{Penalizaci√≥n}} \right]
$$
<br>

Donde:

- P√©rdida: Mide error en datos de entrenamiento

- $\mathcal{R}(\beta)$: Funci√≥n de penalizaci√≥n (var√≠a seg√∫n m√©todo)

- $\lambda \geq 0$: Controla trade-off entre sesgo-varianza

<br>

**M√©todos de Regularizaci√≥n**

***Ridge (Penalizaci√≥n $L_2$)***

Definici√≥n Regresi√≥n Ridge (Regresi√≥n de Cresta): M√©todo de regularizaci√≥n L2 que estabiliza y mejora la precisi√≥n de modelos de regresi√≥n lineal mediante penalizaci√≥n cuadr√°tica. Reduce (shrinkage) la magnitud de los coeficientes de regresi√≥n acerc√°ndolos a cero sin forzarlos a ser exactamente cero, lo que disminuye la complejidad del modelo, mejora su estabilidad y aumenta la capacidad de generalizaci√≥n. Es especialmente √∫til cuando la mayor√≠a de las variables aportan informaci√≥n relevante.

Funci√≥n objetivo:
$$
\hat{\beta}^{\text{ridge}} = \arg\min_{\beta} \left\{ \sum_{i=1}^{N} \left( y_i - \beta_0 - \sum_{j=1}^{p} x_{ij}\beta_j \right)^2 + \lambda \sum_{j=1}^{p} \beta_j^2 \right\}
$$

en t√©rminos matriciales(centrado, sin intercepto):
$$
\hat{\beta}^{\text{ridge}} = (X^T X + \lambda I)^{-1} X^T y
$$

***Propiedades***:

- ***Ventaja***: Estabiliza estimaciones con multicolinealidad

- ***Limitaci√≥n***: Retiene todas las variables (no selecciona)

- ***Efecto***: Al aumentar $\lambda$ ‚Üí coeficientes se reducen en magnitud (pero no se vuelven cero)

<br>

***Lasso (Penalizaci√≥n $L_1$)***

Definici√≥n Lasso (Least Absolute Shrinkage and Selection Operator): M√©todo de regularizaci√≥n L1 que realiza selecci√≥n autom√°tica de variables forzando coeficientes exactamente a cero. Mejora simult√°neamente la precisi√≥n de predicci√≥n y la interpretabilidad de modelos de regresi√≥n lineal mediante penalizaci√≥n que elimina efectivamente las variables menos importantes del modelo, siendo especialmente √∫til cuando existen variables poco relevantes.

Funci√≥n objetivo:
$$
\hat{\beta}^{\text{lasso}} = \arg\min_{\beta} \left\{ \frac{1}{2} \sum_{i=1}^{N} \left( y_i - \beta_0 - \sum_{j=1}^{p} x_{ij}\beta_j \right)^2 + \lambda \sum_{j=1}^{p} |\beta_j| \right\}
$$

Forma restringida equivalente:
$$
\text{sujeto a } \sum_{j=1}^{p} |\beta_j| \leq t
$$

***Propiedades***:

- **t** L√≠mite positivo que controla la magnitud total de los coeficientes.
Cuanto menor es t, mayor es la regularizaci√≥n y m√°s simple el modelo

- ***Ventaja***: Genera modelos interpretables (menos variables)

- ***Limitaci√≥n***: Inestable con variables altamente correlacionadas

- ***Efecto***: Mayor $\lambda$ ‚Üí m√°s coeficientes se hacen 0

<br>

**Elastic Net (Combinaci√≥n $L_1 + L_2$)**

Definici√≥n Elastic Net: M√©todo de regularizaci√≥n h√≠brido que combina las fortalezas de Ridge y Lasso mediante penalizaci√≥n dual (L1 + L2). Realiza selecci√≥n autom√°tica de variables forzando coeficientes irrelevantes a cero (como Lasso), mientras simult√°neamente agrupa y reduce los coeficientes de predictores altamente correlacionados para mejorar la estabilidad num√©rica (como Ridge). Ideal cuando existen grupos de variables correlacionadas y se requiere tanto selecci√≥n como estabilidad.

Funci√≥n objetivo:
$$
\min_{\beta} \left\| y - X\beta \right\|_2^2 + \lambda \left[ \alpha \sum_{j=1}^{p} |\beta_j| + (1 - \alpha) \sum_{j=1}^{p} \beta_j^2 \right]
$$

***Par√°metro de mezcla*** $\alpha \in [0,1]$:

- $\alpha = 0$: Ridge puro (no selecciona variables)

- $\alpha = 1$: Lasso puro (m√°xima selecci√≥n)

- $0 < \alpha < 1$: Combinaci√≥n balanceada

***Propiedades***:

- ***Ventaja***: Selecciona variables sin perder estabilidad

- ***Ideal para***: Datos con grupos de predictores correlacionados


<br>

**Comparaci√≥n de M√©todos**

| Criterio | Ridge | Lasso | Elastic Net |
|----------|-------|-------|-------------|
| **Penalizaci√≥n** | $\sum \beta_j^2$ | $\sum \|\beta_j\|$ | $\alpha \sum \|\beta_j\| + (1-\alpha) \sum \beta_j^2$ |
| **Selecci√≥n de variables** | ‚ùå No | ‚úÖ S√≠ | ‚úÖ S√≠ (moderada) |
| **Multicolinealidad** | ‚úÖ Excelente | ‚ö†Ô∏è Inestable | ‚úÖ Buena |
| **Coeficientes** | Peque√±os $\neq 0$ | Algunos = 0 | Algunos = 0 |
| **Soluci√≥n** | Cerrada | Iterativa | Iterativa |
| **Aplicaci√≥n** | Todas relevantes | Pocas importantes | Correlaciones complejas |

<br>


**Optimizaci√≥n en machine learning**

Definici√≥n: optimizaci√≥n es el proceso de encontrar los par√°metros $\theta \in \mathbb{R}^p$ que minimizan una funci√≥n objetivo $\mathcal{J}(\theta)$, garantizando el mejor ajuste del modelo a datos de entrenamiento mientras se preserva la generalizaci√≥n en datos no vistos.

Formulaci√≥n General:

$$\theta^* = \arg\min_{\theta} \left[ \mathcal{L}(\theta) + \lambda \mathcal{R}(\theta) \right]$$
<br>

| Componente | Rol | Ejemplo Proyecto |
|:-----------|:----|:-----------------|
| $\mathcal{L}(\theta)$ | P√©rdida (error entrenamiento) | $\frac{1}{2n} \|y - X\beta\|_2^2$ |
| $\mathcal{R}(\theta)$ | Regularizaci√≥n (control complejidad) | $\alpha \|\beta\|_1 + (1-\alpha)\|\beta\|_2^2$ |
| $\lambda \geq 0$ | Hiperpar√°metro (trade-off entre sesgo-varianza) | $\lambda^* = 0.001234$ |

<br>

Caracter√≠sticas Clave

| Propiedad | Descripci√≥n | Implicaci√≥n |
|:----------|:------------|:------------|
| Continua | $\theta \in \mathbb{R}^p$ (no discreta) | Gradientes definidos |
| Convexa | $\mathcal{J}(\theta)$ convexa $\Rightarrow$ m√≠nimo global √∫nico | $\checkmark$ Garantizado en Elastic Net |
| Diferenciable | $\nabla \mathcal{J}(\theta)$ existe (excepto $\beta_j=0$ en L1) | Descenso coordenadas |
| Restringida | Multiplicadores de Lagrange | Forma dual Lasso |

<br>

**Algoritmo fundamental: coordinate descent**

$$\beta_j^{(k+1)} = \arg\min_{\beta_j} \mathcal{J}\left(\beta_{-j}^{(k)}, \beta_j\right)$$
**M√©todos de regularizaci√≥n como problemas convexos**

| M√©todo | Funci√≥n Objetivo | Soluci√≥n | Convexidad | Proyecto |
|:-------|:-----------------|:---------|:-----------|:---------|
| Ridge | $\|y-X\beta\|_2^2 + \lambda \|\beta\|_2^2$ | Cerrada: $(X^TX + \lambda I)^{-1}X^Ty$ | $\checkmark$ | $\alpha=0$ |
| Lasso | $\|y-X\beta\|_2^2 + \lambda \|\beta\|_1$ | Iterativa: LARS | $\checkmark$ | $\alpha=1$ |
| Elastic Net | $\|y-X\beta\|_2^2 + \lambda[\alpha\|\beta\|_1 + (1-\alpha)\|\beta\|_2^2]$ | Iterativa: Coordinate Descent | $\checkmark$ | $\alpha^*=0.10$ |

$\alpha \in [0,1]$: Mezcla L1 (selecci√≥n) + L2 (estabilidad)

<br>

**Problema de optimizaci√≥n**

Los tres m√©todos resuelven problemas **convexos** (garantizan √≥ptimo global √∫nico):

***Ridge***: 

- Funci√≥n objetivo diferenciable ‚Üí soluci√≥n anal√≠tica

- Costo computacional: $O(p^3)$ (inversi√≥n matricial)

***Lasso***: 

- No diferenciable en $\beta_j = 0$ ‚Üí algoritmos iterativos (LARS, coordinate descent)

- Selecciona variables durante optimizaci√≥n

***Elastic Net***: 

- Combina ambos enfoques

- Algoritmo eficiente para grillas de $\alpha$ y $\lambda$

<br>

**Validaci√≥n cruzada (Cross-Validation)**

Definici√≥n:T√©cnica estad√≠stica que estima el error de predicci√≥n de un modelo reutilizando los mismos datos para entrenamiento y evaluaci√≥n de forma iterativa.
Permite aprovechar eficientemente conjuntos de datos limitados, aproximando el error esperado(Err) que se obtendr√≠a en muestras independientes provenientes de la misma distribuci√≥n, sin comprometer el conjunto de prueba final.



Mec√°nica de $K$-Fold Cross-Validation

Procedimiento:

1.Partici√≥n: Dividir datos en $K$ pliegues (folds) de tama√±o $\approx n/K$

2.Iteraci√≥n: Ajustar el modelo $K$ veces. En cada iteraci√≥n $i$:
$$
\left.
\begin{cases}
\text{Entrenar: } K - 1 \text{ pliegues}, \\
\text{Validar: } 1 \text{ pliegue restante} \rightarrow \text{calcular } \text{MSE}_i
\end{cases}
\right\}
$$

3.Estimaci√≥n final:
   $$
   CV(\hat{f}, \alpha) = \frac{1}{K} \sum_{i=1}^{K} \text{MSE}_i
   $$

Valores t√≠picos: $K = 5$ o $10$ (equilibrio sesgo-varianza). Caso extremo: $K = N \rightarrow$ **Leave-One-Out CV (LOOCV)**.

<br>

**Aplicaciones en selecci√≥n de modelos**

1. Estimaci√≥n de error de generalizaci√≥n:
   Aproxima el rendimiento en datos no vistos sin usar el conjunto de prueba.

2. Optimizaci√≥n de hiperpar√°metros:  
   Para modelos indexados por $\alpha$ (ej: $\lambda$ en regularizaci√≥n):
   $$
   \alpha^* = \arg\min_{\alpha} CV(\hat{f}, \alpha)
   $$

3. Criterios de selecci√≥n:

   - **$\lambda_{\text{min}}$:** Minimiza $CV(\lambda) \rightarrow$ m√°xima precisi√≥n
   
   - **Regla 1-SE:** Modelo m√°s simple con $CV(\lambda_{1\text{-SE}}) \leq CV(\lambda_{\text{min}}) + SE \rightarrow$ parsimonia

4. Regularizaci√≥n: 

   Determina par√°metros de complejidad: $\lambda$ en Ridge/Lasso, $C$ en SVM, $(\alpha, \lambda)$ en Elastic Net.


<br>

**Justificaci√≥n metodol√≥gica:** La validaci√≥n cruzada garantiza que la selecci√≥n de hiperpar√°metros no est√© sesgada por el conjunto de prueba, preservando la validez de las m√©tricas finales de rendimiento.

<br>

**Elastic Net es ideal porque**:

1. **Variables correlacionadas**:
   - Temperaturas (m√°x/m√≠n/promedio): $r > 0.9$
   - Radiaciones (directa/difusa): relaci√≥n f√≠sica directa
   - Humedades (relativa/absoluta): dependencia funcional

2. **Necesidad de selecci√≥n**:
   - selcci√≥n de variables redundantes

3. **Estabilidad requerida**:
   - Outliers meteorol√≥gicos conservados (63 eventos extremos)
   - Predicciones requieren robustez

**Resultado esperado**: Modelo con mas de $10$ variables activas, coeficientes estables y alta capacidad predictiva ($R^2 > 0.9$).

<br>

## Seleccion de variables
```{r resumen_variables, echo=FALSE}

variable_objetivo <- "Radiaci√≥n solar descendente superficie (W/m¬≤)"
df_final<- df_analisis[, !names(df_analisis) %in% variable_objetivo]

cat("üéØ Variable objetivo: ", variable_objetivo, " (W/m¬≤)\n",
    "üìä Variables predictoras: ", ncol(df_final), "\n", sep = "")

```
<br>

**Explicaci√≥n de Variable Objetivo: Radiaci√≥n Solar Descendente (W/m¬≤)**

***¬øQu√© es la Radiaci√≥n Solar Descendente?*** 

Es la energ√≠a del sol que **llega efectivamente a la superficie terrestre** despu√©s de atravesar la atm√≥sfera. No es toda la radiaci√≥n que sale del sol, sino la que sobrevive al viaje atmosf√©rico considerando:

- ***Absorci√≥n:*** Gases como ozono y vapor de agua capturan parte de la energ√≠a
- ***Dispersi√≥n:*** Mol√©culas de aire redireccionan la luz en todas direcciones
- ***Reflexi√≥n:*** Nubes y aerosoles devuelven energ√≠a al espacio

Es la radiaci√≥n que realmente puedes aprovechar con un panel solar o que calienta tu piel.

Unidades: W/m¬≤ (Vatios por metro cuadrado)
Mide potencia energ√©tica por unidad de √°rea. Indica cu√°nta energ√≠a llega cada segundo a cada metro cuadrado de superficie.

**Ejemplos pr√°cticos:**

- D√≠a despejado al mediod√≠a: ~800-1000 W/m¬≤
- D√≠a parcialmente nublado: ~400-600 W/m¬≤
- D√≠a muy nublado: ~100-200 W/m¬≤
- Noche: 0 W/m¬≤

**Importancia:**

Fuente primaria de energ√≠a terrestre. Impulsa fotos√≠ntesis, regula clima, sostiene temperatura habitable y alimenta el ciclo hidrol√≥gico.


**Objetivo del modelo:**

Predecir radiaci√≥n solar descendente superficie usando 17 variables meteorol√≥gicas (temperatura, humedad, viento, presi√≥n).

**Aplicaciones pr√°cticas:**

- Planificaci√≥n de generaci√≥n fotovoltaica
- Estimaci√≥n de evaporaci√≥n para riego agr√≠cola costero
- Balance energ√©tico en ecosistemas litorales
- Gesti√≥n de recursos h√≠dricos regionales

<br>

## Mostrar variables predictoras
```{r variables predictoras , echo=FALSE}

cat(paste0( "üìã Variables predictoras:\n",paste0("* ", names(df_final), collapse = "\n")
  ))

```
<br>

**Explicaci√≥n de Variables Predictoras**

1. ***Radiaci√≥n solar directa normal en superficie (W/m¬≤)***
- Qu√© es: Radiaci√≥n solar que llega directamente del disco solar a una superficie perpendicular a los rayos del sol, sin incluir la radiaci√≥n dispersada por la atm√≥sfera.

2. ***Temperatura 2 mts altura (¬∞C)***
- Qu√© es: Temperatura del aire medida a 2 metros sobre el suelo (altura est√°ndar meteorol√≥gica).

3. ***Temperatura h√∫meda 2 mts altura (¬∞C*)***
- Qu√© es: Temperatura que alcanzar√≠a el aire si se enfriara por evaporaci√≥n de agua hasta saturarse (100% humedad).(tiene 1*)

4. ***Temperatura m√°x 2 mts altura (¬∞C)***
- Qu√© es: Temperatura m√°s alta del d√≠a a 2 metros de altura.

5. ***Temperatura m√≠n 2 mts altura (¬∞C)***
- Qu√© es: Temperatura m√°s baja del d√≠a (generalmente de madrugada).

6. ***Temperatura m√°x superficie (¬∞C)***
- Qu√© es: Temperatura m√°s alta del suelo/oc√©ano durante el d√≠a.

7. ***Temperatura m√≠n superficie (¬∞C)***
- Qu√© es: Temperatura m√°s baja de la superficie (generalmente de noche).

8. ***Contenido vapor agua 2 mts altura (kg/kg)***
- Qu√© es: Cantidad absoluta de vapor de agua en el aire.

9. ***Humedad relativa 2 mts altura (%)***
- Qu√© es: Porcentaje de saturaci√≥n del aire. 100% = aire totalmente saturado.

10. ***Precipitaci√≥n total corregida (mm)***
- Qu√© es: Cantidad de lluvia acumulada en el d√≠a.

11. ***Presi√≥n superficial (Pa)***
- Qu√© es: Peso de la columna de aire sobre la superficie (presi√≥n atmosf√©rica).

12. ***Velocidad m√°x viento 2 mts altura (m/s)***
- Qu√© es: Velocidad m√°xima del viento medida a 2 metros de altura durante el d√≠a.

13. ***Velocidad m√≠n viento 2 mts altura (m/s)***
- Qu√© es: Velocidad m√≠nima del viento a 2 metros (generalmente de madrugada).

14. ***Velocidad m√°x viento 10 mts altura (m/s)***
- Qu√© es: Velocidad m√°xima del viento a 10 metros de altura.

15. ***Velocidad m√≠n viento 10 mts altura (m/s)***
- Qu√© es: Velocidad m√≠nima del viento a 10 metros de altura.

16. ***Humedad perfil suelo (%)**
- Qu√© es: Porcentaje de humedad en el suelo (saturaci√≥n del perfil subterr√°neo).

17. ***Radiaci√≥n onda larga superficie (W/m¬≤)***
- Qu√© es: Radiaci√≥n t√©rmica infrarroja que emite la superficie calentada.

<br>

**Relaci√≥n Global con la Radiaci√≥n Solar**

Estas variables predictoras est√°n conectadas con la radiaci√≥n solar a trav√©s de dos mecanismos principales:

***1. Variables que indican condiciones atmosf√©ricas (causas de variaci√≥n en radiaci√≥n)***

- ***Nubosidad y humedad***: La humedad relativa, el contenido de vapor de agua y la precipitaci√≥n son indicadores directos de la presencia de nubes y part√≠culas en la atm√≥sfera que bloquean o dispersan la radiaci√≥n solar antes de llegar a la superficie.

- ***Presi√≥n atmosf√©rica***: Sistemas de alta presi√≥n se asocian con cielos despejados (mayor radiaci√≥n), mientras que baja presi√≥n indica sistemas nubosos (menor radiaci√≥n).

- ***Viento***: Transporta masas de aire con diferentes caracter√≠sticas. En zonas costeras como Pichilemu, vientos del este traen aire seco y despejado, mientras que vientos del oeste traen humedad marina y nubosidad.

***2. Variables que son consecuencias de la radiaci√≥n solar (efectos)***

- ***Temperaturas***: La radiaci√≥n solar calienta directamente el aire y las superficies. Temperaturas m√°ximas altas, grandes amplitudes t√©rmicas (diferencia entre m√°xima y m√≠nima) y superficies calientes indican que hubo abundante radiaci√≥n solar durante el d√≠a.

- ***Radiaci√≥n de onda larga***: Es la energ√≠a infrarroja que emite la superficie despu√©s de calentarse por el sol, actuando como "memoria t√©rmica" de la radiaci√≥n recibida.

- ***Radiaci√≥n directa normal***: Esta variable es especialmente informativa porque separa la componente directa de la radiaci√≥n total, permitiendo distinguir entre atm√≥sfera limpia (alta radiaci√≥n directa) y condiciones de nubosidad parcial o contaminaci√≥n (baja radiaci√≥n directa pero radiaci√≥n difusa presente).

<br>

El modelo utiliza estas variables en conjunto para capturar el estado completo del sistema atmosf√©rico: desde las causas meteorol√≥gicas que modulan cu√°nta radiaci√≥n llega (nubes, humedad, presi√≥n), hasta las consecuencias t√©rmicas que confirman cu√°nta energ√≠a realmente lleg√≥ a la superficie. Esta combinaci√≥n permite predicciones robustas de la radiaci√≥n solar descendente total.

<br>

## Estandarizaci√≥n para prueba/entrenamiento

<br>

**Definici√≥n estandarizaci√≥n** (o normalizaci√≥n de caracter√≠sticas) es un proceso fundamental en aprendizaje autom√°tico que ajusta las variables de entrada para que tengan una **media de 0** y una **desviaci√≥n est√°ndar de 1** en el conjunto de entrenamiento. Este proceso es crucial para mejorar la precisi√≥n y estabilidad de diversos modelos, especialmente en aquellos que dependen de m√©tricas de distancia (como la distancia euclidiana) o de la escala de las variables.

Por ejemplo, la estandarizaci√≥n es esencial en:

- ***Regresi√≥n local***: Donde se utiliza la norma euclidiana, la estandarizaci√≥n asegura que los predictores no se vean afectados por diferencias en sus unidades.

- ***Regresi√≥n de Componentes Principales (PCR)***: Los componentes principales son sensibles al escalamiento, por lo que se estandarizan las entradas.

- ***Regresi√≥n Lasso en regresi√≥n log√≠stica***: La estandarizaci√≥n garantiza que la penalizaci√≥n $L_1$ sea equitativa entre variables.

- ***M√©todo de Centros Reducidos m√°s Cercanos (NSC)***: Requiere estandarizar caracter√≠sticas individualmente para mejorar el rendimiento.

- ***Predicci√≥n de radiaci√≥n solar descendente***: La estandarizaci√≥n asegura precisi√≥n al alinear las escalas de las variables, como la radiaci√≥n solar medida en el terreno.

<br>

**Importancia en la predicci√≥n de variable objetivo**

La estandarizaci√≥n es clave para predecir la **radiaci√≥n solar descendente en la superficie**, ya que homogeniza las escalas de las variables y mejora la precisi√≥n del modelo. Sus beneficios incluyen:

- ***Evitar sesgos***: Igualar las escalas de las variables evita que las de mayor magnitud dominen las predicciones, garantizando un an√°lisis equitativo.

- ***Mejorar la convergencia***: Algoritmos como el descenso de gradiente convergen m√°s r√°pido y de manera estable con datos estandarizados.

- ***Facilitar la interpretaci√≥n***: Permite comparar la influencia de diferentes variables, como factores clim√°ticos en la radiaci√≥n solar.

- ***Esencial para PCA y regularizaci√≥n***: Garantiza c√°lculos precisos en t√©cnicas sensibles a la varianza.

- ***Consistencia***: Aplicada solo al conjunto de entrenamiento, asegura predicciones reproducibles en datos de prueba.

<br>

**Expresi√≥n matem√°tica de la estandarizaci√≥n**

La estandarizaci√≥n transforma los datos utilizando la **f√≥rmula del z-score**, que ajusta cada valor para que la variable resultante tenga media 0 y desviaci√≥n est√°ndar 1.

***F√≥rmula del Z-Score***

Para un valor $x_{i,j}$ (observaci√≥n $i$, caracter√≠stica $j$), el valor estandarizado $z_{i,j}$ se calcula como:

$$ z_{i,j} = \frac{x_{i,j} - \bar{x}_j}{\sigma_j} $$

Donde:

- $z_{i,j}$: Valor estandarizado.
- $x_{i,j}$: Valor original de la caracter√≠stica $j$ para la observaci√≥n $i$.
- $\bar{x}_j$: Media emp√≠rica de la caracter√≠stica $j$, calculada como:

$$ \bar{x}_j = \frac{1}{N} \sum_{i=1}^{N} x_{i,j} $$

- $\sigma_j$: Desviaci√≥n est√°ndar emp√≠rica de la caracter√≠stica $j$, que es la ra√≠z cuadrada del elemento diagonal correspondiente de la matriz de covarianza:

$$ \sigma_j = \sqrt{\frac{1}{N} \sum_{i=1}^{N} (x_{i,j} - \bar{x}_j)^2} $$

**C√°lculo de la media y la varianza emp√≠ricas**

La estandarizaci√≥n se basa en los siguientes c√°lculos:

- ***Media emp√≠rica***: Para una caracter√≠stica $j$, se calcula como el promedio de todas las observaciones:

$$ \bar{x}_j = \frac{1}{N} \sum_{i=1}^{N} x_{i,j} $$

- ***Matriz de covarianza emp√≠rica***: Para un conjunto de datos con $p$ caracter√≠sticas, la matriz de covarianza $\mathbf{\Sigma}$ se define como:

$$ \mathbf{\Sigma} = \frac{1}{N} \sum_{i=1}^{N} (x_i - \bar{x})(x_i - \bar{x})^\top $$

Donde $x_i$ es el vector de caracter√≠sticas para la observaci√≥n $i$, y $\bar{x}$ es el vector de medias emp√≠ricas de todas las caracter√≠sticas.

<br>

**Conclusi√≥n**

La estandarizaci√≥n es una t√©cnica indispensable en aprendizaje autom√°tico, especialmente en aplicaciones como la predicci√≥n de radiaci√≥n solar. Al transformar las variables a una escala com√∫n (media 0, desviaci√≥n est√°ndar 1), se evitan sesgos, se mejora la convergencia de los algoritmos y se facilita la interpretaci√≥n de los modelos. Esta transformaci√≥n asegura que las variables no dominen las predicciones debido a diferencias en sus escalas, permitiendo un an√°lisis m√°s preciso y comparable. Su implementaci√≥n es sencilla pero poderosa, garantizando modelos m√°s robustos y precisos.

<br>

**Estandarizaci√≥n de las variables**
```{r estandarizaci√≥n}

# Estandarizar todas las variables
df_final_scaled <- as.data.frame(scale(df_final))

# Estandarizar variable objetivo (como vector)
y_objetivo <- scale(df_analisis[[variable_objetivo]])[,1]

# Verificar estandarizaci√≥n: media ‚âà 0, desviaci√≥n est√°ndar ‚âà 1
media <- apply(df_final_scaled, 2, mean)     
desv_str <- apply(df_final_scaled, 2, sd) 

# Crear tabla de verificaci√≥n
tabla_verificacion <- data.frame(
  Variable = names(media),
  Media = round(media, 9),
  `Desviaci√≥n Est√°ndar` = round(desv_str, 9),
  Estandarizada = ifelse(abs(media) < 0.000001 & abs(desv_str - 1) < 0.000001, 
                         "‚úÖ S√≠", "‚ùå No")
)

# Alternativa con HTML para un marco estilizado
library(kableExtra)
knitr::kable(
  tabla_verificacion,
  caption = "Verificaci√≥n de Estandarizaci√≥n",
  align = c("l", "r", "r", "c"),
  digits = 9,
  format = "html"  # Necesario para aplicar estilos de marco
) %>%
  kable_styling(
    bootstrap_options = "bordered"  # Agrega un marco estilizado
  )
  
```
<br>

```{r echo = FALSE}

cat("üéØ Conclusi√≥n:
La estandarizaci√≥n fue exitosa.datos est√°n correctamente 
preparados para M√©todos de regularizaci√≥n:
‚Ä¢ Ridge Regression
‚Ä¢ Lasso Regression  
‚Ä¢ Elastic Net")

```
<br>

## Divisi√≥n de datos en entrenamiento y prueba
```{r division de train/test}

library(caret)

set.seed(123)

trainIndex <- createDataPartition(y_objetivo, p = 0.8, list = FALSE)

X_train <- df_final_scaled[trainIndex, ]
y_train <- y_objetivo[trainIndex]

X_test<- df_final_scaled[-trainIndex, ]
y_test <- y_objetivo[-trainIndex]

```
<br>

## Verificacion distribucion variable Objetivo 
```{r Verificaci√≥n Num√©rica}

# Calculo media y desviaci√≥n est√°ndar
stats_train <- c(Media = mean(y_train), Desv_Est = sd(y_train))
stats_test <- c(Media = mean(y_test), Desv_Est = sd(y_test))

kable(data.frame(
  Conjunto = c("Entrenamiento", "Prueba"),
  Media = c(round(stats_train[1], 4), round(stats_test[1], 4)),
  Desviacion_Estandar = c(round(stats_train[2], 4), round(stats_test[2], 4))
), caption = "Verificaci√≥n de Distribuci√≥n de variable objetivo",
) %>%
  kable_styling(
    bootstrap_options = c("bordered"),  # +marco
    full_width = TRUE,  
    position = "center"  
  )

```

<br>

**Contexto**: La variable objetivo (radiaci√≥n solar descendente en superficie, estandarizada con media ‚âà 0 y desv. est√°ndar ‚âà 1) se dividi√≥ en entrenamiento (80%) y prueba (20%) usando createDataPartition. Se verifica que las distribuciones de y_train y y_test sean similares para garantizar una partici√≥n equilibrada.

Resultados Num√©ricos:

Media: Entrenamiento (0.0034), Prueba (-0.0134). Ambas muy cercanas a 0, indicando un centrado preciso.

Desviaci√≥n Est√°ndar: Entrenamiento (1.0159), Prueba (0.9474). Cercanas a 1, con una leve variaci√≥n en prueba, aceptable por su menor tama√±o (20%).

Interpretaci√≥n: Las distribuciones de la variable objetivo son similares en ambos conjuntos, con diferencias m√≠nimas que no afectan la precisi√≥n del modelo. La partici√≥n es s√≥lida, asegurando una representaci√≥n consistente de la radiaci√≥n solar en entrenamiento y prueba.

<br>

## Optimizaci√≥n de hiperpar√°metros
```{r Definici√≥n de funci√≥n } 

seleccionar_mejor_regularizacion <- function() {

 # Explora 11 valores de alpha (0=Ridge, 0.5=Elastic Net, 1=Lasso)
  alphas <- seq(0, 1, by = 0.1)
  resultados_grid <- list()

  for(i in seq_along(alphas)) {
    set.seed(123)
    
    # Valida lambda √≥ptimo con CV 10-fold para cada alpha
    cv_temp <- cv.glmnet(as.matrix(X_train), y_train, alpha = alphas[i], nfolds = 10)
    
    # Entrena modelo con lambda.min (m√≠nimo error en CV)
    modelo_temp <- glmnet(as.matrix(X_train), y_train, alpha = alphas[i], lambda = cv_temp$lambda.min)
    
    
    # Calcula R¬≤ en test (capacidad predictiva)
    pred_temp <- predict(modelo_temp, newx = as.matrix(X_test))
    r2_temp <- cor(y_test, pred_temp)^2
    

    # Guarda alpha, lambda, R¬≤ y modelo CV
    resultados_grid[[i]] <- list(
      alpha = alphas[i],
      lambda = cv_temp$lambda.min,
      r2 = r2_temp,
      cv_model = cv_temp
    )
  }

   # Selecciona la configuraci√≥n con mayor R¬≤
  r2_values <- sapply(resultados_grid, function(x) x$r2)
  mejor_idx <- which.max(r2_values)

  return(resultados_grid[[mejor_idx]])
}

# Ejecuta la b√∫squeda y devuelve alpha, lambda, R¬≤ y modelo CV √≥ptimos
regularizacion_optima <- seleccionar_mejor_regularizacion()

``` 

<br>

**Objetivo**

Explorar diferentes combinaciones de Œ± (alpha) y Œª (lambda) para evaluar su desempe√±o en t√©rminos del coeficiente de determinaci√≥n (R¬≤) en los datos de prueba, buscando un equilibrio entre selecci√≥n de variables (L1) y estabilidad ante colinealidad (L2).

**Metodolog√≠a**

Se implement√≥ una b√∫squeda exploratoria sobre 11 valores de Œ± entre 0 y 1 (incrementos de 0.1):

Œ± = 0: Ridge (penalizaci√≥n L2, conserva todos los predictores).

Œ± = 1: Lasso (penalizaci√≥n L1, promueve la selecci√≥n de variables).

0 < Œ± < 1: Elastic Net (combinaci√≥n L1 + L2).

Para cada valor de Œ±:

Se estim√≥ el Œª √≥ptimo mediante validaci√≥n cruzada de 10 pliegues, seleccionando el que minimiza el error medio.

Con ese Œª, se ajust√≥ el modelo final y se calcul√≥ su R¬≤ sobre los datos de prueba.

Los resultados (Œ±, Œª, R¬≤ y modelo CV) se almacenaron para su posterior comparaci√≥n.

El resultado de esta funci√≥n es un conjunto de modelos evaluados, uno por cada Œ±, que permite posteriormente identificar cu√°l presenta el mejor desempe√±o (mayor R¬≤).

**Justificaci√≥n**

- El enfoque Elastic Net resulta adecuado para conjuntos con:

- Alta colinealidad entre variables (como las meteorol√≥gicas).

- Necesidad de selecci√≥n autom√°tica de predictores sin perder estabilidad num√©rica.

- Un contexto donde se requiere equilibrar interpretabilidad y desempe√±o predictivo.

<br>

## Tabla resumen regularizacion √≥ptima
```{r grafico_r2_vs_alpha,fig.width=10, fig.height=5,echo=FALSE}

# Tipo de regularizaci√≥n
tipo <- if (regularizacion_optima$alpha < 0.1) {
  "Ridge (L2)"
} else if (regularizacion_optima$alpha > 0.9) {
  "Lasso (L1)"
} else {
  "Elastic Net"
}

# Tabla compacta 
tabla_hallazgos <- data.frame(
  Par√°metro = c("Modelo", "Hiperpar√°metros", "Desempe√±o"),
  Resultado = c(
    tipo,
    sprintf("Œ±=%.2f, Œª=%.6f", regularizacion_optima$alpha, regularizacion_optima$lambda),
    sprintf("R¬≤=%.4f (%.2f%%)", regularizacion_optima$r2, regularizacion_optima$r2 * 100)
  ),
  stringsAsFactors = FALSE
)

# Renderizar
tabla_hallazgos %>%
  kable(
    align = c('l', 'r'),
    col.names = c("Componente", "Valor √ìptimo"),
    caption = "Configuraci√≥n √ìptima de Regularizaci√≥n"
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover"),
    full_width = TRUE,
    position = "center",
    font_size = 14
  ) %>%
  row_spec(0, bold = TRUE, background = "#34495E", color = "white") %>%
  row_spec(3, bold = TRUE, background = "#D5F4E6") %>%
  column_spec(1, bold = TRUE) %>%
  column_spec(2, color = "#2C3E50", bold = TRUE)  # ‚úÖ Azul oscuro sobrio

```

```{r echo=FALSE}

# Interpretaci√≥n de una l√≠nea
cat(sprintf("\nüéØ El modelo %s (Œ±=%.2f, Œª=%.6f) explica %.2f%% de la varianza en test.\n\n",
            tipo, regularizacion_optima$alpha, regularizacion_optima$lambda, 
            regularizacion_optima$r2 * 100))

```
<br>

## Funci√≥n para entrenamiento y evaluaci√≥n de modelos regularizados
```{r CONFIGURACI√ìN Y ENTRENAMIENTO DE MODELOS EST√ÅNDAR}

# funci√≥n para entrenar y evaluar cualquier m√©todo

library(glmnet) # aqui se aplican conceptos de **Optimizaci√≥n en Machine Learning**

entrenar_modelo <- function(alpha_val, nombre_metodo, X_train, y_train, X_test, y_test) {
  
  set.seed(123)  # agregar misma semilla que b√∫squeda exhaustiva
  
  # Validaci√≥n cruzada para lambda √≥ptimo
  cv_model <- cv.glmnet(as.matrix(X_train), y_train, alpha = alpha_val, nfolds = 10)
  best_lambda <- cv_model$lambda.min
  
  # Modelo final con mejor lambda
  final_model <- glmnet(as.matrix(X_train), y_train, alpha = alpha_val, lambda = best_lambda)
  
  # Predicciones
  y_pred_test <- predict(final_model, newx = as.matrix(X_test))
  y_pred_train <- predict(final_model, newx = as.matrix(X_train))
  
  # M√©tricas
  r2_test <- cor(y_test, y_pred_test)^2
  rmse_test <- sqrt(mean((y_test - y_pred_test)^2))
  r2_train <- cor(y_train, y_pred_train)^2
  
  # Resultados
  return(list(
    metodo = nombre_metodo,
    alpha = alpha_val,
    lambda = best_lambda,
    r2_test = r2_test,
    rmse_test = rmse_test,
    r2_train = r2_train,
    modelo = final_model,
    cv_model = cv_model,
    predicciones = y_pred_test
  ))
}

# Entrenar los 3 modelos
resultados <- list(
  entrenar_modelo(0, "Ridge", X_train, y_train, X_test, y_test),
  entrenar_modelo(1, "Lasso", X_train, y_train, X_test, y_test),
  entrenar_modelo(0.5, "Elastic Net", X_train, y_train, X_test, y_test)
)

```

## Comparaci√≥n de modelos regularizados
```{r comparacion-inicial,echo=FALSE}

#Construcci√≥n de tabla
tabla_resultados <- data.frame(
  M√©todo = sapply(resultados, function(x) x$metodo),
  Alpha = sapply(resultados, function(x) x$alpha),
  Lambda = sapply(resultados, function(x) round(x$lambda, 5)),
  R2_Train = sapply(resultados, function(x) round(x$r2_train, 3)),
  R2_Test = sapply(resultados, function(x) round(x$r2_test, 3)),
  RMSE_Test = sapply(resultados, function(x) round(x$rmse_test, 3))
)

#Identificar el m√©todo √≥ptimo (mayor R2_Test)
metodo_optimo <- tabla_resultados$M√©todo[which.max(tabla_resultados$R2_Test)]

#formateo tabla 
tabla_resultados %>%
  dplyr::mutate(
    M√©todo = ifelse(M√©todo == metodo_optimo,
                    cell_spec(M√©todo, "html", bold = TRUE, color = "white", background = "#3BAFDA"),  # verde-azulado suave
                    cell_spec(M√©todo, "html", color = "#1A5276"))  # azul oscuro para texto general
  ) %>%
  kable("html",
        caption = "Comparaci√≥n de M√©todos de Regularizaci√≥n",
        align = "c", escape = FALSE) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "bordered", "condensed"),
    full_width = TRUE,
    font_size = 14,
    position = "center"
  ) %>%
  add_header_above(c(" " = 1, "Par√°metros" = 2, "Desempe√±o" = 3)) %>%
  add_footnote(label = paste("M√©todo √≥ptimo seg√∫n R¬≤_Test:", metodo_optimo), notation = "symbol") %>%
  row_spec(0, bold = TRUE, color = "white", background = "#1F618D") %>%   # encabezado azul fuerte
  kable_paper("hover", html_font = "Arial") %>%
  column_spec(1, bold = TRUE, width = "10em") %>%  # Ajuste est√©tico de ancho
  column_spec(2:6, width = "8em", background = "#EBF5FB")                 # celeste muy suave de fondo

```

<br>

## Comparaci√≥n de desempe√±o de modelo inicial v/s modelo optimizado
```{r selccion modelo final}

# Identificar mejores modelos para comparaci√≥n
mejor_inicial <- resultados[[which.max(sapply(resultados, `[[`, "r2_test"))]]
mejor_elastic <- regularizacion_optima

# Calcular m√©tricas de comparaci√≥n
mejora_absoluta <- mejor_elastic$r2 - mejor_inicial$r2_test
mejora_relativa <- (mejora_absoluta / mejor_inicial$r2_test) * 100

# Determinar modelo final y reportar resultados
if (mejora_absoluta > 0) {
  # Elastic Net optimizado es superior
  cat("üèÜ RESULTADO: Elastic Net optimizado supera al mejor m√©todo inicial\n\n")
  cat(sprintf("   üìà Mejora absoluta en R¬≤: +%.4f puntos (de %.4f a %.4f)\n",
              mejora_absoluta, mejor_inicial$r2_test, mejor_elastic$r2))
  cat(sprintf("   üìä Mejora relativa: +%.2f%% en varianza explicada\n\n", mejora_relativa))
  
  # Crear modelo final con Elastic Net optimizado
  modelo_final_optimizado <- glmnet(as.matrix(X_train), y_train, 
                                   alpha = mejor_elastic$alpha, 
                                   lambda = mejor_elastic$lambda)
  
  modelo_final <- list(
    metodo = sprintf("Elastic Net (Œ±=%.2f, Œª=%.6f)", mejor_elastic$alpha, mejor_elastic$lambda),
    alpha = mejor_elastic$alpha,
    lambda = mejor_elastic$lambda,
    r2_test = mejor_elastic$r2,
    modelo = modelo_final_optimizado,
    cv_model = mejor_elastic$cv_model,
    predicciones = predict(modelo_final_optimizado, newx = as.matrix(X_test))
  )
  
} else {
  # Modelo inicial sigue siendo superior
  cat(sprintf("üèÜ RESULTADO: %s sigue siendo el mejor modelo\n\n", mejor_inicial$metodo))
  cat(sprintf("   üìâ Diferencia favorable: +%.4f puntos a favor del m√©todo inicial\n\n", 
              abs(mejora_absoluta)))
  
  modelo_final <- mejor_inicial
}

```
```{r include = FALSE}

mejor_modelo <- modelo_final

```
<br>

## Resumen validaci√≥n cruzada: m√©tricas y selecci√≥n de Œª
```{r analisis_validacion_cruzada_detallado, echo=FALSE}

# Extraer datos del modelo CV √≥ptimo
cv_data <- data.frame(
  lambda = mejor_modelo$cv_model$lambda,
  cvm = mejor_modelo$cv_model$cvm,
  cvsd = mejor_modelo$cv_model$cvsd,
  nzero = mejor_modelo$cv_model$nzero
)

# Identificar lambdas √≥ptimos
lambda_min <- mejor_modelo$cv_model$lambda.min
lambda_1se <- mejor_modelo$cv_model$lambda.1se

# Encontrar √≠ndices de los lambdas √≥ptimos
idx_min <- which.min(cv_data$cvm)
idx_1se <- which(cv_data$lambda == lambda_1se)

# Secci√≥n 1: Comparaci√≥n de criterios Œª
criterios_lambda <- data.frame(
  Criterio = c("Œª M√≠nimo MSE", "Œª Modelo Simple (1-SE)", "Diferencia ŒîŒª"),
  `Valor Œª` = c(
    sprintf("%.6f", lambda_min),
    sprintf("%.6f", lambda_1se),
    sprintf("%.6f", lambda_1se - lambda_min)
  ),
  MSE = c(
    sprintf("%.4f", cv_data$cvm[idx_min]),
    sprintf("%.4f", cv_data$cvm[idx_1se]),
    sprintf("+%.4f", cv_data$cvm[idx_1se] - cv_data$cvm[idx_min])
  ),
  `Variables Activas` = c(
    sprintf("%d", cv_data$nzero[idx_min]),
    sprintf("%d", cv_data$nzero[idx_1se]),
    sprintf("%+d", cv_data$nzero[idx_min] - cv_data$nzero[idx_1se])
  ),
  Interpretaci√≥n = c(
    "‚úÖ Mejor predicci√≥n (m√≠nimo error)",
    "‚öñÔ∏è Balance precisi√≥n-parsimonia",
    sprintf("%s complejidad", 
            ifelse(cv_data$nzero[idx_min] > cv_data$nzero[idx_1se], "Mayor", "Menor"))
  ),
  check.names = FALSE
)

# Secci√≥n 2: Caracter√≠sticas del modelo seleccionado
modelo_seleccionado <- data.frame(
  Caracter√≠stica = c(
    "üéØ Modelo Seleccionado",
    "MSE en Validaci√≥n Cruzada",
    "Variables Activas",
    "Rango Œª Explorado",
    "Configuraciones Evaluadas"
  ),
  Valor = c(
    sprintf("Œª = %.6f", lambda_min),
    sprintf("%.4f", cv_data$cvm[idx_min]),
    sprintf("%d/%d (%.1f%%)", 
            cv_data$nzero[idx_min], 
            ncol(X_train),
            (cv_data$nzero[idx_min] / ncol(X_train)) * 100),
    sprintf("[%.6f, %.6f]", min(cv_data$lambda), max(cv_data$lambda)),
    sprintf("%d valores de Œª", nrow(cv_data))
  ),
  check.names = FALSE
)

criterios_lambda %>%
  kable(
    align = c('l', 'c', 'c', 'c', 'l'),
    caption = "An√°lisis de Criterios: Œª M√≠nimo vs Œª 1-SE",
    escape = TRUE
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "bordered"),
    full_width = TRUE,
    position = "center"
  ) %>%
  row_spec(0, bold = TRUE, background = "#2C3E50", color = "white") %>%
  row_spec(1, bold = TRUE, background = "#D5F4E6") %>%
  row_spec(3, italic = TRUE, background = "#F8F9FA") %>%
  column_spec(1, bold = TRUE, width = "12em") %>%
  column_spec(5, italic = TRUE, color = "#5D6D7E") %>%
  footnote(
    general = "Regla 1-SE: Selecciona el modelo m√°s simple con error dentro de 1 desviaci√≥n est√°ndar del m√≠nimo",
    general_title = "Nota:",
    footnote_as_chunk = TRUE
  )

modelo_seleccionado %>%
  kable(
    align = c('l', 'c'),
    caption = "Especificaciones T√©cnicas del Modelo Final",
    escape = TRUE
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "bordered"),
    full_width = TRUE,
    position = "center"
  ) %>%
  row_spec(0, bold = TRUE, background = "#27AE60", color = "white") %>%
  row_spec(1, bold = TRUE, background = "#D5F4E6", color = "#27AE60") %>%
  column_spec(1, bold = TRUE, width = "16em") %>%
  column_spec(2, color = "#2C3E50", bold = TRUE) %>%
  add_header_above(c("Configuraci√≥n √ìptima de Validaci√≥n Cruzada 10-Fold" = 2),
                   bold = TRUE, background = "#D5F4E6")

```
<br>

**Decisi√≥n Final**
```{r echo= FALSE}

cat(sprintf(
"Decisi√≥n Final: Se selecciona Œª m√≠nimo MSE para maximizar precisi√≥n predictiva.  

Justificaci√≥n:
- MSE en CV:%.4f (%.2f%% menor que Œª 1-SE)
- Variables retenidas: %d/%d (%.1f%% del total)
- Ganancia en complejidad: %+d variables vs modelo parsimonioso
- Rango de b√∫squeda: %d configuraciones entre Œª‚àà[%.2e, %.2e]

Trade-off: 
El modelo Œª m√≠nimo sacrifica %.0f variables adicionales para reducir el error en %.4f unidades de MSE, \
lo cual es aceptable dado el objetivo de predicci√≥n.\n",
  cv_data$cvm[idx_min],
  ((cv_data$cvm[idx_1se] - cv_data$cvm[idx_min]) / cv_data$cvm[idx_1se]) * 100,
  cv_data$nzero[idx_min],
  ncol(X_train),
  (cv_data$nzero[idx_min] / ncol(X_train)) * 100,
  cv_data$nzero[idx_min] - cv_data$nzero[idx_1se],
  nrow(cv_data),
  min(cv_data$lambda),
  max(cv_data$lambda),
  abs(cv_data$nzero[idx_min] - cv_data$nzero[idx_1se]),
  cv_data$cvm[idx_1se] - cv_data$cvm[idx_min]
))


```
<br>

**Gr√°fica Validaci√≥n Cruzada 10-Fold - Elastic Net**
```{r validacion_cruzada_modelo grafica,fig.width=10, fig.height=7}

graf_cv <- ggplot(cv_data, aes(x = log(lambda), y = cvm)) +
  # Intervalo de confianza
  geom_ribbon(aes(ymin = cvm - cvsd, ymax = cvm + cvsd, fill = "Intervalo ¬±1 SD"), 
              alpha = 0.3) +
  # Curva de error
  geom_line(aes(color = "Curva MSE"), linewidth = 1.2) +
  geom_point(aes(color = "Curva MSE"), size = 2, alpha = 0.7) +
  
  # L√≠neas verticales de lambdas √≥ptimos
  geom_vline(aes(xintercept = log(lambda_min), linetype = "Œª m√≠nimo MSE"), 
             color = "#06A77D", linewidth = 1) +
  geom_vline(aes(xintercept = log(lambda_1se), linetype = "Œª modelo simple"), 
             color = "#F77F00", linewidth = 1) +
  
  # Anotaciones en los puntos √≥ptimos
  annotate("text", x = log(lambda_min) + 0.05, y = max(cv_data$cvm) * 0.95,
           label = sprintf("Œª min\nMSE=%.4f\n%d vars", 
                          cv_data$cvm[idx_min], cv_data$nzero[idx_min]),
           color = "#06A77D", fontface = "bold", size = 3.0,hjust=-0.2) +
  annotate("text", x = log(lambda_1se)+ 0.05 , y = max(cv_data$cvm) * 0.95,
           label = sprintf("Œª 1-SE\nMSE=%.4f\n%d vars", 
                          cv_data$cvm[idx_1se], cv_data$nzero[idx_1se]),
           color = "#F77F00", fontface = "bold", size = 3.0,hjust= -0.2) +
  
  # Escalas manuales para leyenda
  scale_color_manual(
    name = "Componentes",
    values = c("Curva MSE" = "#2E86AB")
  ) +
  scale_fill_manual(
    name = NULL,
    values = c("Intervalo ¬±1 SD" = "gray60")
  ) +
  scale_linetype_manual(
    name = "Lambdas √ìptimos",
    values = c("Œª m√≠nimo MSE" = "dashed", 
               "Œª modelo simple" = "dashed")
  ) +
  
scale_x_continuous(
  breaks = seq(-7, 3, by = 1),  # Marca cada unidad desde -7
  sec.axis = sec_axis(
    ~ ., 
    name = "N√∫mero de Variables Activas",
    breaks = log(cv_data$lambda[seq(1, nrow(cv_data), length.out = 10)]),
    labels = cv_data$nzero[seq(1, nrow(cv_data), length.out = 10)]
  )
) +
  
  # Etiquetas y tema 
  labs(
    title = sprintf("Validaci√≥n Cruzada 10-Fold: Modelo %s", 
                   mejor_modelo$metodo),
    subtitle = sprintf("Configuraci√≥n √≥ptima: Œª=%.6f | MSE=%.4f | %d variables activas",
                      lambda_min, cv_data$cvm[idx_min], cv_data$nzero[idx_min]),
    x = "log(Œª)",
    y = "Error Cuadr√°tico Medio (MSE)",
    caption = "L√≠nea verde: Œª m√≠nimo MSE | L√≠nea naranja: Œª modelo simple (1-SE)"
  ) +
  theme_minimal(base_size = 12) +
  theme(
    plot.title = element_text(face = "bold", size = 14, hjust = 0.5, 
                              margin = margin(b = 8)),
    plot.subtitle = element_text(size = 11, hjust = 0.5, color = "#27AE60",
                                 face = "bold", margin = margin(b = 15)),
    axis.title = element_text(face = "bold", size = 11),
    axis.title.y.right = element_text(color = "#E74C3C", face = "bold"),
    axis.text.y.right = element_text(color = "#E74C3C"),
    panel.grid.minor = element_blank(),
    panel.border = element_rect(color = "gray70", fill = NA, linewidth = 0.5),
    legend.position = "right",
    legend.box = "vertical",
    legend.title = element_text(face = "bold", size = 10),
    legend.text = element_text(size = 9),
    legend.key.height = unit(1.2, "lines"),#1,0
    legend.spacing.y = unit(0.1, "cm"), # 0.3
    legend.box.spacing = unit(0.7, "cm"),#1.2
    plot.caption = element_text(size = 10, color = "gray50", hjust = 0.5,
                               margin = margin(t = 10))
  ) +
  guides(
    color = guide_legend(order = 1),
    fill = guide_legend(order = 2,title = NULL),
    linetype = guide_legend(order = 3, 
                           override.aes = list(color = c("#06A77D", "#F77F00")),
                           keyheight = unit(3.0, "lines"),
                           spacing.y = unit(0.6, "cm") # espacio entre las dos entradas
  ))

print(graf_cv)

```

<br>

**Interpretaci√≥n del grafico de validacion cruzada (Elastic net)**

El gr√°fico muestra el comportamiento del ***Error Cuadr√°tico Medio (MSE)*** en funci√≥n del par√°metro de regularizaci√≥n $\lambda$ bajo un esquema de ***validaci√≥n cruzada 10-Fold*** para un modelo Elastic Net con $\alpha = 0.10$. Este procedimiento permite identificar el grado de penalizaci√≥n que optimiza la capacidad predictiva del modelo, equilibrando el sesgo y la varianza.

**Estructura del Gr√°fico**

- ***Eje X*** ($\log(\lambda)$): Representa el logaritmo del par√°metro de regularizaci√≥n. Valores **m√°s negativos** (izquierda) corresponden a $\lambda$ peque√±os (poca penalizaci√≥n), mientras que valores **menos negativos** (derecha) indican $\lambda$ grandes (alta penalizaci√≥n).

- ***Eje Y***: Muestra el Error Cuadr√°tico Medio (MSE) promedio obtenido durante la validaci√≥n cruzada.

- ***Eje superior***: Indica el n√∫mero de variables activas (coeficientes distintos de cero) para cada valor de $\lambda$.

- ***L√≠nea azul***: Curva del MSE promedio a lo largo de los valores de $\lambda$.

- ***Banda gris***: Intervalo de confianza correspondiente a $\pm 1$ desviaci√≥n est√°ndar del MSE.

- ***L√≠nea verde*** (izquierda): Identifica el valor $\lambda_{\text{min}}$ que minimiza el error de validaci√≥n.

- ***L√≠nea naranja*** (derecha): Representa el $\lambda_{1\text{-SE}}$, un modelo m√°s parsimonioso seg√∫n la "regla de una desviaci√≥n est√°ndar".


**An√°lisis de Zonas**

1. Zona de Baja Penalizaci√≥n ($\lambda$ peque√±o, $\log(\lambda) \approx -7$ a $-6$)

- Penalizaci√≥n d√©bil: El modelo retiene todas las variables (17 activas).

- MSE bajo y estable ($\approx 0.05$‚Äì$0.06$): El modelo captura bien las relaciones sin penalizar excesivamente los coeficientes.

- ***Punto √≥ptimo:*** se obtiene en $\lambda_{\text{min}} = 0.000886$, cuyo valor logar√≠tmico es $\ln(\lambda_{\text{min}}) \approx -7.02$, alcanzando un MSE de 0.0522.

- ***Interpretaci√≥n***: En esta regi√≥n, el modelo tiene suficiente flexibilidad para capturar patrones reales sin sobreajustar, gracias a que la penalizaci√≥n a√∫n es activa.

2. Zona de Transici√≥n ($\log(\lambda) \approx -5$ a $0$)

- Penalizaci√≥n moderada: El n√∫mero de variables comienza a disminuir (17 ‚Üí 15 ‚Üí 11 ‚Üí 8).

- MSE se mantiene relativamente estable ($\approx 0.05$‚Äì$0.15$): La eliminaci√≥n gradual de variables redundantes no degrada significativamente el rendimiento.

- L√≠nea naranja ($\lambda_{1\text{-SE}}$): Ofrece un modelo m√°s simple (menos variables) con un incremento marginal en el error.

3. Zona de Alta Penalizaci√≥n ($\lambda$ grande, $\log(\lambda) > 0$)

- Penalizaci√≥n extrema: La mayor√≠a de los coeficientes se reducen a cero (8 ‚Üí 0 variables activas).

- MSE aumenta dr√°sticamente (0.15 ‚Üí 1.0): El modelo sufre **infraajuste** (*underfitting*), perdiendo capacidad para capturar relaciones esenciales entre las variables.

- Forma de "J" o "palo de hockey": La curva se dispara hacia arriba cuando la penalizaci√≥n elimina variables cr√≠ticas para la predicci√≥n.

<br>

**Conclusi√≥n**

El modelo Elastic Net con $\alpha = 0.10$ y $\lambda = 0.000886$ logra el **m√≠nimo error de validaci√≥n cruzada** (MSE = 0.0522), reteniendo **17 variables meteorol√≥gicas relevantes**. Este punto corresponde al √≥ptimo estad√≠stico, donde se alcanza un balance adecuado entre complejidad y capacidad predictiva.

**Comportamiento de la curva observado:**

La curva exhibe en este caso una ***forma de "J" (o "U"normal)***, caracter√≠stica del *trade-off* de regularizaci√≥n en modelos bien especificados:

$$
\text{MSE}(\lambda) =
\left\{
\begin{array}{ll}
\text{Bajo y estable} & \text{si } \lambda \text{ es peque√±o (zona √≥ptima)} \\
\text{Incrementa gradualmente} & \text{si } \lambda \text{ es moderado (transici√≥n)} \\
\text{Se dispara} & \text{si } \lambda \text{ es muy grande (infraajuste)}
\end{array}
\right\}
$$


**Interpretaci√≥n de acuerdo al gr√°fico:**

1. ***Izquierda*** ($\lambda$ peque√±o): Modelo completo sin sobreajuste gracias a la regularizaci√≥n Elastic Net ($\alpha=0.10$), que combina L1 (selecci√≥n) y L2 (estabilizaci√≥n).

2. ***Centro***: Zona de parsimonia donde se pueden eliminar variables redundantes con m√≠nimo impacto en el error.

3. ***Derecha*** ($\lambda$ grande): Penalizaci√≥n excesiva que elimina variables esenciales, degradando severamente el rendimiento.

***Diferencia con la "U" invertida cl√°sica:***

- La "U" invertida ocurre cuando el ***eje X es la complejidad del modelo*** (ej: grado de polinomio).

- Aqu√≠, el ***eje X es la penalizaci√≥n*** ($\lambda$), por lo que la curva es una ***"J" o "U levemente achatada*** sigue la tendencia esperada:

- menor penalizaci√≥n ‚Üí mejor rendimiento.

- mayor penalizaci√≥n ‚Üí peor rendimiento.

Este resultado valida que:

- La regularizaci√≥n Elastic Net previene sobreajuste incluso con $\lambda$ peque√±o.

- El modelo seleccionado ($\lambda_{\text{min}}$) maximiza la generalizaci√≥n sin sacrificar variables importantes.

- La validaci√≥n cruzada identific√≥ correctamente el punto √≥ptimo en la regi√≥n de baja penalizaci√≥n.

```{r guardado: validacion_cruzada.png , include=FALSE}

# Guardar con alta resoluci√≥n
png('validacion cruzada.png',  width = 10,height = 7, units = "in",res = 300)
print(graf_cv)
dev.off()

```
<br>

### Evaluaci√≥n del Ajuste del Modelo Elastic Net: Predicciones vs Valores Reales
```{r , fig.width=10, fig.height=5, echo=FALSE}

par(mfrow = c(1, 1))

rmse_test <- sqrt(mean((y_test - mejor_modelo$predicciones)^2))

df_pred <- data.frame(
  real = as.numeric(y_test),
  pred = as.numeric(mejor_modelo$predicciones)
)

ggplot(df_pred, aes(x = real, y = pred)) +
  geom_point(alpha = 0.6, size = 2.5, color = "blue") + ##2E86AB
  geom_abline(intercept = 0, slope = 1, 
            color = "#E74C3C", linewidth = 0.9, linetype = "solid")+
    labs(
      title = paste("Predicciones vs Valores Reales -", mejor_modelo$metodo),
      subtitle = bquote(R^2 ~ "=" ~ .(round(mejor_modelo$r2_test, 4)) ~ 
                      "| RMSE =" ~ .(round(rmse_test, 4))),
    x = "Valores Reales",
    y = "Predicciones"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
    plot.subtitle = element_text(hjust = 0.5, color = "gray30", size = 11),
    panel.grid.minor = element_blank(),
    axis.title = element_text(face = "bold"),
 panel.border = element_rect(color = "#4D4D4D", fill = NA, size = 1.0)  # ‚Üê MARCO negro claro

  ) +
  xlim(min(y_test), max(y_test)) +
  ylim(min(y_test), max(y_test))

cat("El gr√°fico muestra una alineaci√≥n cercana a la l√≠nea roja, indicando un buen ajuste del modelo Elastic Net.")

```

```{r grafico reales vs residious ,include=FALSE}

par(mfrow = c(1, 1))

png('predicciones_vs_reales.png', 
    width = 10, 
    height = 7, 
    units = "in", 
    res = 300)
plot(y_test, mejor_modelo$predicciones, 
     main = paste("Predicciones vs Reales -", mejor_modelo$metodo),
     xlab = "Valores Reales", ylab = "Predicciones",
     pch = 16, col = "blue")
abline(0, 1, col = "red", lwd = 2)

dev.off()

```
<br>

## Importancia de Variables en modelo final elastic net
### Tabla top 10 variables M√°s importantes
```{r Importancia variables mejor modelo(elastic net)}

# Obtener coeficientes del mejor modelo
coef_mejor <- coef(mejor_modelo$modelo)

# Calcular importancia absoluta de cada variable (excepto intercepto)
importancia <- abs(as.numeric(coef_mejor[-1]))
names(importancia) <- names(X_train)

# Ordenar importancia descendente
importancia_ordenada <- sort(importancia, decreasing = TRUE)

# Tomar top 10 y crear tibble
importancia_df_top10 <- importancia_ordenada %>%
  head(10) %>%
  tibble::enframe(name = "Variable", value = "Ponderaci√≥n")

# Mostrar tabla con knitr::kable()
knitr::kable(
  importancia_df_top10,
  caption = "Top 10 variables m√°s importantes",
  format = "markdown",
  align = c("l", rep("c", ncol(resumen_outliers) - 1))
) %>%
  kableExtra::kable_styling(
    position = "center",
    bootstrap_options = c("bordered")  # Agrega marco (correcci√≥n de sintaxis)
  ) %>%
  kableExtra::row_spec(0, extra_css = "border-color: #d3d3d3;") %>%  # Borde gris para el caption
  kableExtra::column_spec(column = 1:ncol(importancia_df_top10), extra_css = "border-color: #d3d3d3;")  # Borde gris para todas las celdas (correcci√≥n de referencia)

```
<br>

### Visualizaci√≥n radar top 10 variables 
```{r Radar Optimizado, fig.width=16, fig.height=14}

# Preparar datos para el gr√°fico de radar
top10 <- importancia_df_top10 %>%
  arrange(desc(Ponderaci√≥n)) %>%  # Ordenar por importancia descendente
  mutate(
    Variable = str_wrap(Variable, width = 16.5),  ## Ajustar nombres para legibilidadclaveclave
    Ponderacion_Norm = (Ponderaci√≥n / max(Ponderaci√≥n)) * 10  # Normalizar a escala 0-10
  )

# Crear gr√°fico de radar optimizado
radar <- ggplot(top10, aes(x = Variable, y = Ponderacion_Norm)) +
  # Barras del radar con color optimizado para temas claro/oscuro
  geom_col(width = 0.9, fill = "#4682B4", alpha = 0.8) +
  # Etiquetas sobre las barras
  geom_text(
    aes(label = sprintf("%.1f", Ponderacion_Norm), y = Ponderacion_Norm + 0.8),
    size = 5.0, color = "black", fontface = "bold", family = "" 
  ) +
  # Convertir a coordenadas polares
  coord_polar(start = 0) +
  # Escala radial optimizada
  scale_y_continuous(
    limits = c(0, 14),
    breaks = seq(0, 10, 2),
    expand = c(0, 0)
  ) +
  # T√≠tulos y etiquetas
  labs(
    title = "Top 10 Variables: Importancia Relativa",
    subtitle = "Escala normalizada de 0 a 10",
    caption = NULL,
    x = NULL, y = NULL
  ) +
  # Tema acad√©mico limpio ##axis.text.x size 9   margin de 30 a 35
  theme_minimal(base_size = 14) +
  theme(
    plot.title = element_text(face = "bold", size = 15, hjust = 0.5, margin = margin(b = 10)),
    plot.subtitle = element_text(size = 14, hjust = 0.5, color = "grey40", margin = margin(b = 20)),
    axis.text.x = element_text(size = 13, face = "bold", color = "black", margin = margin(t = 50),lineheight = 1.0),
    plot.caption = element_text(size = 10, color = "grey50", hjust = 0.5, margin = margin(t = 15)),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_line(linetype = "dotted", color = "grey60", size = 0.5),
    panel.grid.minor.y = element_blank(),
    legend.position = "none",
    plot.margin = margin(20,20,20,20)  # Margen amplio para etiquetas
  )

radar

```

```{r csv radar,include =FALSE,fig.width=16, fig.height=14}

ggsave(
  filename = "radar_top10_variables.png",plot = radar,width = 12,height = 12,dpi =300,bg= "white")

#write.csv(top10, "top10_importancia_radar.csv", row.names = FALSE)

```
<br>

Este gr√°fico de radar visualiza la importancia relativa de las 10 variables m√°s influyentes del modelo final (Elastic Net), normalizadas en una escala de 0 a 10. Las barras representan la ponderaci√≥n de cada variable. El dise√±o optimizado, con m√°rgenes ampliados y una escala radial clara, facilita la interpretaci√≥n de las variables que m√°s contribuyen a las predicciones del modelo.

**Interpretaci√≥n de Variables Clave**

***1. Temperatura m√°x 2 mts altura (¬∞C) ‚Üí 10.0***

Significado: Esta variable es la m√°s influyente del modelo. Representa la m√°xima temperatura del aire a nivel de 2 metros sobre el suelo durante el d√≠a.

Interpretaci√≥n f√≠sica:
La temperatura m√°xima est√° directamente relacionada con la cantidad de energ√≠a solar absorbida por la superficie terrestre y transferida al aire circundante. Cuanto mayor es la radiaci√≥n solar, mayor ser√° el calentamiento diurno del aire.

Conclusi√≥n: Esta variable sintetiza el efecto acumulado de la radiaci√≥n incidente; por eso el modelo la pondera como la de mayor poder predictivo.

***2. Temperatura m√°x superficie (¬∞C) ‚Üí 7.9***

Significado: Temperatura m√°xima registrada en la superficie terrestre o del suelo.

Interpretaci√≥n f√≠sica:
Est√° fuertemente correlacionada con la radiaci√≥n solar porque refleja la energ√≠a absorbida por el suelo durante el d√≠a. Su alta ponderaci√≥n (7.9) confirma que el calentamiento superficial es un buen indicador de la intensidad de radiaci√≥n recibida.

Relaci√≥n con la anterior: Ambas (temperatura m√°x aire y m√°x superficie) son indicadores t√©rmicos de la radiaci√≥n solar, pero la temperatura del aire a 2 m se ve m√°s directamente afectada por la radiaci√≥n neta y el balance energ√©tico superficial.

***3. Temperatura 2 mts altura (¬∞C) ‚Üí 6.4***

Significado: Temperatura promedio o instant√°nea a 2 m del suelo.

Interpretaci√≥n f√≠sica:
Esta variable captura el estado t√©rmico general de la atm√≥sfera baja, integrando la influencia de la radiaci√≥n solar, la humedad y la circulaci√≥n del aire.

Conclusi√≥n: Aunque menos espec√≠fica que la temperatura m√°xima, sigue siendo un buen descriptor del r√©gimen t√©rmico local y su relaci√≥n con la radiaci√≥n entrante.

***4. Temperatura h√∫meda 2 mts altura (¬∞C) ‚Üí 4.9***

Significado: Temperatura que considera tanto el calor sensible como la cantidad de vapor de agua en el aire (una mezcla entre temperatura del aire y humedad).

Interpretaci√≥n f√≠sica:
Este indicador integra temperatura del aire y humedad relativa, reflejando el contenido 
energ√©tico total (entalp√≠a) del aire h√∫medo. En condiciones de alta humedad, la mayor 
absorci√≥n de radiaci√≥n por vapor de agua reduce la componente directa disponible.

Conclusi√≥n: Su ponderaci√≥n intermedia indica que la humedad atmosf√©rica modula la radiaci√≥n, pero no es el factor dominante en el modelo.

***5. Radiaci√≥n solar directa normal en superficie (W/m¬≤) ‚Üí 4.3***

Significado: Significado: Componente de radiaci√≥n solar que llega sin dispersi√≥n atmosf√©rica, medida perpendicular a los rayos solares.

Interpretaci√≥n f√≠sica:
Su ponderaci√≥n moderada (4.3) refleja que, si bien es una medida directa de intensidad 
solar, la variable objetivo (radiaci√≥n solar descendente superficie) integra tambi√©n componentes 
difusa y reflejada. Las variables t√©rmicas capturan mejor la radiaci√≥n neta absorbida 
por el sistema superficie-atm√≥sfera.

Conclusi√≥n: Esta variable aporta informaci√≥n complementaria sobre condiciones de cielo 
despejado, pero su poder predictivo es parcialmente capturado por las temperaturas m√°ximas, 
que ya integran el efecto acumulado de toda la radiaci√≥n incidente.


**Validaci√≥n del Modelo**

El an√°lisis de importancia relativa confirma que el modelo Elastic Net construy√≥ un predictor 
f√≠sicamente coherente y estad√≠sticamente robusto:

- ***Dominancia t√©rmica***: Las 4 variables de mayor peso son todas t√©rmicas, reflejando que la       radiaci√≥n solar se manifiesta principalmente a trav√©s del calentamiento del sistema                 superficie-atm√≥sfera.

- ***Jerarqu√≠a f√≠sica validada***: La temperatura m√°xima a 2 mts altura(¬∞c)(10.0) captura la          respuesta t√©rmica m√°s directa a la radiaci√≥n, mientras que la temperatura m√°x superficial(¬∞c)      (7.9) registra la absorci√≥n energ√©tica inicial. Esta jerarqu√≠a es consistente con la f√≠sica del     balance radiativo.
   
- ***Rol moderado de variables radiativas directas***: La radiaci√≥n solar directa normal(W/m¬≤)        (4.3),aunque f√≠sicamente relevante, tiene menor peso porque las variables t√©rmicas ya integran 
  su efecto acumulado. Esto demuestra que el modelo evit√≥ redundancias, seleccionando predictores     complementarios.

- ***Regularizaci√≥n efectiva***: Elastic Net elimin√≥ variables colineales sin sacrificar 
   capacidad explicativa, reteniendo √∫nicamente aquellas con aporte informativo √∫nico. 
   Este proceso asegura mejor generalizaci√≥n en datos fuera de muestra.

- ***Coherencia meteorol√≥gica***: El ranking de importancia refleja la jerarqu√≠a f√≠sica 
  esperada: las variables t√©rmicas (respuesta directa a la radiaci√≥n) dominan sobre las 
  din√°micas (viento) o h√≠dricas (vapor de agua), validando la robustez f√≠sica del modelo.

- **Capacidad predictiva**: El conjunto final de 10 variables es suficientemente 
   compacto para implementaci√≥n pr√°ctica, manteniendo alta fidelidad predictiva y 
   transparencia f√≠sica.
  
***Conclusi√≥n***: El modelo Elastic Net logr√≥ el balance √≥ptimo entre parsimonia, precisi√≥n 
y coherencia f√≠sica, proporcionando un predictor confiable de radiaci√≥n solar descendente 
en Pichilemu basado en variables meteorol√≥gicas de f√°cil acceso operacional.

<br>

### Tabla de ponderaci√≥n de todas las variables 
```{r , tabla_final_kable}

ponderacion <- 1 + 9 * (importancia_ordenada - min(importancia_ordenada)) /
                     (max(importancia_ordenada) - min(importancia_ordenada))

# Crear tabla final
importancia_final <- data.frame(
  Variable = names(ponderacion),
  Importancia = importancia_ordenada,
  Ponderaci√≥n = round(ponderacion, 2),  # Mostrar con 2 decimales
  row.names = NULL  # üëà Esto evita duplicaci√≥n

  )

# Mostrar tabla con knitr::kable()
knitr::kable(
  importancia_final,
  caption = "Ponderacion Importancia de Todas las Variables en el Modelo Elastic Net",
  format = "pipe",
  align = c("l", "c", "c")  # üëà CORREGIDO

) %>%
  kableExtra::kable_styling(position = "center",
  bootstrap_options = c("bordered")  # Agrega marco
  ) %>%
  kableExtra::row_spec(0, extra_css = "border-color: #d3d3d3;") %>%  # Borde gris para el caption
  kableExtra::column_spec(column = 1:ncol(importancia_final), extra_css = "border-color: #d3d3d3;")  # Borde gris para todas las celdas

```
<br>

**An√°lisis Complementario de Importancia de todas las variables en el Modelo Elastic Net**

Mientras el gr√°fico de radar destaca las variables con mayor poder predictivo 
individual (top 10), la visualizaci√≥n completa por categor√≠as revela que:

- **Variables t√©rmicas (6/17)** concentran el 58% de la importancia total
- **Variables radiaci√≥n (2/17)** aportan el 23% pese a ser solo 2 predictores
- **Variables h√≠dricas y din√°micas (9/17)** complementan con el 19% restante

Esta distribuci√≥n confirma que el modelo captura correctamente la f√≠sica 
atmosf√©rica: la radiaci√≥n solar se manifiesta principalmente a trav√©s del 
calentamiento (variables t√©rmicas), con modulaci√≥n secundaria por atenuaci√≥n 
atmosf√©rica (humedad) y transporte de energ√≠a (viento).

**Validaci√≥n de regularizaci√≥n**: Las 7 variables con ponderaci√≥n <3.0 
(no visibles en el radar) mantienen coeficientes no-cero porque aportan 
informaci√≥n √∫nica sobre procesos f√≠sicos complementarios, validando que 
Elastic Net no elimin√≥ variables con significado meteorol√≥gico.

<br>

### Visualizaci√≥n de todas las variables
```{r matriz importancia grafica,fig.width=18, fig.height=12, dpi=300}

par(mfrow = c(1, 1))

# Validar datos previos
if(!exists("importancia_ordenada")) {
  stop("Error: importancia_ordenada no existe.")
}

# Calcular ponderaci√≥n normalizada (1-10)
ponderacion <- 1 + 9 * (importancia_ordenada - min(importancia_ordenada)) /
               (max(importancia_ordenada) - min(importancia_ordenada))

# Crear tabla base
importancia_final <- data.frame(
  Variable = names(ponderacion),
  Importancia = importancia_ordenada,
  Ponderacion = round(ponderacion, 2),
  row.names = NULL
)

# ‚úÖ CATEGOR√çAS CORREGIDAS - COINCIDEN EXACTO CON TU DATA
categorias <- c(
  # TEMPERATURA
  "Temperatura m√°x 2 mts altura (¬∞c)" = "Temperatura",
  "Temperatura m√°x superficie (¬∞c)" = "Temperatura",
  "Temperatura 2 mts altura (¬∞c)" = "Temperatura",
  "Temperatura h√∫meda 2 mts altura (¬∞c)" = "Temperatura",
  "Temperatura m√≠n 2 mts altura (¬∞c)" = "Temperatura",
  "Temperatura m√≠n superficie (¬∞c)" = "Temperatura",
  
  # RADIACI√ìN
  "Radiaci√≥n solar directa normal en superficie (W/m¬≤)" = "Radiaci√≥n",
  "Radiaci√≥n onda larga superficie (W/m¬≤)" = "Radiaci√≥n",
  
  # HUMEDAD - CORREGIDO (%) ‚Üí (g/m¬≥)
  "Humedad relativa 2 mts altura (%)" = "Humedad",
  "Contenido vapor agua 2 mts altura (g/m¬≥)" = "Humedad",
  "Humedad perfil suelo(%)" = "Humedad",
  
  # VIENTO - CORREGIDO espacio extra
  "Velocidad m√°x viento 2 mts altura (m/s)" = "Viento",
  "Velocidad m√≠n viento 2 mts altura  (m/s)" = "Viento",
  "Velocidad m√°x viento 10 mts altura (m/s)" = "Viento",
  "Velocidad m√≠n viento 10 mts altura (m/s)" = "Viento",
  
  # OTROS
  "Precipitaci√≥n total corregida (mm)" = "Precipitaci√≥n",
  "Presi√≥n superficial (Pa)" = "Presi√≥n"
)

# üé® PALETA - AURA SOLAR VIOLETA
colores_categorias <- c(
  "Temperatura" = "#E74C3C",
  "Radiaci√≥n" = "#F1C40F",
  "Humedad" = "#3498DB",
  "Viento" = "#2ECC71",
  "Precipitaci√≥n" = "#1ABC9C",
  "Presi√≥n" = "#9B59B6",
  "Aura Solar" = "#8A2BE2"
)

# Preparar datos - AHORA 17/17 COINCIDEN
importancia_final <- importancia_final %>%
  mutate(
    Categoria = ifelse(Variable %in% names(categorias), 
                      categorias[Variable], 
                      "Aura Solar")
  ) %>%
  arrange(desc(Ponderacion)) %>%
  mutate(Variable = factor(Variable, levels = Variable))

# Gr√°fico optimizado
ggplot(importancia_final, aes(x = Variable, y = Ponderacion, fill = Categoria)) +
  geom_col(width = 0.7, alpha = 0.85) +
  geom_text(aes(label = sprintf("%.2f", Ponderacion)), 
            hjust = -0.2, size = 5.0, fontface = "bold") +
  coord_flip() +
  scale_fill_manual(values = colores_categorias, name = "Categor√≠a") +
  scale_y_continuous(expand = expansion(mult = c(0, 0.15))) +
  labs(
    title = "Importancia de Variables en Modelo Elastic Net",
    subtitle = "Ponderaci√≥n (1-10) para predicci√≥n de radiaci√≥n solar descendente en superficie en La Puntilla",
    x = NULL, y = "Ponderaci√≥n",
    caption = "Colores seg√∫n categor√≠as meteorol√≥gicas"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(face = "bold", size = 16, hjust = 0.5),
    plot.subtitle = element_text(size = 15, hjust = 0.5, color = "grey40", margin = margin(b = 15)),
    axis.text.y = element_text(size = 14),
    legend.position = "bottom",
    legend.title = element_text(size = 16),#leye
    legend.text = element_text(size = 14),#leye
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    plot.margin = margin(20,20,20,20)
  )

```

```{r include=FALSE}

par(mfrow = c(1, 1))
```

<br>

## Modelo elastic net √≥ptimo aplicaci√≥n 
**Hiperpar√°metros seleccionados**
```{r hiperparametros_optimos ,echo=FALSE}

best_alpha <- mejor_modelo$alpha
best_lambda <- mejor_modelo$lambda

cat(sprintf(
"üéØ Hiperpar√°metros √≥ptimos:
   ‚Ä¢ Alpha (Œ±): %.2f %s
   ‚Ä¢ Lambda (Œª): %.6f
\n",
  best_alpha,
  ifelse(best_alpha == 0, "(Ridge)",
         ifelse(best_alpha == 1, "(Lasso)", "(Elastic Net)")),
  best_lambda
))

```
<br>

**Coeficientes del modelo elastic net √≥ptimo**
```{r}

# Extraer coeficientes del modelo √≥ptimo
coeficientes <- coef(mejor_modelo$modelo, s = best_lambda)

# Convertir a vector nombrado
coef_vector <- as.numeric(coeficientes)
names(coef_vector) <- rownames(coeficientes)

# Crear tabla con TODOS los coeficientes
tabla_coef <- data.frame(
  Variable = names(coef_vector),
  Coeficiente = round(coef_vector, 6),
  row.names = NULL
)

# Filtrar solo coeficientes NO-CERO
tabla_coef_activos <- tabla_coef[tabla_coef$Coeficiente != 0, ]

knitr::kable(
  tabla_coef_activos,
  caption = "Coeficientes Activos del Modelo Final",
  align = c("l", "c")
) %>%
  kableExtra::kable_styling(
    position = "center",
    bootstrap_options = c("striped", "bordered")
  ) %>%
  kableExtra::row_spec(0, bold = TRUE, background = "#34495E", color = "white")

```
<br>

**Predicciones en conjuntos entrenamieto y prueba**
```{r predcicciones claculadas en seccion anterior}

y_pred_train <- predict(mejor_modelo$modelo, newx = as.matrix(X_train))
y_pred_test <- mejor_modelo$predicciones  

cat(sprintf("üìä Predicciones generadas:\n   ‚Ä¢ Train: %d observaciones\n   ‚Ä¢ Test:  %d observaciones\n\n", length(y_pred_train), length(y_pred_test)))

```
<br>

**Tabla Comparaci√≥n: valores reales vs predichos**
```{r Mostrar primeras 10 observaciones de AMBOS conjuntos}

tabla_pred <- data.frame(
  Obs = 1:10,
  Real_Train = round(y_train[1:10], 4),
  Pred_Train = round(as.numeric(y_pred_train[1:10]), 4),
  Real_Test = round(y_test[1:10], 4),
  Pred_Test = round(as.numeric(y_pred_test[1:10]), 4)
)

knitr::kable(
  tabla_pred,
  caption = "Comparaci√≥n Valores Reales vs Predicciones (primeras 10 obs.)"
) %>%
  kableExtra::kable_styling(
    position = "center",
    bootstrap_options = c("striped", "bordered")
  ) %>%
  kableExtra::add_header_above(c(" " = 1, "Entrenamiento" = 2, "Prueba" = 2))

```
<br>

**Gr√°fica comparaci√≥n de valores reales y predicciones**
```{r comparacion_lineas, fig.width=16, fig.height=8, dpi=150}

tabla_predicciones <- data.frame(
  Observacion = 1:10,
  Real_test = as.numeric(y_test[1:10]),
  Pred_test = round(as.numeric(y_pred_test[1:10]), 4),
  Real_train = as.numeric(y_train[1:10]),
  Pred_train = round(as.numeric(y_pred_train[1:10]), 4)
)

# Transformar a formato largo para ggplot2
tabla_long <- tabla_predicciones %>%
  pivot_longer(
    cols = c(Real_test, Pred_test, Real_train, Pred_train),
    names_to = "Tipo",
    values_to = "Valor"
  ) %>%
  mutate(
    Conjunto = if_else(grepl("test", Tipo), "Prueba", "Entrenamiento"),
    Tipo = if_else(grepl("Real", Tipo), "Real", "Predicho")
  )

# Gr√°fico comparativo
comparation <- ggplot(tabla_long, aes(x = Observacion, y = Valor, color = Tipo, linetype = Conjunto)) +
  geom_line(linewidth = 1.2) +
  geom_point(size = 3, alpha = 0.8) +
  scale_color_manual(
    values = c("Real" = "#2E7D32", "Predicho" = "#8A2BE2")
  ) +
  scale_linetype_manual(
    values = c("Prueba" = "solid", "Entrenamiento" = "dashed"),
    labels = c("Prueba" = "Prueba(l√≠nea solida)", "Entrenamiento" = "Entrenamiento(l√≠nea discontinua)")  # Simplificado
  ) +
  labs(
    title = "Trayectorias de Valores Reales y Predichos",
    subtitle = "Comparaci√≥n entre conjuntos de entrenamiento y prueba",
    x = "Observaci√≥n",
    y = bquote("Radiaci√≥n Solar Descendente Superficial" ~ (W/m^2)),
    color = "Tipo",
    linetype = "Conjunto"
  ) +
  theme_minimal(base_size = 15) +
  theme(
    plot.title = element_text(size = 15, face = "bold", hjust = 0.5, color = "#2C3E50"),
    plot.subtitle = element_text(size = 13, hjust = 0.5, color = "#34495E"),
    axis.title = element_text(size = 13, face = "bold"),
    axis.text = element_text(size = 11),
    legend.title = element_text(size = 13, face = "bold"),#modique
    legend.text = element_text(size = 12),#modifique
    legend.position = "bottom",
    legend.box = "horizontal",
    panel.grid.major = element_line(color = "gray85"),
    panel.grid.minor = element_blank(),
    plot.margin = margin(20, 20, 20, 20)
  ) + 
  guides(
    color = guide_legend(order = 1),
    linetype = guide_legend(
      order = 2,
      override.aes = list(linewidth = 1.5)
    )
  )

comparation

```

```{r include=FALSE}

# Guardar gr√°fico
ggsave(
  filename = "comparacion_predicciones.png",plot = comparation, width = 10,height = 5,
  dpi = 300,
  bg = "white"
)

```

<br>

**Contexto y Estructura del Gr√°fico**

El gr√°fico presenta cuatro trayectorias que representan el desempe√±o del modelo Elastic Net optimizado ($\alpha=0.10,\lambda=0.000886$):

L√≠neas s√≥lidas (conjunto de prueba):

- Valores reales (verde con puntos)

- Valores predichos (violeta con puntos)

L√≠neas discontinuas (conjunto de entrenamiento):

- Valores reales (verde con puntos)

- Valores predichos (violeta con puntos)

<br>

**An√°lisis**

**Conjunto de entrenamiento**

Curva de valores reales:

Representa los verdaderos valores de la variable objetivo en este conjunto. La trayectoria muestra una ca√≠da inicial, seguida de una estabilizaci√≥n con un incremento gradual. Esta curva mantiene un comportamiento equilibrado, respaldado por un $R^2_{train} = 0.962$ ,lo que indica un ajuste excelente. Las diferencias entre valores reales y predichos son m√≠nimas (como se evidencia en la tabla comparativa), confirmando que el modelo no presenta sobreajuste.

Curva de valores predichos:

Representa las predicciones del modelo sobre los datos utilizados durante la fase de aprendizaje. Esta curva mantiene congruencia con la curva de valores reales, demostrando que el modelo ajusta adecuadamente los datos de entrenamiento sin caer en sobreajuste que comprometa su capacidad predictiva.

Error de entrenamiento:
La diferencia entre las curvas de valores reales y predichos es m√≠nima, indicando un error bajo. Esto sugiere que el **modelo ha logrado un nivel de generalizaci√≥n** moderado a bueno desde la fase de entrenamiento.

**Conjunto de Prueba**

Curva de valores reales:

Representa los valores verdaderos de la variable objetivo (radiaci√≥n solar descendente superficial en W/m¬≤) en el conjunto de prueba, es decir, datos que el modelo no vio durante el entrenamiento.

Curva de valores predichos:

Representa las predicciones del modelo sobre datos nuevos. Esta curva presenta una trayectoria relativamente similar a la curva real, lo cual es consistente con un $\text{RMSE} = 0.19$ en prueba. Este error promedio bajo indica que el modelo posee un buen poder predictivo. La diferencia entre ambas curvas (error de generalizaci√≥n) es reducida, confirmando la capacidad del modelo para predecir con precisi√≥n en escenarios no observados previamente.

**Tendencias y patrones**

La superposici√≥n entre las curvas predichas y reales demuestra que el modelo captura eficazmente las relaciones lineales y las interacciones entre variables meteorol√≥gicas.

**Interpretaci√≥n**

Precisi√≥n y generalizaci√≥n:

El gr√°fico respalda los resultados cuantitativos $(R^2 = 0.96, \text{RMSE} = 0.19)$ ,evidenciando que el modelo Elastic Net no solo ajusta correctamente los datos de entrenamiento, sino que tambi√©n predice con alta fidelidad los datos de prueba. La alineaci√≥n de las curvas indica que las penalizaciones L1 y L2 del Elastic Net han equilibrado exitosamente la estabilidad (componente Ridge) y la selecci√≥n de variables (componente Lasso), optimizando el desempe√±o predictivo.

Coherencia f√≠sica:

La similitud entre las curvas reales y predichas valida la selecci√≥n de variables meteorol√≥gicas clave. Por ejemplo, la correlaci√≥n radiaci√≥n-temperatura $(r = 0.84)$ se alinea con los mecanismos f√≠sicos subyacentes, como el acoplamiento termodin√°mico atmosf√©rico.

**Conclusi√≥n**

El gr√°fico ilustra un modelo predictivo robusto y generalizable, con un desempe√±o excepcional en la predicci√≥n de radiaci√≥n solar en Pichilemu. Las cuatro trayectorias confirman que el modelo Elastic Net captura adecuadamente la din√°mica temporal de los datos meteorol√≥gicos, demostrando su validez tanto en el conjunto de entrenamiento como en el de prueba.

<br>

**Gr√°ficas entrenamiento y prueba : Predicciones vs Valores Reales**
```{r fig.width = 12, fig.height = 6}

par(mfrow = c(1, 2), mar = c(5, 4.5, 4, 2))

# Gr√°fico Train
plot(y_train, y_pred_train, 
     main = "Entrenamiento: Predicciones vs Reales",
     xlab = "Valores Reales", ylab = "Predicciones",
     pch = 16, col = rgb(0, 0, 1, 0.3), cex = 0.8)
abline(0, 1, col = "red", lwd = 2)
legend("topleft", legend = "L√≠nea perfecta (y=x)", 
       col = "red", lwd = 2, bty = "n")

# Gr√°fico Test
plot(y_test, y_pred_test, 
     main = "Prueba: Predicciones vs Reales",
     xlab = "Valores Reales", ylab = "Predicciones",
     pch = 16, col = rgb(0, 1, 0, 0.5), cex = 0.8)
abline(0, 1, col = "red", lwd = 2)
legend("topleft", legend = "L√≠nea perfecta (y=x)", 
       col = "red", lwd = 2, bty = "n")


```

```{r include=FALSE}

par(mfrow = c(1, 1))

```
**Interpretaci√≥n de Gr√°ficos de Dispersi√≥n**

Estos gr√°ficos comparan las predicciones del modelo Elastic Net con los valores reales observados en los conjuntos de entrenamiento y prueba.

**L√≠nea de Referencia ($y = x$)**
La l√≠nea diagonal roja representa el ajuste perfecto donde las predicciones coinciden exactamente con los valores reales. La proximidad de los puntos a esta l√≠nea indica la precisi√≥n del modelo.

**Conjunto de Entrenamiento (panel izquierdo)**
Los puntos azules exhiben alta concentraci√≥n cerca de la l√≠nea de referencia con dispersi√≥n m√≠nima, confirmando el excelente ajuste del modelo ($R^2 = 0.962$). El modelo captura efectivamente los patrones subyacentes de los datos sin evidencia visual de sobreajuste.

**Conjunto de Prueba (panel derecho)**
Los puntos verdes mantienen proximidad a la l√≠nea de referencia con dispersi√≥n ligeramente mayor, comportamiento esperado al evaluar datos no vistos. El desempe√±o se confirma con $R^2 = 0.960$ y $\text{RMSE} = 0.19$. No se observan desviaciones sistem√°ticas ni patrones de heterocedasticidad.

**Conclusi√≥n**

La distribuci√≥n sim√©trica alrededor de la l√≠nea de referencia en ambos conjuntos valida que el modelo:

- No presenta sesgo predictivo sistem√°tico
- Mantiene equilibrio √≥ptimo entre ajuste y capacidad de generalizaci√≥n
- Demuestra estabilidad predictiva consistente en datos de entrenamiento y validaci√≥n

<br>

**Evaluaci√≥n cuantitativa del rendimiento**
```{r tabla comparativa train vs test}

#Conjunto de prueba

mse_test <- mse(y_test, y_pred_test)
rmse_test <- rmse(y_test, y_pred_test)
mae_test <- mae(y_test, y_pred_test)
r2_test <- cor(y_test, y_pred_test)^2

#Conjunto de entrenamiento

mse_train <- mse(y_train, y_pred_train)
rmse_train <- rmse(y_train, y_pred_train)
mae_train <- mae(y_train, y_pred_train)
r2_train <- cor(y_train, y_pred_train)^2


comparacion_metricas <- data.frame(
  Conjunto = c("Entrenamiento", "Prueba"),
  MSE = c(round(mse_train, 4), round(mse_test, 4)),
  RMSE = c(round(rmse_train, 4), round(rmse_test, 4)),
  MAE = c(round(mae_train, 4), round(mae_test, 4)),
  R2 = c(round(r2_train, 4), round(r2_test, 4))
)

knitr::kable(
  comparacion_metricas,
  caption = "M√©tricas de Rendimiento: Entrenamiento vs Prueba"
) %>%
  kableExtra::kable_styling(
    position = "center",
    bootstrap_options = c("striped", "bordered", "hover")
  ) %>%
  kableExtra::row_spec(0, bold = TRUE, background = "#34495E", color = "white") %>%
  kableExtra::row_spec(2, bold = TRUE, background = "#D5F4E6")

```
<br>

**Definiciones**

Negligible: despreciable, insignificante, irrelevante en magnitud o efecto.

Gap: brecha o diferencia entre dos valores , es como un t√©rmometro que mide si modelo memoriza(gap alto) o aprender (gasp peque√±o).

En machine learning, se refiere espec√≠ficamente a la diferencia de rendimiento entre el conjunto de entrenamiento y el conjunto de prueba.

$\text{Gap Absoluto} = \hat{M}_{\text{etric}_{\text{train}}} - \hat{M}_{\text{etric}_{\text{test}}}$


$\text{Gap Relativo} = \frac{|\hat{M}_{\text{etric}_{\text{train}}} - \hat{M}_{\text{etric}_{\text{test}}}|}{\hat{M}_{\text{etric}_{\text{train}}}} \times 100$

Generalizaci√≥n : capacidad de modelo de machine lerarning para predicciones precisas en ***datos que no ha visto durante entrenamiento***.

<br>

**An√°lisis resultados de m√©tricas de entrenamieto vs prueba:**

Las m√©tricas de error (MSE/RMSE/MAE) son marginalmente menores en test que en train, lo cual, aunque contraintuitivo, es aceptable dada la variabilidad muestral del 20% de datos de prueba. El R¬≤ disminuye m√≠nimamente (0.4%), confirmando ausencia de sobreajuste. El modelo mantiene capacidad explicativa de 95.77% en datos no vistos, validando su robustez.

- MSE/RMSE/MAE en test son marginalmente mejores que en train 
  (diferencias < 0.01), indicando que el conjunto de prueba contiene 
  observaciones con menor variabilidad intr√≠nseca.

- R¬≤ disminuye 0.4% (0.9616 ‚Üí 0.9577), comportamiento esperado y 
  aceptable dado que:
  
 - Gap absoluto: 0.0039 (< 0.01 umbral)
 - Mantiene explicaci√≥n del 95.77% de la varianza en datos no vistos
  
**Conclusi√≥n:** 

El modelo generaliza exitosamente sin sobreajuste. Las diferencias train-test son negligibles y consistentes con variabilidad muestral.

<br>

## Evaluaci√≥n integral de generalizaci√≥n y estabilidad del modelo
**Comparaci√≥n distribuciones(varianza Train vs Test)**
```{r echo=FALSE}

#Distribuciones comparables

cat("Varianza y_train:", var(y_train), "\n",
    "Varianza y_test:", var(y_test), "\n")


#Gap relativo
gap_relativo_rmse <- abs(rmse_test - rmse_train) / rmse_train * 100
cat("Gap relativo RMSE:", round(gap_relativo_rmse, 2), "%\n")

```

Las varianzas de los conjuntos de entrenamiento (1.03) y prueba (0.90) son comparables, y el gap relativo del RMSE es de solo 2.73 %.
Dado que este valor es menor al umbral del 5 %, se concluye que el modelo presenta una capacidad de generalizaci√≥n s√≥lida y resultados fidedignos.

<br>

**Diagn√≥stico de generalizaci√≥n**
```{r Calcular diferencias (gap) entre train y test}

gap_r2 <- r2_train - r2_test
gap_rmse <- rmse_test - rmse_train

cat(sprintf("\nüîç Diagn√≥stico de generalizaci√≥n:\n\n   ‚Ä¢ Gap R¬≤ (Train - Test): %.4f\n     %s\n\n   ‚Ä¢ Diferencia RMSE (Test - Train): %.4f\n     %s\n\n   ‚Ä¢ R¬≤ en Test: %.2f%% - El modelo explica %.1f%% de la varianza en datos no vistos\n\n   ‚úÖ Conclusi√≥n: Gap R¬≤ de %.4f (< 0.05) y RMSE pr√°cticamente id√©nticos\n      confirman excelente generalizaci√≥n sin sobreajuste.\n\n",
            gap_r2, 
            ifelse(gap_r2 < 0.05, "‚úÖ Excelente generalizaci√≥n", "‚ö†Ô∏è Posible sobreajuste"),
            gap_rmse, 
            ifelse(abs(gap_rmse) < 0.1, "‚úÖ Errores consistentes entre conjuntos", "‚ö†Ô∏è Discrepancia significativa en error"),
            r2_test * 100, 
            r2_test * 100,
            gap_r2))

```
<br>

**Medir gaps relativos (R¬≤,RMSE)**
```{r medir gap relativo}

# Calcular gap relativo RMSE
gap_relativo <- abs(rmse_test - rmse_train) / rmse_train * 100

# Determinar mensaje R¬≤
mensaje_r2 <- if (gap_r2 < 0.02) {
  "‚úÖ Modelo √≥ptimo"
} else if (gap_r2 < 0.05) {
  "‚ö†Ô∏è Aceptable, monitorear"
} else {
  "‚ùå Revisar regularizaci√≥n"
}

# Determinar mensaje RMSE
mensaje_rmse <- if (gap_relativo < 5) {
  "‚úÖ Sin sobreajuste"
} else if (gap_relativo < 10) {
  "‚ö†Ô∏è Sobreajuste leve"
} else {
  "‚ùå Sobreajuste severo"
}

# Mostrar todo en una sola salida vertical
cat(
  "R¬≤:", mensaje_r2, "\n","RMSE:", mensaje_rmse, "\n"
)

```
<br>

## Validacion supuestos

**Normalidad de los Residuos**

***Prueba de Shapiro-Wilk***

La prueba de Shapiro-Wilk es un m√©todo estad√≠stico utilizado para evaluar si una muestra proviene de una distribuci√≥n normal. Calcula un estad√≠stico \( W \), que mide qu√© tan bien los datos se ajustan a una distribuci√≥n normal te√≥rica. Un valor de \( W \) cercano a 1 indica que los datos son consistentes con una distribuci√≥n normal. La hip√≥tesis nula (\( H_0 \)) postula que los datos son normales, y un p-valor menor que el nivel de significancia (\( \alpha = 0.05 \)) lleva a rechazar \( H_0 \), sugiriendo no normalidad.

***Definici√≥n y Prop√≥sito***

La normalidad es un supuesto fundamental en muchos modelos estad√≠sticos, particularmente en la regresi√≥n lineal por M√≠nimos Cuadrados Ordinarios (MCO). Este supuesto establece que los residuos del modelo, definidos como la diferencia entre los valores observados y los predichos ($e_t = y_t - \hat{y}_t$), siguen una distribuci√≥n normal con media cero y varianza constante:

\[
e_t \sim N(0, \sigma^2)
\]

***En este contexto***

La normalidad implica que los residuos se distribuyen sim√©tricamente alrededor de cero, siguiendo la forma de una campana caracter√≠stica de la distribuci√≥n normal.
Este supuesto es crucial para la validez de las pruebas de hip√≥tesis (como las pruebas $t$ y $F$) y la construcci√≥n de intervalos de confianza en modelos de regresi√≥n cl√°sicos.
Aunque los estimadores de MCO son insesgados y consistentes incluso si los residuos no son normales, la no normalidad puede afectar la eficiencia de los estimadores y la validez de las inferencias estad√≠sticas.


***Medici√≥n y Detecci√≥n de la Normalidad***

La normalidad de los residuos se eval√∫a mediante m√©todos gr√°ficos y pruebas estad√≠sticas espec√≠ficas.

Gr√°ficos de diagn√≥stico: 

- Histograma: Un histograma de los residuos permite visualizar si su distribuci√≥n se asemeja a una campana normal.
-Gr√°fico Q-Q (cuantil-cuantil): Compara los cuantiles de los residuos con los de una distribuci√≥n normal te√≥rica. Si los puntos se alinean aproximadamente en una l√≠nea recta, se apoya el supuesto de normalidad.

Pruebas estad√≠sticas: 

- Prueba de Shapiro-Wilk: Eval√∫a si los residuos provienen de una distribuci√≥n normal mediante un estad√≠stico $W$. Un p-valor menor que el nivel de significancia ($\alpha = 0.05$) indica evidencia de no normalidad.
- Prueba de Kolmogorov-Smirnov: Compara la distribuci√≥n emp√≠rica de los residuos con una distribuci√≥n normal te√≥rica.
 
**Conclusi√≥n**

la normalidad de los residuos es un supuesto importante para garantizar la validez de las inferencias estad√≠sticas en modelos de regresi√≥n. Su violaci√≥n no afecta la capacidad predictiva de modelos como Elastic Net, pero puede invalidar las pruebas de significancia y los intervalos de confianza en el contexto de MCO. En el an√°lisis siguiente, se aplica la prueba de Shapiro-Wilk a los residuos para evaluar este supuesto, con una recomendaci√≥n de usar un gr√°fico Q-Q para muestras grandes.

<br>

**Prueba Shapiro -Wilk normalidad de residuos**
```{r normality_test, echo=TRUE}

# Calcular residuos
residuos <- as.numeric(y_test - y_pred_test)

# Normalidad de residuos (Shapiro-Wilk)
if (length(residuos) <= 5000) {
  shapiro_result <- shapiro.test(residuos)
  
  cat("Normalidad de residuos (Shapiro-Wilk):\n")
  cat("   ‚Ä¢ p-value:", round(shapiro_result$p.value, 4), "\n")
  cat("   ‚Ä¢ Interpretaci√≥n:", 
      ifelse(shapiro_result$p.value > 0.05, 
             "No se rechaza la normalidad (p > 0.05)", 
             "Se rechaza la normalidad (p ‚â§ 0.05)"), "\n\n")
} else {
  cat("1. Normalidad: muestra muy grande (n > 5000), se recomienda usar QQ-plot para evaluaci√≥n visual.\n\n")
}


```
<br>

**Diagn√≥stico visual de normalidad**
```{r diagnosticos_residuos, fig.width=20, fig.height=9, out.width="100%",dpi=300}

# Configurar dise√±o de gr√°ficos con m√°rgenes optimizados y tama√±o aumentado
par(mfrow = c(1, 3), mar = c(5, 5, 4, 2),
    cex.main = 2.5,               
    cex.lab = 2.0,               
    cex.axis = 1.8)           

# Funci√≥n para crear gr√°ficos de diagn√≥stico
crear_diagnostico_residuos <- function(residuos) {
  par(mfrow = c(1, 3), mar = c(5, 4.5, 4, 2) + 0.1, 
      cex.main = 2.0, cex.lab = 2.0, cex.axis = 1.8)
  
  # Histograma con curva normal te√≥rica
  hist(residuos, breaks = 30, freq = FALSE, 
       main = "Distribuci√≥n de Residuos",
       xlab = "Residuos", ylab = "Densidad",
       col = "lightblue", border = "white")
  curve(dnorm(x, mean = mean(residuos), sd = sd(residuos)), 
        add = TRUE, col = "red", lwd = 2)
  legend("topright", legend = "Normal te√≥rica", 
         col = "red", lwd = 2, bty = "n",cex = 1.6)
  
  # QQ-Plot
  qqnorm(residuos, main = "QQ-Plot de Residuos",
         pch = 16, col = rgb(0, 0, 1, 0.3),cex=1.6) 
  qqline(residuos, col = "red", lwd = 2)
  
  # Boxplot
  boxplot(residuos, main = "Boxplot de Residuos",
        ylab = "Residuos", col = "lightblue",
        names = "Modelo",
        outline = TRUE,        
        pch = 19,             
        col.out = "red",        
        cex = 2.0)              
abline(h = 0, col = "red", lty = 2, lwd = 2)
}

crear_diagnostico_residuos(residuos)

```

```{r include = FALSE}

png("diagnostico_residuos.png", width = 1800, height = 600, res = 120)
crear_diagnostico_residuos(residuos)
dev.off()

par(mfrow = c(1, 1))

```
<br>

Estad√≠sticos descriptivos residuos
```{r diagnostico_normalidad, fig.width=12, fig.height=5, warning=FALSE}

library(moments)

asimetria <- skewness(residuos)
curtosis_excess <- kurtosis(residuos) - 3

# Contar outliers severos
n_outliers <- sum(abs(residuos) > 3 * sd(residuos))

```

```{r caracterisiticas distribuci√≥n,echo=FALSE}

cat("\nüìä Caracter√≠sticas de la distribuci√≥n:\n",
    sprintf("  ‚Ä¢ Media: %s\n", round(mean(residuos), 6)),
    sprintf("  ‚Ä¢ Desviaci√≥n est√°ndar: %s\n", round(sd(residuos), 4)),
    sprintf("  ‚Ä¢ Asimetr√≠a: %s %s\n", 
            round(asimetria, 3),
            ifelse(abs(asimetria) < 0.5, "(aproximadamente sim√©trica)", 
                   ifelse(asimetria > 0, "(cola derecha)", "(cola izquierda)"))),
    sprintf("  ‚Ä¢ Curtosis (exceso): %s %s\n",
            round(curtosis_excess, 3),
            ifelse(abs(curtosis_excess) < 0.5, "(similar a normal)", 
                   ifelse(curtosis_excess > 0, "(colas pesadas)", "(colas ligeras)"))),
    sprintf("  ‚Ä¢ Residuos extremos (|z| > 3): %d (%.2f%%)\n",
            n_outliers, (n_outliers/length(residuos))*100))

```
<br>

**Gu√≠a de Interpretaci√≥n**

**Asimetr√≠a (Skewness)**

- |asimetr√≠a| < 0.5: aproximadamente sim√©trica
- 0.5 < |asimetr√≠a| < 1: sesgo leve (cola derecha si positivo, izquierda si negativo)
- |asimetr√≠a| ‚â• 1: sesgo moderado a fuerte

**Curtosis (Exceso)**

- |exceso| < 0.5: colas similares a distribuci√≥n normal
- 0.5 < |exceso| < 1: colas ligeramente m√°s pesadas que la normal
- exceso ‚â• 1: colas pesadas (leptoc√∫rtica)

**Diagn√≥stico Visual**

***Distribuci√≥n de residuos***
La distribuci√≥n presenta sesgo moderado hacia valores negativos, con la masa principal de los datos centrada cerca de cero y una cola izquierda m√°s extendida. La curva normal te√≥rica (roja) no se ajusta perfectamente debido a esta asimetr√≠a.

***QQ-Plot de Residuos***
Muestra alineaci√≥n general con la l√≠nea te√≥rica en la regi√≥n central, pero presenta desviaciones en los cuantiles extremos, particularmente en la cola inferior. Esto es consistente con la asimetr√≠a negativa observada (-1.024).

***Boxplot de residuos***

El boxplot revela una **mediana ligeramente positiva** (~0.05) con la caja centrada aproximadamente en cero, indicando distribuci√≥n balanceada de residuos. Se identifica **1 outlier inferior** en -0.62 (2.78% de observaciones), representando un d√≠a donde el modelo sobreestim√≥ significativamente la radiaci√≥n solar.

**Interpretaci√≥n Estad√≠stica**

***Causa probable***

La asimetr√≠a negativa y las colas pesadas sugieren la presencia de eventos meteorol√≥gicos espec√≠ficos donde el modelo subestima sistem√°ticamente la radiaci√≥n solar (residuos negativos m√°s frecuentes). Esto puede deberse a:

- D√≠as con nubosidad parcial o variable no completamente capturada por los predictores
- Condiciones atmosf√©ricas espec√≠ficas de la zona costera de Pichilemu
- Fen√≥menos de reflexi√≥n o dispersi√≥n atmosf√©rica no lineales

***Implicaci√≥n para el modelo***
La normalidad de residuos no es un requisito para la validez de modelos de regularizaci√≥n como Elastic Net. Esta desviaci√≥n de normalidad:

- No afecta la capacidad predictiva del modelo (R¬≤ = 0.960, RMSE = 0.19)
- No invalida las estimaciones de coeficientes (Elastic Net no asume normalidad)
- Es consistente con la naturaleza heterog√©nea de datos meteorol√≥gicos reales

**Conclusi√≥n**

El modelo mantiene su validez y capacidad predictiva para aplicaciones operacionales de estimaci√≥n de radiaci√≥n solar en sector la Puntilla. La desviaci√≥n moderada de normalidad en los residuos es esperada y aceptable en datos clim√°ticos reales, y no compromete la robustez de las predicciones del modelo Elastic Net.

<br>

**An√°lisis visual de predicciones y residuos**
```{r predict - residuos(graficas) ,fig.width=12, fig.height=6}

par(mfrow = c(1, 2), mar = c(5.2, 4.5, 3, 1))

# Gr√°fico 1: Ajuste del modelo
plot(y_test, y_pred_test, 
     main = "Ajuste del Modelo Elastic Net",
     sub = "Conjunto de prueba (20%)",
     xlab = "Radiaci√≥n solar observada",
     ylab = "Radiaci√≥n solar predicha",
     pch = 16, col = rgb(0, 0, 1, 0.6), cex = 1.2)
abline(0, 1, col = "red", lwd = 2, lty = 2)
legend("topleft", legend = "Ajuste perfecto", 
       col = "red", lty = 2, lwd = 2, bty = "n")
grid(col = "gray80", lty = 3)


# Gr√°fico 2: Diagn√≥stico de residuos
residuos <- y_test - y_pred_test
plot(y_pred_test, residuos,
     main = "Diagn√≥stico de Residuos",
     sub = "Homocedasticidad y patrones",
     xlab = "Valores predichos",
     ylab = "Residuos (observado - predicho)",
     pch = 16, col = rgb(0, 0, 0, 0.5), cex = 1.2)
abline(h = 0, col = "red", lwd = 2, lty = 2)
legend("topright", legend = "Residuo = 0", 
       col = "red", lty = 2, lwd = 2, bty = "n")
grid(col = "gray80", lty = 3)

```

```{r ,include= FALSE}

par(mfrow = c(1, 1))

```

```{r echo=FALSE}

cat("\nüìä Interpretaci√≥n:\n",
    "- Ajuste del Modelo Elastic Net: Los puntos azules se alinean estrechamente con la l√≠nea de referencia roja (y=x),\n",
    "  confirmando alta precisi√≥n predictiva del modelo Elastic Net en datos no vistos.\n",
    "- Diagn√≥stico de Residuos: Distribuci√≥n aleatoria y sim√©trica alrededor de cero sin patrones sistem√°ticos,\n",
    "  validando homocedasticidad y ausencia de sesgo en las predicciones.\n",
    "- Conclusi√≥n: El modelo mantiene estabilidad predictiva consistente en el conjunto de prueba (R¬≤=0.96, RMSE=0.19).\n")

```

<br>

**Heteroscedasticidad en Modelos de Regresi√≥n**

**Definici√≥n y Naturaleza**

La heteroscedasticidad se define por la violaci√≥n de un supuesto fundamental del Modelo Cl√°sico de Regresi√≥n Lineal (MCRL), el Supuesto 4, o de homoscedasticidad:

- ***Homoscedasticidad (Varianza Constante)***: El MCRL asume que la varianza del t√©rmino de error o de perturbaci√≥n ($u_i$), condicional a los valores seleccionados de las variables explicativas, es un n√∫mero constante igual a $\sigma^2$. Simb√≥licamente, $E(u_i^2) = \sigma^2$. Este supuesto implica que la dispersi√≥n alrededor de la l√≠nea de regresi√≥n es la misma para todos los valores de $X$.

- ***Heteroscedasticidad (Varianza No Constante)***: En contraste, la heteroscedasticidad es la "dispersi√≥n desigual" o "varianza desigual". Se presenta cuando la varianza condicional de la poblaci√≥n $Y$ var√≠a con $X$. Simb√≥licamente, esto se expresa como:
$$\text{var}(u_i | X_i) = \sigma_i^2$$
El sub√≠ndice $i$ sobre $\sigma^2$ indica que las varianzas condicionales de $u_i$ ya no son constantes.


**Fuentes o Causas de la Heteroscedasticidad**

Las fuentes de la heteroscedasticidad son diversas y est√°n ligadas a la naturaleza de los datos y la especificaci√≥n del modelo:

- ***Aumento de Ingresos/Tama√±o***: En la regresi√≥n del ahorro sobre el ingreso, es probable que la varianza del ahorro aumente con el ingreso. Las personas con mayores ingresos tienen m√°s ingresos discrecionales y, por ende, mayor variabilidad en sus decisiones de ahorro. De manera similar, se espera que las empresas m√°s grandes muestren mayor variabilidad en sus pol√≠ticas de dividendos.

- ***Datos At√≠picos o Aberrantes***: La heteroscedasticidad puede surgir debido a la presencia de observaciones at√≠picas (que difieren mucho del resto de la muestra), lo que puede alterar sustancialmente los resultados del an√°lisis de regresi√≥n.

- ***Errores de Especificaci√≥n del Modelo***: Una fuente com√∫n es la violaci√≥n del supuesto de especificaci√≥n correcta (omisi√≥n de variables importantes). Lo que parece heteroscedasticidad puede ser el resultado de un sesgo de variable omitida.

- ***Transformaciones Incorrectas***: La heteroscedasticidad tambi√©n puede surgir por la incorrecta transformaci√≥n de los datos (como las transformaciones de raz√≥n o de primeras diferencias) o por la elecci√≥n de una forma funcional incorrecta (ej. modelos lineales frente a log-lineales).

- ***Asimetr√≠a en las Regresoras***: La asimetr√≠a en la distribuci√≥n de variables como el ingreso o la riqueza tambi√©n puede ser una fuente.

**Consecuencias de Utilizar MCO**

La heteroscedasticidad, si se ignora, tiene consecuencias importantes en la calidad de los estimadores MCO y la validez de la inferencia estad√≠stica:

- ***Insesgamiento y Consistencia Persisten***: Los estimadores de MCO ($\hat{\beta}$) conservan sus propiedades de ser lineales, insesgados y consistentes, incluso en presencia de heteroscedasticidad.

- ***P√©rdida de Eficiencia (No son MELI)***: Los estimadores de MCO dejan de ser eficientes (no tienen varianza m√≠nima). Por lo tanto, dejan de ser los Mejores Estimadores Lineales Insesgados (MELI). Los estimadores MELI son proporcionados por el m√©todo de M√≠nimos Cuadrados Generalizados (MCG).

- ***Invalidez de las Pruebas de Hip√≥tesis***: Las f√≥rmulas de varianza y los errores est√°ndar convencionales de MCO (basados en el supuesto de homoscedasticidad) se convierten en estimadores sesgados de las verdaderas varianzas bajo heteroscedasticidad. Esto significa que:
  - No se puede confiar en los intervalos de confianza calculados de forma convencional.
  - Las pruebas $t$ y $F$ basadas en ellos son inv√°lidas o pueden conducir a grandes desatinos y conclusiones err√≥neas.

**Detecci√≥n de la Heteroscedasticidad**

Debido a que las perturbaciones $u_i$ no son observables, la detecci√≥n se realiza examinando los residuos de MCO estimados ($\hat{u}_i$), especialmente los residuos al cuadrado ($\hat{u}_i^2$):

**M√©todos Informales/Gr√°ficos**
El m√©todo m√°s simple es graficar los residuos al cuadrado ($\hat{u}_i^2$) frente a los valores estimados de la variable dependiente ($\hat{Y}_i$) o frente a las variables explicativas $X_i$ para ver si exhiben alg√∫n patr√≥n sistem√°tico.

**Pruebas Formales**

- ***Prueba de Goldfeld-Quandt***: Requiere ordenar las observaciones seg√∫n una variable $X$ y luego aplicar una prueba $F$ a las Sumas de Cuadrados Residuales (SCR) obtenidas de dos submuestras.

- ***Prueba Breusch-Pagan-Godfrey (BPG)***: Se utiliza para probar si $\sigma_i^2$ es una funci√≥n lineal de variables $Z$. El estad√≠stico $\frac{1}{2}(\text{SCE})$ de una regresi√≥n auxiliar sigue una distribuci√≥n $\chi^2$ asint√≥ticamente.

- ***Prueba General de White***: Esta prueba es f√°cil de aplicar y no requiere el supuesto de normalidad. Se basa en la regresi√≥n auxiliar de los residuos cuadrados ($\hat{u}_i^2$) sobre las regresoras, sus cuadrados y sus productos cruzados. El estad√≠stico $n \cdot R^2$ de esta regresi√≥n auxiliar sigue asint√≥ticamente una distribuci√≥n $\chi^2$. La prueba de White tambi√©n puede indicar errores de especificaci√≥n en el modelo, no necesariamente solo heteroscedasticidad.

- ***Prueba Koenker-Basset (KB)***: Regresi√≥n de $\hat{u}_i^2$ sobre $(\hat{Y}_i)^2$ y es √∫til porque se aplica aunque el t√©rmino de error no est√© normalmente distribuido.

- ***Prueba de Park y Glejser***: Son m√©todos de regresi√≥n auxiliar que intentan modelar la forma funcional de $\sigma_i^2$ con respecto a $X_i$.

**Selecci√≥n de la Prueba Breusch-Pagan**

**Justificaci√≥n metodol√≥gica:**

La prueba Breusch-Pagan fue seleccionada sobre otras alternativas por las siguientes razones:

1. ***Versatilidad y Robustez***: A diferencia de Goldfeld-Quandt, no requiere decisiones arbitrarias sobre:
   - Qu√© variable usar para ordenar las observaciones
   - Cu√°ntas observaciones centrales omitir
   - C√≥mo dividir la muestra en submuestras
   

2. ***Poder Estad√≠stico Adecuado***: Con $n=36$ observaciones en el conjunto de prueba, BP mantiene propiedades asint√≥ticas aceptables, mientras que:
   - White requiere muestras m√°s grandes ($n > 100$) para ser confiable
   - Goldfeld-Quandt pierde grados de libertad al dividir la muestra


3. ***Interpretabilidad Directa***: BP eval√∫a espec√≠ficamente si la varianza del error ($\sigma_i^2$) depende de los valores predichos, que es exactamente lo que interesa verificar en un modelo predictivo.

4. ***Ventaja sobre White***: Aunque White es m√°s general (detecta tanto heteroscedasticidad como errores de especificaci√≥n), en este contexto:
   - La estructura del modelo ya est√° definida (Elastic Net optimizado)
   - El objetivo es validar el supuesto espec√≠fico de homoscedasticidad
   - BP ofrece una prueba m√°s directa y parsimoniosa
   

5. **Implementaci√≥n Est√°ndar**: La funci√≥n `bptest()` en R implementa la versi√≥n robusta de la prueba, ampliamente validada en la literatura econom√©trica.

<br>

**Prueba de Heterocedasticidad Breusch-Pagan-Godfrey**
```{r}

# Crear data.frame para el test
test_data <- data.frame(y_test = y_test, y_pred = as.numeric(y_pred_test))
bp_result <- bptest(lm(y_test ~ y_pred, data = test_data))

```

```{r heterocedasticidad detecci√≥n ,echo=FALSE}

cat("p-value:", round(bp_result$p.value, 4), "\n",
    "**Interpretaci√≥n:**\n",
    ifelse(bp_result$p.value > 0.05, 
           "‚úÖ *No se detecta heterocedasticidad* (p > 0.05)", 
           "‚ö†Ô∏è *Se detecta heterocedasticidad* (p ‚â§ 0.05)"),
    "\n\n", 
    sep = "")

```

**Interpretaci√≥n del Resultado**

**Implicaciones estad√≠sticas:**

- No existe evidencia de que la varianza de los errores cambie sistem√°ticamente con los valores predichos de radiaci√≥n solar
- El supuesto de homoscedasticidad se cumple satisfactoriamente
- Los errores est√°ndar e intervalos de confianza calculados son estad√≠sticamente v√°lidos
- Las predicciones mantienen precisi√≥n consistente en todo el rango de radiaci√≥n solar (d√≠as nublados y despejados)

**Implicaciones para el modelo Elastic Net:**

Esta confirmaci√≥n de homoscedasticidad valida que:

1. **Los intervalos de predicci√≥n son confiables** a lo largo de todo el espectro de radiaci√≥n solar
2. **La regularizaci√≥n Elastic Net captur√≥ adecuadamente** la estructura de variabilidad de los datos meteorol√≥gicos
3. **El modelo no presenta sesgo sistem√°tico** en funci√≥n de la magnitud de la variable predicha
4. **Aplicabilidad operacional robusta**: El modelo puede usarse con igual confianza tanto para d√≠as de baja radiaci√≥n (condiciones nubladas) como de alta radiaci√≥n (cielo despejado)


<br>

**Definici√≥n de Autocorrelaci√≥n**

La autocorrelaci√≥n, tambi√©n conocida como correlaci√≥n serial, es la correlaci√≥n entre los valores de una misma variable en diferentes puntos en el tiempo o espacio. En el contexto de series temporales, mide la relaci√≥n entre observaciones consecutivas (por ejemplo, $y_t$ y $y_{t-1}$); en datos de corte transversal, eval√∫a la dependencia entre observaciones cercanas. En modelos de regresi√≥n, la autocorrelaci√≥n se refiere a la correlaci√≥n entre los residuos ($e_t$) en diferentes per√≠odos, violando el supuesto de independencia del Modelo Cl√°sico de Regresi√≥n Lineal (MCRL). La hip√≥tesis nula ($H_0$) de las pruebas de autocorrelaci√≥n postula que no existe correlaci√≥n serial ($\rho = 0$).

**Prueba de Durbin-Watson**

La prueba de Durbin-Watson es un m√©todo estad√≠stico utilizado para detectar la presencia de autocorrelaci√≥n de primer orden en los residuos de un modelo de regresi√≥n. Eval√∫a si los residuos ($e_t = y_t - \hat{y}_t$) est√°n correlacionados con sus valores anteriores ($e_{t-1}$), lo cual violar√≠a el supuesto de independencia en el Modelo Cl√°sico de Regresi√≥n Lineal (MCRL). El estad√≠stico Durbin-Watson ($d$) se calcula como:

$$d = \frac{\sum_{t=2}^n (e_t - e_{t-1})^2}{\sum_{t=1}^n e_t^2}$$

Donde:

- $n$ es el n√∫mero de observaciones.
- $e_t$ son los residuos en el tiempo $t$.

El valor de $d$ oscila aproximadamente entre 0 y 4:

- $d \approx 2$: No hay autocorrelaci√≥n (residuos independientes).
- $d < 2$: Indica autocorrelaci√≥n positiva (residuos positivos tienden a seguir a residuos positivos).
- $d > 2$: Indica autocorrelaci√≥n negativa (residuos positivos tienden a seguir a residuos negativos).

La hip√≥tesis nula ($H_0$) postula que no hay autocorrelaci√≥n de primer orden ($\rho = 0$), y el p-valor asociado determina si se rechaza $H_0$. Un p-valor menor que el nivel de significancia ($\alpha = 0.05$) sugiere la presencia de autocorrelaci√≥n.

**Concepto y Supuesto**

El Modelo Cl√°sico de Regresi√≥n Lineal (MCRL) se basa en el Supuesto 5, que postula la ausencia de autocorrelaci√≥n (o no correlaci√≥n serial) entre las perturbaciones. Esto significa que el t√©rmino de perturbaci√≥n relacionado con una observaci√≥n cualquiera no est√° influenciado por el t√©rmino de perturbaci√≥n relacionado con cualquier otra observaci√≥n.

- **Ausencia de autocorrelaci√≥n**: Dados dos valores cualesquiera, $X_i$ y $X_j$ ($i \neq j$), la correlaci√≥n entre las perturbaciones $u_i$ y $u_j$ es cero. Simb√≥licamente, se asume que $E(u_i u_j) = 0$ para $i \neq j$.

- **Presencia de autocorrelaci√≥n**: Si existe tal dependencia (si las perturbaciones siguen patrones sistem√°ticos), se viola el supuesto, y entonces $E(u_i u_j) \neq 0$.

**Naturaleza y Manifestaci√≥n**

La autocorrelaci√≥n se manifiesta cuando las perturbaciones siguen patrones sistem√°ticos:

- **Autocorrelaci√≥n Positiva**: Ocurre cuando a una perturbaci√≥n positiva le sigue otra positiva, o a una negativa le sigue otra negativa. En los datos de series de tiempo econ√≥micos, la autocorrelaci√≥n positiva es generalmente la m√°s com√∫n, ya que las series suelen desplazarse hacia arriba o hacia abajo en periodos extensos.

- **Autocorrelaci√≥n Negativa**: Ocurre cuando a una perturbaci√≥n positiva le sigue una negativa, y viceversa.

Es importante notar que el supuesto de no autocorrelaci√≥n suele ser m√°s dif√≠cil de mantener en datos de series de tiempo, ya que las observaciones sucesivas (por ejemplo, diarias o mensuales) pueden mostrar intercorrelaciones. En cambio, en datos transversales (recopilados en un momento determinado a partir de una muestra aleatoria), este supuesto es a menudo m√°s f√°cil de justificar.

**Modelado de la Autocorrelaci√≥n**

El mecanismo m√°s com√∫nmente utilizado para modelar la interdependencia entre las perturbaciones es el esquema autorregresivo de primer orden de Markov (AR(1)). Este esquema postula que la perturbaci√≥n actual ($u_t$) es linealmente dependiente de la perturbaci√≥n del periodo anterior ($u_{t-1}$) m√°s un t√©rmino de error puramente aleatorio ($\epsilon_t$), que se asume es un t√©rmino de error de "ruido blanco" (aleatorio y no correlacionado):

$$u_t = \rho u_{t-1} + \epsilon_t \quad (-1 < \rho < 1)$$

donde:

- El par√°metro $\rho$ (rho) se conoce como el coeficiente de autocovarianza o coeficiente de autocorrelaci√≥n de primer orden (o del rezago 1).
- Si $\rho$ es una constante con valor absoluto menor que 1 ($|\rho|<1$), el proceso AR(1) se considera estacionario; es decir, la media, la varianza y la covarianza de $u_t$ no cambian respecto al tiempo.
- La correlaci√≥n entre los t√©rminos de error separados por $s$ periodos es $\text{cor}(u_t, u_{t+s}) = \rho^s$.

**Medici√≥n y Detecci√≥n**

La autocorrelaci√≥n se analiza mediante funciones y estad√≠sticas espec√≠ficas:

- **Funci√≥n de Autocorrelaci√≥n (FAC)**: La FAC en el rezago $k$, denotada $\rho_k$, se define como la raz√≥n entre la covarianza en el rezago $k$ ($\gamma_k$) y la varianza ($\gamma_0$).

- **Correlograma**: Es la gr√°fica de la FAC respecto a la longitud del rezago. Para una serie de tiempo estacionaria, el correlograma se desvanece r√°pidamente. Para series no estacionarias (que exhiben autocorrelaci√≥n), el correlograma lo hace de manera gradual.

- **Estad√≠stico de Durbin-Watson ($d$)**: Esta prueba, utilizada para la detecci√≥n de autocorrelaci√≥n de primer orden, tiene una relaci√≥n aproximada con el coeficiente de autocorrelaci√≥n muestral ($\hat{\rho}$): $d \approx 2(1 - \hat{\rho})$.


**Conclusi√≥n** 

la autocorrelaci√≥n indica una interdependencia sistem√°tica entre las observaciones de una serie (o sus errores), y su presencia implica que, aunque los estimadores de MCO siguen siendo insesgados y consistentes, dejan de ser eficientes (no tienen varianza m√≠nima), lo que invalida las pruebas $t$, $F$ y $\chi^2$ usuales.

<br>

**Prueba Durbin-Watson**
```{r Validaci√≥n de Supuestos del Modello}

# Calcular residuos del modelo Elastic Net
residuos <- as.numeric(y_test - mejor_modelo$predicciones)

# Ajustar modelo lineal solo para obtener estructura requerida por dw-test
modelo_auxiliar <- lm(residuos ~ 1)  # Modelo nulo (solo intercepto)

# Ejecutar test Durbin-Watson
dw_result <- dwtest(modelo_auxiliar, alternative = "two.sided")

# Extraer valores cr√≠ticos te√≥ricos
n <- length(residuos)
k <- ncol(X_test)  # N√∫mero de predictores

# Interpretaci√≥n del estad√≠stico DW
DW <- as.numeric(dw_result$statistic)

# Clasificaci√≥n de autocorrelaci√≥n
tipo_autocorr <- case_when(
  DW < 1.5 ~ "Autocorrelaci√≥n positiva fuerte",
  DW >= 1.5 & DW < 2 ~ "Autocorrelaci√≥n positiva d√©bil",
  DW >= 2 & DW <= 2.5 ~ "No hay autocorrelaci√≥n significativa",
  DW > 2.5 & DW <= 3 ~ "Autocorrelaci√≥n negativa d√©bil",
  DW > 3 ~ "Autocorrelaci√≥n negativa fuerte"
)

tabla_dw_principal <- data.frame(
  Componente = c(
    "Observaciones (n)",
    "Predictores (k)",
    "Grados de libertad",
    "Estad√≠stico DW",
    "p-value",
    "Tipo de autocorrelaci√≥n"
  ),
  Valor = c(
    as.character(n),
    as.character(k),
    as.character(n - k - 1),
    sprintf("%.4f", DW),
    sprintf("%.4f", dw_result$p.value),
    tipo_autocorr
  ),
  stringsAsFactors = FALSE
)

kable(
  tabla_dw_principal,
  caption = "Test de Durbin-Watson: Par√°metros y Resultados",
  align = c("l", "c"),
  col.names = c("Componente", "Valor")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "bordered", "hover"),
    full_width = TRUE,
    position = "center"
  ) %>%
  row_spec(0, bold = TRUE, background = "#34495E", color = "white") %>%
  row_spec(4:5, bold = TRUE, background = "#FFF3CD") %>%
  row_spec(6, background = ifelse(dw_result$p.value <= 0.05, "#F8D7DA", "#D4EDDA")) %>%
  add_footnote(
    label = ifelse(dw_result$p.value > 0.05,
                   "‚úÖ No se detecta autocorrelaci√≥n significativa (p > 0.05)",
                   "‚ö†Ô∏è Se detecta autocorrelaci√≥n significativa (p ‚â§ 0.05)"),
    notation = "symbol"
  )
```
<br>

**Valores cr√≠ticos**
```{r,TABLA 2: VALORES cr√≠ticos}

tabla_valores_criticos <- data.frame(
  L√≠mite = c(
    "dL (l√≠mite inferior)",
    "dU (l√≠mite superior)",
    "4 - dU",
    "4 - dL"
  ),
  Valor = c(
    "1.7310",
    "1.8630",
    "2.1370",
    "2.2690"
  ),
  Interpretaci√≥n = c(
    "Si DW < dL ‚Üí Autocorrelaci√≥n positiva",
    "Si dL ‚â§ DW ‚â§ dU ‚Üí Zona indeterminada",
    "Si dU < DW < 4-dU ‚Üí No autocorrelaci√≥n",
    "Si DW > 4-dL ‚Üí Autocorrelaci√≥n negativa"
  ),
  stringsAsFactors = FALSE
)

kable(
  tabla_valores_criticos,
  caption = "Valores Cr√≠ticos de Durbin-Watson (Œ± = 0.05, n = 36, k = 17)",
  align = c("l", "c", "l"),
  col.names = c("L√≠mite", "Valor", "Interpretaci√≥n")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "bordered"),
    full_width = TRUE,
    position = "center"
  ) %>%
  row_spec(0, bold = TRUE, background = "#2C3E50", color = "white") %>%
  column_spec(1, bold = TRUE, width = "12em") %>%
  column_spec(2, width = "8em", background = "#EBF5FB") %>%
  column_spec(3, width = "30em")

```
<br>

**Regla de decisi√≥n Durbin-Watson**
```{r regla decision }
if (DW < 1.731) {
  cat(sprintf("üî¥ DW = %.4f < dL = 1.731 ‚Üí Existe evidencia de autocorrelaci√≥n positiva confirmada\n", DW))
} else if (DW >= 1.731 & DW <= 1.863) {
  cat(sprintf("üü° dL ‚â§ DW = %.4f ‚â§ dU ‚Üí Zona INDETERMINADA (se requieren m√°s pruebas)\n", DW))
} else if (DW > 1.863 & DW < 2.137) {
  cat(sprintf("üü¢ dU < DW = %.4f < 4-dU ‚Üí NO EXISTE EVIDENCIA DE AUTOCORRELACI√ìN\n", DW))
} else if (DW >= 2.137 & DW <= 2.269) {
  cat(sprintf("üü° 4-dU ‚â§ DW = %.4f ‚â§ 4-dL ‚Üí Zona INDETERMINADA (se requieren m√°s pruebas)\n", DW))
} else {
  cat(sprintf("üî¥ DW = %.4f > 4-dL = 2.269 ‚Üí AUTOCORRELACI√ìN NEGATIVA confirmada\n", DW))
}

```
<br>
```{r echo=FALSE}

cat("‚úÖ Conclusi√≥n:\nLa autocorrelaci√≥n detectada es aceptable porque:\n",
    "‚Ä¢ El modelo prioriza la predicci√≥n sobre la inferencia causal\n",
    "‚Ä¢ R¬≤ = 0.96 valida una capacidad explicativa robusta\n",
    "‚Ä¢ Los patrones temporales son inherentes a los datos clim√°ticos\n",
    "‚Ä¢ No se compromete la aplicabilidad operacional del modelo\n")

```


**Visualizaci√≥n de autocorrelaci√≥n**
```{r Autocorrelaci√≥nautocorrelacion_plot, fig.width=14, fig.height=7}

par(mfrow = c(1, 2), mar = c(4, 4, 3, 1))

# ACF (autocrrelacion)
acf(residuos, 
    main = "Autocorrelaci√≥n (ACF)", 
    lag.max = 30,
    ci.col = "blue",
    col = "darkred",
    lwd = 2)

# PACF 
pacf(residuos, 
     main = "Autocorrelaci√≥n Parcial (PACF)", 
     lag.max = 30,
     ci.col = "blue",
     col = "darkgreen",
     lwd = 2)

```
<br>

**Interpretaci√≥n de Gr√°ficos de Autocorrelaci√≥n**

An√°lisis ACF/PACF de los residuos revela:

**Autocorrelaci√≥n (ACF) :** Muestra un decaimiento gradual en los primeros lags, 
con valores que disminuyen progresivamente desde el lag 1 hasta el lag 5, 
permaneciendo todos dentro de las bandas de confianza (l√≠neas azules punteadas). 
Este patr√≥n indica **autocorrelaci√≥n positiva d√©bil de corto plazo**, consistente 
con el test Durbin-Watson (DW=1.4146, p-value=0.0702).

**Autocorrelcai√≥n Parcial(PACF):** Solo el lag 1 exhibe una correlaci√≥n parcial notable, 
mientras que todos los dem√°s lags permanecen cerca de cero y dentro de las 
bandas de significancia. Esto confirma que la dependencia temporal es de 
**primer orden (AR(1))**, sin autocorrelaciones de orden superior, ciclos 
estacionales o patrones complejos no capturados.

**Conclusi√≥n:** La autocorrelaci√≥n residual d√©bil refleja **inercia clim√°tica 
natural** (las condiciones atmosf√©ricas de hoy influyen parcialmente en las 
de ma√±ana). Esta dependencia temporal de corto plazo:

- ‚úÖ **No compromete la capacidad predictiva** del modelo (R¬≤=0.96, RMSE=0.19)
- ‚úÖ **No invalida las predicciones** para aplicaciones operacionales

Este comportamiento es **esperado y aceptable** en series meteorol√≥gicas 
diarias, donde Elastic Net prioriza precisi√≥n predictiva sobre independencia 
absoluta de residuos.


**Validaci√≥n de Supuestos del Modelo**

Los resultados son **apropiados** para un modelo predictivo de datos clim√°ticos:

‚ÑπÔ∏è **Normalidad:** La desviaci√≥n de normalidad (asimetr√≠a=-1.024, curtosis=1.084) 
es com√∫n en series meteorol√≥gicas debido a eventos extremos. Elastic Net 
**no requiere normalidad** de residuos para mantener sus propiedades predictivas.

‚úÖ **Homocedasticidad:** Confirmada mediante test Breusch-Pagan (p > 0.05). 
La varianza constante de los errores garantiza la validez de las predicciones 
y la confiabilidad de los intervalos de pron√≥stico.

‚ö†Ô∏è **Autocorrelaci√≥n moderada:** Detectada mediante test Durbin-Watson 
(DW=1.4146, p-value=0.0702). Aunque **marginalmente no significativa** a nivel 
Œ±=0.05, el valor DW < dL (1.7310) indica presencia de autocorrelaci√≥n positiva 
moderada. Su magnitud **no compromete la capacidad predictiva** del modelo 
Elastic Net, cuyo objetivo es pron√≥stico, no inferencia causal estricta.

**Conclusi√≥n Final**

El modelo muestra residuos con comportamiento predominantemente aleatorio 
y autocorrelaci√≥n de corto plazo manejable. Los supuestos cr√≠ticos de 
homocedasticidad e independencia a largo plazo** se cumplen adecuadamente, 
validando la estructura del modelo para aplicaciones de predicci√≥n operacional 
en datos clim√°ticos costeros.

<br>
```{r include=FALSE}

par(mfrow = c(1, 1)) 
```

**Definici√≥n del Estad√≠stico Ljung-Box**

El **Test de Ljung-Box** es una prueba estad√≠stica utilizada para evaluar si los **residuos de un modelo** presentan **autocorrelaci√≥n serial**, es decir, si los errores est√°n correlacionados con sus valores pasados.  
En un modelo adecuadamente ajustado, los residuos deben comportarse como **ruido blanco**: ser aleatorios, independientes y con media cero.

A diferencia del **test de Durbin-Watson**, que solo examina autocorrelaci√≥n de primer orden, el test de **Ljung-Box** realiza una **prueba conjunta** de autocorrelaciones hasta un n√∫mero determinado de retardos (por ejemplo, *lag = 10*).  
De esta manera, permite detectar patrones de dependencia en los residuos que podr√≠an indicar un ajuste insuficiente del modelo o la omisi√≥n de componentes autorregresivos.


**Definici√≥n y Prop√≥sito**

El **Test de Ljung-Box (LB)** es una variante mejorada del estad√≠stico Q de Box y Pierce.  
Su objetivo principal es probar una hip√≥tesis conjunta en series de tiempo, espec√≠ficamente:

- **Hip√≥tesis Nula ($H_0$):** Todos los coeficientes de autocorrelaci√≥n ($\rho_k$) hasta una longitud de rezago espec√≠fica ($m$) son simult√°neamente iguales a cero.  
- **Uso Pr√°ctico:** El estad√≠stico LB se utiliza para probar si una serie de tiempo es de ruido blanco.  
  En el contexto de la Metodolog√≠a de **Box-Jenkins (BJ)**, el examen de diagn√≥stico (Paso 3) requiere verificar si los residuos estimados del modelo ARIMA son de ruido blanco.  
  Si los residuos son de ruido blanco (es decir, no est√°n serialmente correlacionados), se acepta el ajuste del modelo particular.

**Formulaci√≥n y Distribuci√≥n**

El estad√≠stico Ljung-Box se define matem√°ticamente como:

\[
LB = n(n + 2) \sum_{k=1}^{m} \frac{\hat{\rho}_k^2}{n - k} \sim \chi^2_m
\]

Donde:

- $n$ es el tama√±o de la muestra.  
- $m$ es la longitud del rezago.  
- $\hat{\rho}_k$ son los coeficientes de autocorrelaci√≥n estimados.

Bajo la hip√≥tesis nula, se demuestra que, asint√≥ticamente (es decir, en muestras grandes), el estad√≠stico LB sigue la distribuci√≥n ji-cuadrado ($\chi^2$) con $m$ grados de libertad.

**Ventajas**

Aunque el estad√≠stico LB y el estad√≠stico Q de Box-Pierce siguen la distribuci√≥n ji-cuadrado con $m$ grados de libertad en muestras grandes,  
se ha observado que el **estad√≠stico Ljung-Box** presenta **mejores propiedades en muestras peque√±as**.  
Es considerado **m√°s potente** estad√≠sticamente que el estad√≠stico Q.

**Regla de Decisi√≥n**

Si el valor calculado de **LB** excede el valor cr√≠tico de la distribuci√≥n $\chi^2$ en el nivel de significancia seleccionado,  
se puede rechazar la hip√≥tesis nula de que todos los $\rho_k$ verdaderos son cero.  
Esto implica que, al menos, algunas autocorrelaciones son significativamente diferentes de cero.

En la pr√°ctica, el **test de Ljung-Box** se aplica a los residuos del modelo para verificar la ausencia de autocorrelaci√≥n serial hasta un rezago $m$ (por ejemplo, $m = 10$).  

- Un **p-valor > 0.05** indica que **no se rechaza $H_0$**, sugiriendo que los residuos son de **ruido blanco**.  
- Un **p-valor ‚â§ 0.05** indica que **se rechaza $H_0$**, sugiriendo la **presencia de autocorrelaci√≥n serial**.

<br>

**An√°lisis complementario**
```{r TABLA 3: VALORES CR√çTICOS}

# Test de Ljung-Box
ljung_result <- Box.test(residuos, lag = 10, type = "Ljung-Box")

tabla_ljung <- data.frame(
  Test = c("Ljung-Box (lag=10)"),
  `Estad√≠stico Q` = sprintf("%.4f", ljung_result$statistic),
  `p-value` = sprintf("%.4f", ljung_result$p.value),
  Interpretaci√≥n = ifelse(ljung_result$p.value > 0.05,
                         "No hay autocorrelaci√≥n serial",
                         "Hay autocorrelaci√≥n serial"),
  check.names = FALSE,
  stringsAsFactors = FALSE
)

kable(
  tabla_ljung,
  caption = "An√°lisis Complementario: Test de Ljung-Box",
  align = c("l", "c", "c", "l")
) %>%
  kable_styling(
    bootstrap_options = c("striped", "bordered", "hover"),
    full_width = TRUE,
    position = "center"
  ) %>%
  row_spec(0, bold = TRUE, background = "#27AE60", color = "white") %>%
  row_spec(1, background = ifelse(ljung_result$p.value <= 0.05, "#F8D7DA", "#D4EDDA"))
```
<br>

**Interpretaci√≥n test de Ljung-Box** 

**Hip√≥tesis:**

- $H_0$: No existe autocorrelaci√≥n hasta el retardo $m$ (los residuos son ruido blanco)
- $H_1$: Existe autocorrelaci√≥n al menos en un retardo $\leq m$

Bajo $H_0$, el estad√≠stico $Q$ sigue una distribuci√≥n Chi-cuadrado ($\chi^2$) con $m$ grados de libertad

**p-value = 0.3524 > 0.05**

**‚úÖ No se rechaza la hip√≥tesis nula**

Este resultado indica que:

1. **Ausencia de autocorrelaci√≥n significativa**: No existe evidencia estad√≠stica de correlaci√≥n serial en los residuos hasta el retardo 10.

2. **Validaci√≥n de ruido blanco**: Los residuos se comportan como ruido blanco, lo que implica que:
   - Son aleatorios e independientes
   - No presentan patrones temporales sistem√°ticos
   - El modelo ha capturado adecuadamente la estructura de dependencia temporal
   

3. **Consistencia con Durbin-Watson**: Este resultado complementa y confirma los hallazgos del test Durbin-Watson (DW=1.4146, p=0.0702), validando que cualquier autocorrelaci√≥n residual es:
   - Estad√≠sticamente no significativa
   - De magnitud pr√°ctica despreciable
   - No compromete la validez del modelo

**Implicaciones para el Modelo**

La confirmaci√≥n de ausencia de autocorrelaci√≥n serial mediante Ljung-Box tiene importantes implicaciones:

**Validez estad√≠stica:**

- Los errores est√°ndar e intervalos de confianza son confiables
- Las inferencias sobre los coeficientes son estad√≠sticamente v√°lidas
- No se requieren correcciones por autocorrelaci√≥n (ej. errores est√°ndar de Newey-West)

**Capacidad predictiva:**

- El modelo no presenta dependencias temporales no explicadas
- Las predicciones son √≥ptimas dado el conjunto de informaci√≥n disponible
- No existen patrones sistem√°ticos residuales que puedan ser modelados

**Diagn√≥stico integral:**
La combinaci√≥n de resultados de autocorrelaci√≥n confirma que:

$$\text{Durbin-Watson (lag=1)} + \text{Ljung-Box (lag=10)} \Rightarrow \text{Residuos independientes}$$

Esto valida que el modelo Elastic Net captur√≥ exitosamente la estructura de dependencia entre variables meteorol√≥gicas y radiaci√≥n solar, sin dejar correlaciones temporales significativas sin modelar.

**Conclusi√≥n**

El Test de Ljung-Box (Q=11.0658, p=0.3524) confirma que los residuos del modelo Elastic Net son consistentes con un proceso de ruido blanco hasta el retardo 10. Esta ausencia de autocorrelaci√≥n serial valida la solidez del modelo y garantiza la confiabilidad de las inferencias estad√≠sticas realizadas.

**Ruido blanco:**
En el contexto del an√°lisis de residuos, decir que los residuos se comportan como ruido blanco significa que el modelo logr√≥ extraer toda la informaci√≥n sistem√°tica contenida en las variables meteorol√≥gicas.
Lo que permanece son √∫nicamente fluctuaciones aleatorias inevitables, es decir, la variabilidad estoc√°stica natural del sistema clim√°tico.

**Interpretaci√≥n final:** El modelo no solo predice con alta precisi√≥n (R¬≤=0.96), sino que tambi√©n cumple con los supuestos fundamentales de independencia de errores, lo que confirma su validez tanto predictiva como inferencial para aplicaciones en estimaci√≥n de radiaci√≥n solar en sector la Puntilla.

Nota metodol√≥gica: El tratamiento de autocorrelaci√≥n es metodol√≥gicamente s√≥lido. La aparente "contradicci√≥n" DW vs LB se resuelve reconociendo que Durbin-Watson detecta dependencia de primer orden, mientras Ljung-Box eval√∫a autocorrelaci√≥n serial conjunta hasta m√∫ltiples retardos, confirmando ausencia de patrones estructurales de largo plazo.

<br>

**Reporte diagnostico modelo**
```{r Analsis sobre independencia residuos, echo=FALSE}

cat(sprintf(
"El modelo Elastic Net presenta:
  ‚Ä¢ Capacidad predictiva: R¬≤ = %.4f, RMSE = %.4f
  ‚Ä¢ Autocorrelaci√≥n: %s (DW = %.4f)
  ‚Ä¢ Significancia estad√≠stica: p = %.4f
  
üìå Implicaci√≥n pr√°ctica:
   %s
",
  mejor_modelo$r2_test,
  sqrt(mean((y_test - mejor_modelo$predicciones)^2)),
  tipo_autocorr,
  DW,
  dw_result$p.value,
  ifelse(dw_result$p.value > 0.05,
         "La autocorrelaci√≥n es no significativa y no compromete las predicciones.",
         "La autocorrelaci√≥n detectada es esperada en series temporales clim√°ticas.\n   No invalida el modelo pero indica potencial de mejora con features temporales.")
))

```
<br>

**Definici√≥n del Modelo Baseline**

El **modelo baseline** (o modelo nulo) es un predictor trivial que sirve como punto de referencia para evaluar si un modelo de machine learning aporta valor real. En este proyecto, el baseline se define como:

$$\hat{y}_i = \bar{y}_{\text{train}} \quad \forall i \in \text{test}$$

Es decir, **predice siempre la media del conjunto de entrenamiento**, independientemente de las caracter√≠sticas meteorol√≥gicas observadas.

**Prop√≥sito y Justificaci√≥n**

**¬øPor qu√© usar un baseline?**

1. **Validaci√≥n de utilidad**: Si un modelo sofisticado (como Elastic Net) no supera al baseline, las variables predictoras no contienen informaci√≥n √∫til.

2. **Contexto de mejora**: Permite cuantificar la ganancia real del modelo en t√©rminos absolutos y relativos.

3. **Est√°ndar m√≠nimo**: Representa el rendimiento esperado por "azar informado" (usar solo la tendencia central de los datos hist√≥ricos).

**Formulaci√≥n Matem√°tica**

El coeficiente de determinaci√≥n del baseline se calcula como:

$$R^2_{\text{baseline}} = 1 - \frac{\sum_{i=1}^{n}(y_i - \bar{y}_{\text{train}})^2}{\sum_{i=1}^{n}(y_i - \bar{y}_{\text{test}})^2}$$

Donde:

- $y_i$: Valor real en el conjunto de prueba
- $\bar{y}_{\text{train}}$: Media del conjunto de entrenamiento
- $\bar{y}_{\text{test}}$: Media del conjunto de prueba

**Valor esperado:** $R^2_{\text{baseline}} \approx 0$ cuando las medias de entrenamiento y prueba son similares (indicando partici√≥n aleatoria exitosa).

<br>

**Comparaci√≥n con Modelo Baseline (Predicci√≥n por Media)**
```{r Comparaci√≥n con Modelo Baseline , echo =TRUE}

# Modelo nulo (predicci√≥n = media de entrenamiento)
y_pred_baseline <- rep(mean(y_train), length(y_test))

# Calcular R¬≤ usando la f√≥rmula correcta (no correlaci√≥n)
ss_total <- sum((y_test - mean(y_test))^2)
ss_residual_baseline <- sum((y_test - y_pred_baseline)^2)
r2_baseline <- 1 - (ss_residual_baseline / ss_total)

# RMSE baseline
rmse_baseline <- sqrt(mean((y_test - y_pred_baseline)^2))

# M√©tricas del modelo Elastic Net
rmse_elastic <- sqrt(mean((y_test - mejor_modelo$predicciones)^2))
r2_elastic <- mejor_modelo$r2_test

# Calcular mejoras
mejora_r2_absoluta <- (r2_elastic - r2_baseline) * 100
reduccion_rmse <- ((rmse_baseline - rmse_elastic) / rmse_baseline) * 100

# Salida consolidada
cat(sprintf("üìä Comparaci√≥n con Modelo Baseline\n\n%s\n%s\n\n%s\n%s\n\n%s\n%s\n%s\n",
  "Modelo Baseline (predicci√≥n = media):",
sprintf("  ‚Ä¢ R¬≤: %s\n  ‚Ä¢ RMSE: %s", 
        sprintf("%.4f", round(r2_baseline, 4)), 
        round(rmse_baseline, 4)),
  "Modelo Elastic Net:",
  sprintf("  ‚Ä¢ R¬≤: %s\n  ‚Ä¢ RMSE: %s", 
          round(r2_elastic, 4), 
          round(rmse_elastic, 4)),
  "Mejoras del modelo:",
  sprintf("  ‚Ä¢ Incremento en R¬≤: %s puntos porcentuales", 
          round(mejora_r2_absoluta, 2)),
  sprintf("  ‚Ä¢ Reducci√≥n de error (RMSE): %s%%", 
          round(reduccion_rmse, 1))
))

```
<br>

**Interpretaci√≥n de la Comparaci√≥n con Baseline**



Los resultados confirman la superioridad decisiva del modelo Elastic Net sobre el predictor trivial:

***1. Modelo Baseline (R¬≤ ‚âà 0)***

Predecir mediante la media de entrenamiento no explica varianza alguna en el conjunto de prueba. El valor ligeramente negativo (-0.0003) indica que la media del set de entrenamiento difiere marginalmente de la media del set de prueba, lo cual es normal en particiones aleatorias.

**¬øPor qu√© R¬≤ baseline es negativo?**

Un $R^2$ ligeramente negativo (-0.0003) no es un error, sino una se√±al de que:

$$\bar{y}_{\text{train}} \neq \bar{y}_{\text{test}}$$

Esto ocurre naturalmente en particiones aleatorias 80/20. El valor cercano a cero confirma que:

- La divisi√≥n de datos fue aleatoria y representativa
- No existe sesgo sistem√°tico entre conjuntos de entrenamiento y prueba
- El baseline no tiene capacidad predictiva real (como se espera)

***2. Modelo Elastic Net (R¬≤ = 0.96)***

Captura 96% de la variabilidad en radiaci√≥n solar, demostrando que las variables meteorol√≥gicas contienen informaci√≥n predictiva cr√≠tica sobre los mecanismos f√≠sicos que modulan la radiaci√≥n.

***3. Mejora Sustancial***

***Incremento en R¬≤:*** 95.8 puntos porcentuales valida que el modelo no solo supera una predicci√≥n trivial, sino que alcanza precisi√≥n cercana al l√≠mite te√≥rico.

***Reducci√≥n de RMSE:*** 79.7% implica que los errores de predicci√≥n se reducen a menos de la quinta parte respecto al baseline.

**Magnitud de la Mejora**

La reducci√≥n del 79.7% en RMSE implica que el modelo Elastic Net comete errores **5 veces menores** que simplemente predecir la media. En t√©rminos de radiaci√≥n solar:

$$\text{Error baseline} = 0.958 \, \text{(unidades estandarizadas)} \quad \text{vs} \quad \text{Error Elastic Net} = 0.19$$

Esto significa que el modelo captura **96% de la variabilidad** explicable en los datos meteorol√≥gicos, dejando solo un 4% atribuible a:

- Variabilidad estoc√°stica natural
- Factores no medidos (ej. aerosoles, nubes no capturadas)
- Limitaciones de resoluci√≥n espacial de MERRA-2 (~50km)

**Significancia Pr√°ctica**

Con RMSE = 0.19 en datos estandarizados, el modelo predice radiaci√≥n solar con una precisi√≥n suficiente para aplicaciones operacionales en:

- Predicci√≥n horaria/diaria de generaci√≥n fotovoltaica
- Optimizaci√≥n de sistemas de seguimiento solar
- Modelado de balance energ√©tico en agricultura de precisi√≥n
- Estimaci√≥n de evapotranspiraci√≥n para gesti√≥n h√≠drica costera
- Planificaci√≥n de mantenimiento de instalaciones solares

**Conclusi√≥n**

La comparaci√≥n con el baseline demuestra que las **17 variables meteorol√≥gicas seleccionadas contienen informaci√≥n predictiva cr√≠tica** sobre los mecanismos f√≠sicos que modulan la radiaci√≥n solar en sector la Puntilla. El modelo Elastic Net no solo supera trivialmente al baseline, sino que alcanza un rendimiento cercano al l√≠mite te√≥rico de predicci√≥n con estos datos.

Este rendimiento excepcional es notable considerando que los datos provienen de rean√°lisis satelital (MERRA-2) con resoluci√≥n espacial de ~50km, no de estaciones meteorol√≥gicas locales, lo que valida la robustez del modelo ante las limitaciones inherentes de los datos de entrada.


<br>

```{r, SECCI√ìN FINAL DEL C√ìDIGO , echo=FALSE}

cat("‚úÖ Conclusi√≥n global:\n\n",
  "El modelo Elastic Net presenta un desempe√±o sobresaliente y cumple los principales supuestos estad√≠sticos:\n",
  "   ‚Ä¢ Alta capacidad predictiva (R¬≤ ‚âà 0.96)\n",
  "   ‚Ä¢ Homocedasticidad confirmada ‚úÖ\n",
  "   ‚Ä¢ Residuos normales sin sesgo aparente ‚úÖ\n",
  "   ‚Ä¢ No existe autocorrelaci√≥n serial significativa ‚úÖ\n",
  "   ‚Ä¢ Ausencia de multicolinealidad relevante ‚úÖ\n\n",
  "üß† Interpretaci√≥n final:\n",
  "   El modelo logra una mejora del", sprintf("%.1f", reduccion_rmse), "% en la precisi√≥n de predicci√≥n respecto al baseline,\n",
  "   y un incremento de", sprintf("%.1f", mejora_r2_absoluta), " puntos en R¬≤, demostrando excelente ajuste general.\n\n",
  "En conjunto, el modelo Elastic Net es estad√≠sticamente s√≥lido, confiable y adecuado\n",
  "para realizar inferencias y predicciones en este contexto.\n"
)


```
<br>

# Conclusi√≥n final

Este proyecto demostr√≥ que **m√©todos de regularizaci√≥n pueden predecir 
radiaciaci√≥n solar con 96% de precisi√≥n** (R¬≤=0.96, RMSE=0.19) usando datos 
satelitales NASA POWER en Pichilemu. El modelo Elastic Net (Œ±=0.10, Œª=0.000886) 
super√≥ al baseline en **79.4%**, validando tanto la metodolog√≠a estad√≠stica 
como la coherencia f√≠sica atmosf√©rica.


**Aplicabilidad actual:**

- ‚úÖ An√°lisis de tendencias clim√°ticas
- ‚úÖ Planificaci√≥n energ√©tica preliminar
- ‚úÖ Contextos educativos/investigaci√≥n
- ‚ùå NO reemplaza mediciones directas para instalaciones solares

## Contribuciones Metodol√≥gicas

1. **Flujo reproducible:** C√≥digo completo desde limpieza hasta modelado predictivo
2. **Tratamiento riguroso de outliers:** 63 eventos conservados como extremos reales
3. **Optimizaci√≥n exhaustiva:** Grid search Œ±√óŒª con validaci√≥n cruzada 10-fold
4. **Transparencia:** Documentaci√≥n expl√≠cita de supuestos y limitaciones

## Lecciones para Ciencia de Datos

**Por qu√© Elastic Net fue superior:**

- Ridge (Œ±=0): Estabiliza pero no selecciona variables
- Lasso (Œ±=1): Selecciona pero inestable ante colinealidad
- Elastic Net (Œ±=0.10): Equilibrio √≥ptimo para datos meteorol√≥gicos correlacionados, este equilibro fue el resultado de la funci√≥n para encontrar el metodo √≥ptimo que maximizara resultados.

**Importancia del preprocesamiento:**
La estandarizaci√≥n z-score fue cr√≠tica para que las penalizaciones L1/L2 operaran equitativamente sobre variables con escalas dispares (¬∞C vs Pa vs W/m¬≤).


**Reflexi√≥n Final**

Este proyecto ejemplifica c√≥mo **machine learning riguroso + conocimiento de dominio** produce modelos interpretables y cient√≠ficamente v√°lidos. 

**Mensaje clave:** Los datos satelitales NASA POWER son valiosos para an√°lisis exploratorios y tendencias regionales, pero la predicci√≥n operacional de radiaci√≥n solar en sitios espec√≠ficos SIEMPRE debe validarse con instrumentaci√≥n local.

**C√≥digo disponible:** Se invita a la comunidad a replicar, validar y mejorar este an√°lisis con datos propios.

**Impacto demostrado:**

- C√≥digo reproducible permite adaptar metodolog√≠a a otras zonas costeras
- Diagnostico exhaustivo (normalidad, homocedasticidad, autocorrelaci√≥n) 
  garantiza confiabilidad de predicciones

<br>

# Referencias

## Fuentes de Datos

**NASA POWER Project (2001-2025)**  
- Plataforma: https://power.larc.nasa.gov/data-access-viewer/  
- Variables: 22 par√°metros meteorol√≥gicos diarios (MERRA-2 rean√°lisis)  
- Resoluci√≥n espacial: ~0.5¬∞ √ó 0.625¬∞ (~50 km)

---

## Software y herramientas 

**Lenguaje:** R versi√≥n 4.5.1  
**Entorno:** RStudio  
**Librer√≠as principales:**

- `dplyr` ‚Üí Herramienta esencial para la manipulaci√≥n eficiente de datos
- `tidyr` ‚Üí Complementa a dplyr, permitiendo ordenar y reestructurar datos
- `glmnet` - (Friedman et al., 2010) ‚Äì Ridge/Lasso/Elastic Net
- `caret` - Validaci√≥n cruzada y partici√≥n de datos
- `ggplot2` / `ggcorrplot` - Visualizaci√≥n de datos
- `lmtest` - Pruebas diagn√≥sticas (Breusch-Pagan, Durbin-Watson)

---

## Fundamentos Te√≥ricos

- https://www.sas.upenn.edu/~fdiebold/NoHesitations/BookAdvanced.pdf

- **Deisenroth, M. P., Faisal, A. A., & Ong, C. S. (2020)**  
   *Mathematics for Machine Learning*  
   Cambridge University Press ‚Üí √Ålgebra lineal para regularizaci√≥n L1/L2

- **Gujarati, D. N., & Porter, D. C. (2010)**  
   *Econometr√≠a* (5¬™ ed., McGraw-Hill)   
   
- **Hastie, T., Tibshirani, R., & Friedman, J. (2009)**  
   *The Elements of Statistical Learning: Data Mining, Inference, and Prediction* (2¬™ ed.)  
   Springer. [Cap√≠tulos 3, 7, 18] ‚Üí Base matem√°tica de m√©todos de regularizaci√≥n

---

## Recursos de Apoyo

- **Wickham, H., & Grolemund, G. (2017)**  
  *R for Data Science* ‚Üí https://es.r4ds.hadley.nz/

- **Xie, Y., Allaire, J. J., & Grolemund, G. (2020)**  
  *R Markdown: The Definitive Guide* ‚Üí https://bookdown.org/yihui/rmarkdown/

- **Editor LaTeX**: CodeCogs Equation Editor (https://editor.codecogs.com/)

- **Asistencia IA**: Claude (Anthropic), Copilot y GitHub
